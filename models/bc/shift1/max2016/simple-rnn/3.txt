__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
in_age (InputLayer)             (None, None, 2)      0                                            
__________________________________________________________________________________________________
in_bio (InputLayer)             (None, None, 7)      0                                            
__________________________________________________________________________________________________
in_fielding_position (InputLaye (None, None, 2)      0                                            
__________________________________________________________________________________________________
in_out_fielding_position (Input (None, None, 12)     0                                            
__________________________________________________________________________________________________
in_out_league_offense (InputLay (None, None, 9)      0                                            
__________________________________________________________________________________________________
in_out_park_factors (InputLayer (None, None, 8)      0                                            
__________________________________________________________________________________________________
in_out_plate_discipline (InputL (None, None, 8)      0                                            
__________________________________________________________________________________________________
in_out_running (InputLayer)     (None, None, 18)     0                                            
__________________________________________________________________________________________________
in_out_saber (InputLayer)       (None, None, 14)     0                                            
__________________________________________________________________________________________________
in_out_stats_extended (InputLay (None, None, 36)     0                                            
__________________________________________________________________________________________________
in_park_factors (InputLayer)    (None, None, 8)      0                                            
__________________________________________________________________________________________________
masked_in_age (Masking)         (None, None, 2)      0           in_age[0][0]                     
__________________________________________________________________________________________________
masked_in_bio (Masking)         (None, None, 7)      0           in_bio[0][0]                     
__________________________________________________________________________________________________
masked_in_fielding_position (Ma (None, None, 2)      0           in_fielding_position[0][0]       
__________________________________________________________________________________________________
masked_in_out_fielding_position (None, None, 12)     0           in_out_fielding_position[0][0]   
__________________________________________________________________________________________________
masked_in_out_league_offense (M (None, None, 9)      0           in_out_league_offense[0][0]      
__________________________________________________________________________________________________
masked_in_out_park_factors (Mas (None, None, 8)      0           in_out_park_factors[0][0]        
__________________________________________________________________________________________________
masked_in_out_plate_discipline  (None, None, 8)      0           in_out_plate_discipline[0][0]    
__________________________________________________________________________________________________
masked_in_out_running (Masking) (None, None, 18)     0           in_out_running[0][0]             
__________________________________________________________________________________________________
masked_in_out_saber (Masking)   (None, None, 14)     0           in_out_saber[0][0]               
__________________________________________________________________________________________________
masked_in_out_stats_extended (M (None, None, 36)     0           in_out_stats_extended[0][0]      
__________________________________________________________________________________________________
masked_in_park_factors (Masking (None, None, 8)      0           in_park_factors[0][0]            
__________________________________________________________________________________________________
time_distributed_8 (TimeDistrib (None, None, 1)      0           masked_in_age[0][0]              
__________________________________________________________________________________________________
time_distributed_1 (TimeDistrib (None, None, 6)      0           masked_in_bio[0][0]              
__________________________________________________________________________________________________
time_distributed_2 (TimeDistrib (None, None, 1)      0           masked_in_fielding_position[0][0]
__________________________________________________________________________________________________
time_distributed_7 (TimeDistrib (None, None, 11)     0           masked_in_out_fielding_position[0
__________________________________________________________________________________________________
time_distributed_9 (TimeDistrib (None, None, 8)      0           masked_in_out_league_offense[0][0
__________________________________________________________________________________________________
time_distributed_4 (TimeDistrib (None, None, 7)      0           masked_in_out_park_factors[0][0] 
__________________________________________________________________________________________________
time_distributed_6 (TimeDistrib (None, None, 7)      0           masked_in_out_plate_discipline[0]
__________________________________________________________________________________________________
time_distributed_11 (TimeDistri (None, None, 17)     0           masked_in_out_running[0][0]      
__________________________________________________________________________________________________
time_distributed_5 (TimeDistrib (None, None, 13)     0           masked_in_out_saber[0][0]        
__________________________________________________________________________________________________
time_distributed_3 (TimeDistrib (None, None, 35)     0           masked_in_out_stats_extended[0][0
__________________________________________________________________________________________________
time_distributed_10 (TimeDistri (None, None, 7)      0           masked_in_park_factors[0][0]     
__________________________________________________________________________________________________
norm_in_age (BatchNormalization (None, None, 1)      4           time_distributed_8[0][0]         
__________________________________________________________________________________________________
norm_in_bio (BatchNormalization (None, None, 6)      24          time_distributed_1[0][0]         
__________________________________________________________________________________________________
norm_in_fielding_position (Batc (None, None, 1)      4           time_distributed_2[0][0]         
__________________________________________________________________________________________________
norm_in_out_fielding_position ( (None, None, 11)     44          time_distributed_7[0][0]         
__________________________________________________________________________________________________
norm_in_out_league_offense (Bat (None, None, 8)      32          time_distributed_9[0][0]         
__________________________________________________________________________________________________
norm_in_out_park_factors (Batch (None, None, 7)      28          time_distributed_4[0][0]         
__________________________________________________________________________________________________
norm_in_out_plate_discipline (B (None, None, 7)      28          time_distributed_6[0][0]         
__________________________________________________________________________________________________2018-02-07 04:31:17.524737: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-02-07 04:31:24.083899: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: eca0:00:00.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2018-02-07 04:31:24.083946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: eca0:00:00.0, compute capability: 3.7)

norm_in_out_running (BatchNorma (None, None, 17)     68          time_distributed_11[0][0]        
__________________________________________________________________________________________________
norm_in_out_saber (BatchNormali (None, None, 13)     52          time_distributed_5[0][0]         
__________________________________________________________________________________________________
norm_in_out_stats_extended (Bat (None, None, 35)     140         time_distributed_3[0][0]         
__________________________________________________________________________________________________
norm_in_park_factors (BatchNorm (None, None, 7)      28          time_distributed_10[0][0]        
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, None, 113)    0           norm_in_age[0][0]                
                                                                 norm_in_bio[0][0]                
                                                                 norm_in_fielding_position[0][0]  
                                                                 norm_in_out_fielding_position[0][
                                                                 norm_in_out_league_offense[0][0] 
                                                                 norm_in_out_park_factors[0][0]   
                                                                 norm_in_out_plate_discipline[0][0
                                                                 norm_in_out_running[0][0]        
                                                                 norm_in_out_saber[0][0]          
                                                                 norm_in_out_stats_extended[0][0] 
                                                                 norm_in_park_factors[0][0]       
__________________________________________________________________________________________________
gru_1 (GRU)                     (None, None, 113)    76953       concatenate_1[0][0]              
__________________________________________________________________________________________________
gru_2 (GRU)                     (None, None, 113)    76953       gru_1[0][0]                      
__________________________________________________________________________________________________
mv_out_stats (TimeDistributed)  (None, None, 5)      4560        gru_2[0][0]                      
__________________________________________________________________________________________________
mv_out_counts (TimeDistributed) (None, None, 3)      2736        gru_2[0][0]                      
__________________________________________________________________________________________________
mv_out_mean_covariance (TimeDis (None, None, 72)     65664       gru_2[0][0]                      
__________________________________________________________________________________________________
mv_out_fielding_position (TimeD (None, None, 11)     10032       gru_2[0][0]                      
__________________________________________________________________________________________________
out_stats (Activation)          (None, None, 5)      0           mv_out_stats[0][0]               
__________________________________________________________________________________________________
out_counts (Activation)         (None, None, 3)      0           mv_out_counts[0][0]              
__________________________________________________________________________________________________
out_mean_covariance (Activation (None, None, 72)     0           mv_out_mean_covariance[0][0]     
__________________________________________________________________________________________________
out_fielding_position (Activati (None, None, 11)     0           mv_out_fielding_position[0][0]   
==================================================================================================
Total params: 237,350
Trainable params: 237,124
Non-trainable params: 226
__________________________________________________________________________________________________
Train on 5879 samples, validate on 1409 samples
Epoch 1/1000

Epoch 00001: val_loss improved from inf to 19.83793, saving model to models/bc/shift1/max2016/simple-rnn/3.h5
 - 15s - loss: 21.7201 - out_stats_loss: 8.3020 - out_counts_loss: 3.6949 - out_mean_covariance_loss: 104.6220 - out_fielding_position_loss: 4.4921 - val_loss: 19.8379 - val_out_stats_loss: 7.7917 - val_out_counts_loss: 2.8835 - val_out_mean_covariance_loss: 98.9270 - val_out_fielding_position_loss: 4.2164
Epoch 2/1000

Epoch 00002: val_loss improved from 19.83793 to 16.80023, saving model to models/bc/shift1/max2016/simple-rnn/3.h5
 - 5s - loss: 17.9703 - out_stats_loss: 6.9410 - out_counts_loss: 2.4845 - out_mean_covariance_loss: 90.5677 - out_fielding_position_loss: 4.0164 - val_loss: 16.8002 - val_out_stats_loss: 6.5581 - val_out_counts_loss: 2.1873 - val_out_mean_covariance_loss: 85.3832 - val_out_fielding_position_loss: 3.7858
Epoch 3/1000

Epoch 00003: val_loss improved from 16.80023 to 15.13312, saving model to models/bc/shift1/max2016/simple-rnn/3.h5
 - 5s - loss: 15.7870 - out_stats_loss: 6.0949 - out_counts_loss: 2.1232 - out_mean_covariance_loss: 79.5529 - out_fielding_position_loss: 3.5912 - val_loss: 15.1331 - val_out_stats_loss: 5.9583 - val_out_counts_loss: 1.9705 - val_out_mean_covariance_loss: 76.5262 - val_out_fielding_position_loss: 3.3780
Epoch 4/1000

Epoch 00004: val_loss improved from 15.13312 to 14.13876, saving model to models/bc/shift1/max2016/simple-rnn/3.h5
 - 5s - loss: 14.5394 - out_stats_loss: 5.6799 - out_counts_loss: 1.9958 - out_mean_covariance_loss: 73.1089 - out_fielding_position_loss: 3.2082 - val_loss: 14.1388 - val_out_stats_loss: 5.6840 - val_out_counts_loss: 1.8610 - val_out_mean_covariance_loss: 72.0034 - val_out_fielding_position_loss: 2.9936
Epoch 5/1000

Epoch 00005: val_loss improved from 14.13876 to 13.57049, saving model to models/bc/shift1/max2016/simple-rnn/3.h5
 - 5s - loss: 13.7274 - out_stats_loss: 5.4759 - out_counts_loss: 1.9261 - out_mean_covariance_loss: 69.5220 - out_fielding_position_loss: 2.8493 - val_loss: 13.5705 - val_out_stats_loss: 5.5995 - val_out_counts_loss: 1.8328 - val_out_mean_covariance_loss: 69.5617 - val_out_fielding_position_loss: 2.6601
Epoch 6/1000

Epoch 00006: val_loss improved from 13.57049 to 13.08219, saving model to models/bc/shift1/max2016/simple-rnn/3.h5
 - 5s - loss: 13.3405 - out_stats_loss: 5.4386 - out_counts_loss: 1.9113 - out_mean_covariance_loss: 68.2933 - out_fielding_position_loss: 2.5760 - val_loss: 13.0822 - val_out_stats_loss: 5.4737 - val_out_counts_loss: 1.7988 - val_out_mean_covariance_loss: 67.9615 - val_out_fielding_position_loss: 2.4116
Epoch 7/1000

Epoch 00007: val_loss improved from 13.08219 to 12.82376, saving model to models/bc/shift1/max2016/simple-rnn/3.h5
 - 5s - loss: 12.9461 - out_stats_loss: 5.3344 - out_counts_loss: 1.8830 - out_mean_covariance_loss: 66.7293 - out_fielding_position_loss: 2.3923 - val_loss: 12.8238 - val_out_stats_loss: 5.4230 - val_out_counts_loss: 1.8104 - val_out_mean_covariance_loss: 67.0183 - val_out_fielding_position_loss: 2.2394
Epoch 8/1000

Epoch 00008: val_loss improved from 12.82376 to 12.58451, saving model to models/bc/shift1/max2016/simple-rnn/3.h5
 - 5s - loss: 12.6640 - out_stats_loss: 5.2719 - out_counts_loss: 1.8548 - out_mean_covariance_loss: 65.8086 - out_fielding_position_loss: 2.2469 - val_loss: 12.5845 - val_out_stats_loss: 5.3595 - val_out_counts_loss: 1.7843 - val_out_mean_covariance_loss: 66.0750 - val_out_fielding_position_loss: 2.1370
Epoch 9/1000

Epoch 00009: val_loss improved from 12.58451 to 12.45516, saving model to models/bc/shift1/max2016/simple-rnn/3.h5
 - 5s - loss: 12.4996 - out_stats_loss: 5.2416 - out_counts_loss: 1.8593 - out_mean_covariance_loss: 64.9048 - out_fielding_position_loss: 2.1535 - val_loss: 12.4552 - val_out_stats_loss: 5.3306 - val_out_counts_loss: 1.7833 - val_out_mean_covariance_loss: 65.6495 - val_out_fielding_position_loss: 2.0588
Epoch 10/1000

Epoch 00010: val_loss improved from 12.45516 to 12.29646, saving model to models/bc/shift1/max2016/simple-rnn/3.h5
 - 5s - loss: 12.2600 - out_stats_loss: 5.1416 - out_counts_loss: 1.8400 - out_mean_covariance_loss: 63.7005 - out_fielding_position_loss: 2.0934 - val_loss: 12.2965 - val_out_stats_loss: 5.2683 - val_out_counts_loss: 1.7790 - val_out_mean_covariance_loss: 64.9241 - val_out_fielding_position_loss: 2.0030
Epoch 11/1000

Epoch 00011: val_loss improved from 12.29646 to 12.21798, saving model to models/bc/shift1/max2016/simple-rnn/3.h5
 - 5s - loss: 12.1648 - out_stats_loss: 5.1131 - out_counts_loss: 1.8335 - out_mean_covariance_loss: 63.2906 - out_fielding_position_loss: 2.0536 - val_loss: 12.2180 - val_out_stats_loss: 5.2449 - val_out_counts_loss: 1.7846 - val_out_mean_covariance_loss: 64.4027 - val_out_fielding_position_loss: 1.9684
Epoch 12/1000

Epoch 00012: val_loss improved from 12.21798 to 12.12176, saving model to models/bc/shift1/max2016/simple-rnn/3.h5
 - 5s - loss: 12.1267 - out_stats_loss: 5.1266 - out_counts_loss: 1.8223 - out_mean_covariance_loss: 63.4256 - out_fielding_position_loss: 2.0065 - val_loss: 12.1218 - val_out_stats_loss: 5.2105 - val_out_counts_loss: 1.7665 - val_out_mean_covariance_loss: 64.0212 - val_out_fielding_position_loss: 1.9438
Epoch 13/1000

Epoch 00013: val_loss improved from 12.12176 to 12.04294, saving model to models/bc/shift1/max2016/simple-rnn/3.h5
 - 5s - loss: 11.9632 - out_stats_loss: 5.0503 - out_counts_loss: 1.8055 - out_mean_covariance_loss: 62.3769 - out_fielding_position_loss: 1.9885 - val_loss: 12.0429 - val_out_stats_loss: 5.1760 - val_out_counts_loss: 1.7557 - val_out_mean_covariance_loss: 63.6393 - val_out_fielding_position_loss: 1.9293
Epoch 14/1000

Epoch 00014: val_loss improved from 12.04294 to 11.99120, saving model to models/bc/shift1/max2016/simple-rnn/3.h5
 - 5s - loss: 11.8702 - out_stats_loss: 5.0215 - out_counts_loss: 1.7973 - out_mean_covariance_loss: 61.9522 - out_fielding_position_loss: 1.9539 - val_loss: 11.9912 - val_out_stats_loss: 5.1595 - val_out_counts_loss: 1.7533 - val_out_mean_covariance_loss: 63.3820 - val_out_fielding_position_loss: 1.9092
Epoch 15/1000

Epoch 00015: val_loss improved from 11.99120 to 11.92989, saving model to models/bc/shift1/max2016/simple-rnn/3.h5
 - 5s - loss: 11.8585 - out_stats_loss: 5.0076 - out_counts_loss: 1.7994 - out_mean_covariance_loss: 61.8663 - out_fielding_position_loss: 1.9582 - val_loss: 11.9299 - val_out_stats_loss: 5.1281 - val_out_counts_loss: 1.7479 - val_out_mean_covariance_loss: 63.1011 - val_out_fielding_position_loss: 1.8988
Epoch 16/1000

Epoch 00016: val_loss improved from 11.92989 to 11.91394, saving model to models/bc/shift1/max2016/simple-rnn/3.h5
 - 5s - loss: 11.7204 - out_stats_loss: 4.9552 - out_counts_loss: 1.7790 - out_mean_covariance_loss: 61.1102 - out_fielding_position_loss: 1.9307 - val_loss: 11.9139 - val_out_stats_loss: 5.1192 - val_out_counts_loss: 1.7610 - val_out_mean_covariance_loss: 62.9341 - val_out_fielding_position_loss: 1.8871
Epoch 17/1000

Epoch 00017: val_loss improved from 11.91394 to 11.86966, saving model to models/bc/shift1/max2016/simple-rnn/3.h5
 - 5s - loss: 11.6892 - out_stats_loss: 4.9390 - out_counts_loss: 1.7738 - out_mean_covariance_loss: 60.9676 - out_fielding_position_loss: 1.9279 - val_loss: 11.8697 - val_out_stats_loss: 5.1102 - val_out_counts_loss: 1.7461 - val_out_mean_covariance_loss: 62.6905 - val_out_fielding_position_loss: 1.8788
Epoch 18/1000

Epoch 00018: val_loss improved from 11.86966 to 11.83298, saving model to models/bc/shift1/max2016/simple-rnn/3.h5
 - 5s - loss: 11.6625 - out_stats_loss: 4.9431 - out_counts_loss: 1.7701 - out_mean_covariance_loss: 60.8579 - out_fielding_position_loss: 1.9064 - val_loss: 11.8330 - val_out_stats_loss: 5.0986 - val_out_counts_loss: 1.7420 - val_out_mean_covariance_loss: 62.3449 - val_out_fielding_position_loss: 1.8752
Epoch 19/1000

Epoch 00019: val_loss did not improve
 - 5s - loss: 11.6530 - out_stats_loss: 4.9493 - out_counts_loss: 1.7561 - out_mean_covariance_loss: 61.0270 - out_fielding_position_loss: 1.8963 - val_loss: 11.9005 - val_out_stats_loss: 5.1396 - val_out_counts_loss: 1.7685 - val_out_mean_covariance_loss: 62.5322 - val_out_fielding_position_loss: 1.8657
Epoch 20/1000

Epoch 00020: val_loss improved from 11.83298 to 11.76334, saving model to models/bc/shift1/max2016/simple-rnn/3.h5
 - 5s - loss: 11.5521 - out_stats_loss: 4.8986 - out_counts_loss: 1.7522 - out_mean_covariance_loss: 60.3579 - out_fielding_position_loss: 1.8834 - val_loss: 11.7633 - val_out_stats_loss: 5.0700 - val_out_counts_loss: 1.7365 - val_out_mean_covariance_loss: 62.0256 - val_out_fielding_position_loss: 1.8555
Epoch 21/1000

Epoch 00021: val_loss improved from 11.76334 to 11.75152, saving model to models/bc/shift1/max2016/simple-rnn/3.h5
 - 5s - loss: 11.5122 - out_stats_loss: 4.8855 - out_counts_loss: 1.7356 - out_mean_covariance_loss: 60.1640 - out_fielding_position_loss: 1.8829 - val_loss: 11.7515 - val_out_stats_loss: 5.0662 - val_out_counts_loss: 1.7368 - val_out_mean_covariance_loss: 61.9046 - val_out_fielding_position_loss: 1.8533
Epoch 22/1000

Epoch 00022: val_loss did not improve
 - 5s - loss: 11.4484 - out_stats_loss: 4.8703 - out_counts_loss: 1.7377 - out_mean_covariance_loss: 59.7011 - out_fielding_position_loss: 1.8553 - val_loss: 11.7536 - val_out_stats_loss: 5.0809 - val_out_counts_loss: 1.7321 - val_out_mean_covariance_loss: 61.8926 - val_out_fielding_position_loss: 1.8461
Epoch 23/1000

Epoch 00023: val_loss improved from 11.75152 to 11.71247, saving model to models/bc/shift1/max2016/simple-rnn/3.h5
 - 5s - loss: 11.4396 - out_stats_loss: 4.8694 - out_counts_loss: 1.7318 - out_mean_covariance_loss: 59.7538 - out_fielding_position_loss: 1.8508 - val_loss: 11.7125 - val_out_stats_loss: 5.0542 - val_out_counts_loss: 1.7312 - val_out_mean_covariance_loss: 61.6688 - val_out_fielding_position_loss: 1.8436
Epoch 24/1000

Epoch 00024: val_loss improved from 11.71247 to 11.70670, saving model to models/bc/shift1/max2016/simple-rnn/3.h5
 - 5s - loss: 11.4492 - out_stats_loss: 4.8821 - out_counts_loss: 1.7314 - out_mean_covariance_loss: 59.8177 - out_fielding_position_loss: 1.8449 - val_loss: 11.7067 - val_out_stats_loss: 5.0575 - val_out_counts_loss: 1.7334 - val_out_mean_covariance_loss: 61.5855 - val_out_fielding_position_loss: 1.8366
Epoch 25/1000

Epoch 00025: val_loss improved from 11.70670 to 11.67795, saving model to models/bc/shift1/max2016/simple-rnn/3.h5
 - 5s - loss: 11.3782 - out_stats_loss: 4.8483 - out_counts_loss: 1.7209 - out_mean_covariance_loss: 59.4673 - out_fielding_position_loss: 1.8357 - val_loss: 11.6780 - val_out_stats_loss: 5.0411 - val_out_counts_loss: 1.7345 - val_out_mean_covariance_loss: 61.3927 - val_out_fielding_position_loss: 1.8327
Epoch 26/1000

Epoch 00026: val_loss improved from 11.67795 to 11.67099, saving model to models/bc/shift1/max2016/simple-rnn/3.h5
 - 5s - loss: 11.3464 - out_stats_loss: 4.8460 - out_counts_loss: 1.7136 - out_mean_covariance_loss: 59.2752 - out_fielding_position_loss: 1.8231 - val_loss: 11.6710 - val_out_stats_loss: 5.0455 - val_out_counts_loss: 1.7323 - val_out_mean_covariance_loss: 61.4024 - val_out_fielding_position_loss: 1.8231
Epoch 27/1000

Epoch 00027: val_loss improved from 11.67099 to 11.63636, saving model to models/bc/shift1/max2016/simple-rnn/3.h5
 - 5s - loss: 11.3014 - out_stats_loss: 4.8308 - out_counts_loss: 1.7108 - out_mean_covariance_loss: 58.9863 - out_fielding_position_loss: 1.8106 - val_loss: 11.6364 - val_out_stats_loss: 5.0244 - val_out_counts_loss: 1.7310 - val_out_mean_covariance_loss: 61.2230 - val_out_fielding_position_loss: 1.8198
Epoch 28/1000

Epoch 00028: val_loss did not improve
 - 5s - loss: 11.2898 - out_stats_loss: 4.8217 - out_counts_loss: 1.6933 - out_mean_covariance_loss: 59.2187 - out_fielding_position_loss: 1.8139 - val_loss: 11.6413 - val_out_stats_loss: 5.0314 - val_out_counts_loss: 1.7336 - val_out_mean_covariance_loss: 61.1770 - val_out_fielding_position_loss: 1.8174
Epoch 29/1000

Epoch 00029: val_loss improved from 11.63636 to 11.63598, saving model to models/bc/shift1/max2016/simple-rnn/3.h5
 - 5s - loss: 11.2213 - out_stats_loss: 4.7935 - out_counts_loss: 1.6878 - out_mean_covariance_loss: 58.8184 - out_fielding_position_loss: 1.7991 - val_loss: 11.6360 - val_out_stats_loss: 5.0359 - val_out_counts_loss: 1.7355 - val_out_mean_covariance_loss: 61.0599 - val_out_fielding_position_loss: 1.8116
Epoch 30/1000

Epoch 00030: val_loss improved from 11.63598 to 11.59608, saving model to models/bc/shift1/max2016/simple-rnn/3.h5
 - 5s - loss: 11.1689 - out_stats_loss: 4.7826 - out_counts_loss: 1.6841 - out_mean_covariance_loss: 58.4010 - out_fielding_position_loss: 1.7821 - val_loss: 11.5961 - val_out_stats_loss: 5.0114 - val_out_counts_loss: 1.7303 - val_out_mean_covariance_loss: 60.8473 - val_out_fielding_position_loss: 1.8120
Epoch 31/1000

Epoch 00031: val_loss did not improve
 - 5s - loss: 11.1823 - out_stats_loss: 4.8043 - out_counts_loss: 1.6791 - out_mean_covariance_loss: 58.5647 - out_fielding_position_loss: 1.7707 - val_loss: 11.6345 - val_out_stats_loss: 5.0332 - val_out_counts_loss: 1.7467 - val_out_mean_covariance_loss: 60.9723 - val_out_fielding_position_loss: 1.8060
Epoch 32/1000

Epoch 00032: val_loss did not improve
 - 5s - loss: 11.1712 - out_stats_loss: 4.7871 - out_counts_loss: 1.6690 - out_mean_covariance_loss: 58.8197 - out_fielding_position_loss: 1.7740 - val_loss: 11.6313 - val_out_stats_loss: 5.0213 - val_out_counts_loss: 1.7636 - val_out_mean_covariance_loss: 60.8095 - val_out_fielding_position_loss: 1.8060
Epoch 33/1000

Epoch 00033: val_loss improved from 11.59608 to 11.58232, saving model to models/bc/shift1/max2016/simple-rnn/3.h5
 - 5s - loss: 11.0694 - out_stats_loss: 4.7435 - out_counts_loss: 1.6642 - out_mean_covariance_loss: 57.9262 - out_fielding_position_loss: 1.7654 - val_loss: 11.5823 - val_out_stats_loss: 5.0102 - val_out_counts_loss: 1.7375 - val_out_mean_covariance_loss: 60.6730 - val_out_fielding_position_loss: 1.8011
Epoch 34/1000

Epoch 00034: val_loss improved from 11.58232 to 11.56716, saving model to models/bc/shift1/max2016/simple-rnn/3.h5
 - 5s - loss: 11.0755 - out_stats_loss: 4.7557 - out_counts_loss: 1.6452 - out_mean_covariance_loss: 58.0967 - out_fielding_position_loss: 1.7698 - val_loss: 11.5672 - val_out_stats_loss: 5.0087 - val_out_counts_loss: 1.7322 - val_out_mean_covariance_loss: 60.6411 - val_out_fielding_position_loss: 1.7942
Epoch 35/1000

Epoch 00035: val_loss improved from 11.56716 to 11.54226, saving model to models/bc/shift1/max2016/simple-rnn/3.h5
 - 5s - loss: 11.0338 - out_stats_loss: 4.7375 - out_counts_loss: 1.6417 - out_mean_covariance_loss: 57.9804 - out_fielding_position_loss: 1.7556 - val_loss: 11.5423 - val_out_stats_loss: 4.9996 - val_out_counts_loss: 1.7279 - val_out_mean_covariance_loss: 60.4844 - val_out_fielding_position_loss: 1.7905
Epoch 36/1000

Epoch 00036: val_loss did not improve
 - 5s - loss: 11.0313 - out_stats_loss: 4.7432 - out_counts_loss: 1.6542 - out_mean_covariance_loss: 57.5829 - out_fielding_position_loss: 1.7547 - val_loss: 11.5938 - val_out_stats_loss: 5.0173 - val_out_counts_loss: 1.7617 - val_out_mean_covariance_loss: 60.5418 - val_out_fielding_position_loss: 1.7877
Epoch 37/1000

Epoch 00037: val_loss did not improve
 - 5s - loss: 10.9638 - out_stats_loss: 4.7189 - out_counts_loss: 1.6373 - out_mean_covariance_loss: 57.3617 - out_fielding_position_loss: 1.7395 - val_loss: 11.5626 - val_out_stats_loss: 5.0084 - val_out_counts_loss: 1.7445 - val_out_mean_covariance_loss: 60.5072 - val_out_fielding_position_loss: 1.7844
Epoch 38/1000

Epoch 00038: val_loss improved from 11.54226 to 11.52961, saving model to models/bc/shift1/max2016/simple-rnn/3.h5
 - 5s - loss: 10.9411 - out_stats_loss: 4.7042 - out_counts_loss: 1.6317 - out_mean_covariance_loss: 57.4078 - out_fielding_position_loss: 1.7348 - val_loss: 11.5296 - val_out_stats_loss: 4.9950 - val_out_counts_loss: 1.7365 - val_out_mean_covariance_loss: 60.2885 - val_out_fielding_position_loss: 1.7837
Epoch 39/1000

Epoch 00039: val_loss did not improve
 - 5s - loss: 10.9320 - out_stats_loss: 4.7158 - out_counts_loss: 1.6210 - out_mean_covariance_loss: 57.4412 - out_fielding_position_loss: 1.7231 - val_loss: 11.5574 - val_out_stats_loss: 4.9981 - val_out_counts_loss: 1.7590 - val_out_mean_covariance_loss: 60.4319 - val_out_fielding_position_loss: 1.7788
Epoch 40/1000

Epoch 00040: val_loss improved from 11.52961 to 11.51842, saving model to models/bc/shift1/max2016/simple-rnn/3.h5
 - 5s - loss: 10.8836 - out_stats_loss: 4.7023 - out_counts_loss: 1.6063 - out_mean_covariance_loss: 57.1913 - out_fielding_position_loss: 1.7153 - val_loss: 11.5184 - val_out_stats_loss: 4.9933 - val_out_counts_loss: 1.7387 - val_out_mean_covariance_loss: 60.2076 - val_out_fielding_position_loss: 1.7761
Epoch 41/1000

Epoch 00041: val_loss did not improve
 - 5s - loss: 10.9421 - out_stats_loss: 4.7308 - out_counts_loss: 1.6277 - out_mean_covariance_loss: 57.5343 - out_fielding_position_loss: 1.7068 - val_loss: 11.5270 - val_out_stats_loss: 4.9921 - val_out_counts_loss: 1.7435 - val_out_mean_covariance_loss: 60.2723 - val_out_fielding_position_loss: 1.7778
Epoch 42/1000

Epoch 00042: val_loss improved from 11.51842 to 11.49960, saving model to models/bc/shift1/max2016/simple-rnn/3.h5
 - 5s - loss: 10.8266 - out_stats_loss: 4.6899 - out_counts_loss: 1.5943 - out_mean_covariance_loss: 57.0427 - out_fielding_position_loss: 1.6904 - val_loss: 11.4996 - val_out_stats_loss: 4.9872 - val_out_counts_loss: 1.7392 - val_out_mean_covariance_loss: 60.0934 - val_out_fielding_position_loss: 1.7685
Epoch 43/1000

Epoch 00043: val_loss did not improve
 - 5s - loss: 10.8756 - out_stats_loss: 4.7093 - out_counts_loss: 1.6093 - out_mean_covariance_loss: 57.1257 - out_fielding_position_loss: 1.7007 - val_loss: 11.5416 - val_out_stats_loss: 5.0150 - val_out_counts_loss: 1.7519 - val_out_mean_covariance_loss: 60.1948 - val_out_fielding_position_loss: 1.7651
Epoch 44/1000

Epoch 00044: val_loss did not improve
 - 5s - loss: 10.7567 - out_stats_loss: 4.6565 - out_counts_loss: 1.5863 - out_mean_covariance_loss: 56.5266 - out_fielding_position_loss: 1.6877 - val_loss: 11.5173 - val_out_stats_loss: 4.9883 - val_out_counts_loss: 1.7593 - val_out_mean_covariance_loss: 60.0898 - val_out_fielding_position_loss: 1.7652
Epoch 45/1000

Epoch 00045: val_loss did not improve
 - 5s - loss: 10.6913 - out_stats_loss: 4.6356 - out_counts_loss: 1.5742 - out_mean_covariance_loss: 56.2998 - out_fielding_position_loss: 1.6665 - val_loss: 11.5096 - val_out_stats_loss: 4.9880 - val_out_counts_loss: 1.7596 - val_out_mean_covariance_loss: 60.0042 - val_out_fielding_position_loss: 1.7618
Epoch 46/1000

Epoch 00046: val_loss improved from 11.49960 to 11.49805, saving model to models/bc/shift1/max2016/simple-rnn/3.h5
 - 5s - loss: 10.7427 - out_stats_loss: 4.6681 - out_counts_loss: 1.5723 - out_mean_covariance_loss: 56.5105 - out_fielding_position_loss: 1.6768 - val_loss: 11.4981 - val_out_stats_loss: 4.9836 - val_out_counts_loss: 1.7581 - val_out_mean_covariance_loss: 60.0039 - val_out_fielding_position_loss: 1.7562
Epoch 47/1000

Epoch 00047: val_loss improved from 11.49805 to 11.47469, saving model to models/bc/shift1/max2016/simple-rnn/3.h5
 - 5s - loss: 10.7161 - out_stats_loss: 4.6640 - out_counts_loss: 1.5637 - out_mean_covariance_loss: 56.4686 - out_fielding_position_loss: 1.6650 - val_loss: 11.4747 - val_out_stats_loss: 4.9792 - val_out_counts_loss: 1.7502 - val_out_mean_covariance_loss: 59.8468 - val_out_fielding_position_loss: 1.7530
Epoch 48/1000

Epoch 00048: val_loss did not improve
 - 5s - loss: 10.6762 - out_stats_loss: 4.6561 - out_counts_loss: 1.5504 - out_mean_covariance_loss: 56.3272 - out_fielding_position_loss: 1.6534 - val_loss: 11.4914 - val_out_stats_loss: 4.9883 - val_out_counts_loss: 1.7606 - val_out_mean_covariance_loss: 59.8615 - val_out_fielding_position_loss: 1.7494
Epoch 49/1000

Epoch 00049: val_loss did not improve
 - 5s - loss: 10.6370 - out_stats_loss: 4.6294 - out_counts_loss: 1.5519 - out_mean_covariance_loss: 56.0265 - out_fielding_position_loss: 1.6543 - val_loss: 11.5128 - val_out_stats_loss: 5.0009 - val_out_counts_loss: 1.7677 - val_out_mean_covariance_loss: 59.8731 - val_out_fielding_position_loss: 1.7506
Epoch 50/1000

Epoch 00050: val_loss did not improve
 - 5s - loss: 10.6270 - out_stats_loss: 4.6363 - out_counts_loss: 1.5432 - out_mean_covariance_loss: 56.2163 - out_fielding_position_loss: 1.6366 - val_loss: 11.5034 - val_out_stats_loss: 4.9950 - val_out_counts_loss: 1.7748 - val_out_mean_covariance_loss: 59.7669 - val_out_fielding_position_loss: 1.7452
Epoch 51/1000

Epoch 00051: val_loss did not improve
 - 5s - loss: 10.5879 - out_stats_loss: 4.6184 - out_counts_loss: 1.5357 - out_mean_covariance_loss: 56.0449 - out_fielding_position_loss: 1.6316 - val_loss: 11.5098 - val_out_stats_loss: 5.0037 - val_out_counts_loss: 1.7683 - val_out_mean_covariance_loss: 59.9573 - val_out_fielding_position_loss: 1.7400
Epoch 52/1000

Epoch 00052: val_loss did not improve
 - 5s - loss: 10.5815 - out_stats_loss: 4.6099 - out_counts_loss: 1.5383 - out_mean_covariance_loss: 55.8652 - out_fielding_position_loss: 1.6400 - val_loss: 11.4916 - val_out_stats_loss: 5.0021 - val_out_counts_loss: 1.7638 - val_out_mean_covariance_loss: 59.7498 - val_out_fielding_position_loss: 1.7381
Epoch 53/1000

Epoch 00053: val_loss did not improve
 - 5s - loss: 10.5674 - out_stats_loss: 4.6206 - out_counts_loss: 1.5412 - out_mean_covariance_loss: 55.6733 - out_fielding_position_loss: 1.6221 - val_loss: 11.5443 - val_out_stats_loss: 5.0132 - val_out_counts_loss: 1.8019 - val_out_mean_covariance_loss: 59.7816 - val_out_fielding_position_loss: 1.7401
Epoch 54/1000

Epoch 00054: val_loss did not improve
 - 5s - loss: 10.4807 - out_stats_loss: 4.5853 - out_counts_loss: 1.5171 - out_mean_covariance_loss: 55.1721 - out_fielding_position_loss: 1.6197 - val_loss: 11.5343 - val_out_stats_loss: 5.0106 - val_out_counts_loss: 1.7984 - val_out_mean_covariance_loss: 59.7152 - val_out_fielding_position_loss: 1.7396
Epoch 55/1000

Epoch 00055: val_loss did not improve
 - 5s - loss: 10.5091 - out_stats_loss: 4.6120 - out_counts_loss: 1.5071 - out_mean_covariance_loss: 55.7079 - out_fielding_position_loss: 1.6047 - val_loss: 11.5456 - val_out_stats_loss: 5.0187 - val_out_counts_loss: 1.8122 - val_out_mean_covariance_loss: 59.6369 - val_out_fielding_position_loss: 1.7329
Epoch 56/1000

Epoch 00056: val_loss did not improve
 - 5s - loss: 10.4571 - out_stats_loss: 4.5798 - out_counts_loss: 1.5133 - out_mean_covariance_loss: 55.2240 - out_fielding_position_loss: 1.6028 - val_loss: 11.4928 - val_out_stats_loss: 4.9970 - val_out_counts_loss: 1.7858 - val_out_mean_covariance_loss: 59.6632 - val_out_fielding_position_loss: 1.7269
Epoch 57/1000

Epoch 00057: val_loss did not improve
 - 5s - loss: 10.5393 - out_stats_loss: 4.6339 - out_counts_loss: 1.5097 - out_mean_covariance_loss: 56.0136 - out_fielding_position_loss: 1.5950 - val_loss: 11.4870 - val_out_stats_loss: 4.9907 - val_out_counts_loss: 1.7931 - val_out_mean_covariance_loss: 59.5009 - val_out_fielding_position_loss: 1.7282
Epoch 58/1000

Epoch 00058: val_loss did not improve
 - 5s - loss: 10.4837 - out_stats_loss: 4.6020 - out_counts_loss: 1.4998 - out_mean_covariance_loss: 55.7958 - out_fielding_position_loss: 1.5921 - val_loss: 11.5178 - val_out_stats_loss: 4.9976 - val_out_counts_loss: 1.8135 - val_out_mean_covariance_loss: 59.6304 - val_out_fielding_position_loss: 1.7253
Epoch 59/1000

Epoch 00059: val_loss did not improve
 - 5s - loss: 10.3840 - out_stats_loss: 4.5567 - out_counts_loss: 1.5013 - out_mean_covariance_loss: 54.8800 - out_fielding_position_loss: 1.5819 - val_loss: 11.5408 - val_out_stats_loss: 5.0144 - val_out_counts_loss: 1.8133 - val_out_mean_covariance_loss: 59.6485 - val_out_fielding_position_loss: 1.7306
Epoch 60/1000

Epoch 00060: val_loss did not improve
 - 5s - loss: 10.3787 - out_stats_loss: 4.5662 - out_counts_loss: 1.4902 - out_mean_covariance_loss: 54.8846 - out_fielding_position_loss: 1.5780 - val_loss: 11.4812 - val_out_stats_loss: 4.9918 - val_out_counts_loss: 1.7972 - val_out_mean_covariance_loss: 59.4418 - val_out_fielding_position_loss: 1.7201
Epoch 61/1000

Epoch 00061: val_loss did not improve
 - 5s - loss: 10.4047 - out_stats_loss: 4.5854 - out_counts_loss: 1.4809 - out_mean_covariance_loss: 55.1680 - out_fielding_position_loss: 1.5801 - val_loss: 11.5027 - val_out_stats_loss: 4.9893 - val_out_counts_loss: 1.8189 - val_out_mean_covariance_loss: 59.4744 - val_out_fielding_position_loss: 1.7208
Epoch 62/1000

Epoch 00062: val_loss did not improve
 - 5s - loss: 10.3643 - out_stats_loss: 4.5708 - out_counts_loss: 1.4790 - out_mean_covariance_loss: 55.0082 - out_fielding_position_loss: 1.5641 - val_loss: 11.4850 - val_out_stats_loss: 4.9943 - val_out_counts_loss: 1.8079 - val_out_mean_covariance_loss: 59.3549 - val_out_fielding_position_loss: 1.7150
Epoch 63/1000

Epoch 00063: val_loss did not improve
 - 5s - loss: 10.3222 - out_stats_loss: 4.5468 - out_counts_loss: 1.4778 - out_mean_covariance_loss: 54.5822 - out_fielding_position_loss: 1.5684 - val_loss: 11.4944 - val_out_stats_loss: 4.9950 - val_out_counts_loss: 1.8165 - val_out_mean_covariance_loss: 59.3981 - val_out_fielding_position_loss: 1.7130
Epoch 64/1000

Epoch 00064: val_loss did not improve
 - 5s - loss: 10.2880 - out_stats_loss: 4.5412 - out_counts_loss: 1.4634 - out_mean_covariance_loss: 54.4626 - out_fielding_position_loss: 1.5603 - val_loss: 11.4879 - val_out_stats_loss: 4.9956 - val_out_counts_loss: 1.8130 - val_out_mean_covariance_loss: 59.4044 - val_out_fielding_position_loss: 1.7090
Epoch 65/1000

Epoch 00065: val_loss did not improve
 - 5s - loss: 10.2934 - out_stats_loss: 4.5494 - out_counts_loss: 1.4545 - out_mean_covariance_loss: 54.5885 - out_fielding_position_loss: 1.5601 - val_loss: 11.5210 - val_out_stats_loss: 5.0156 - val_out_counts_loss: 1.8293 - val_out_mean_covariance_loss: 59.4384 - val_out_fielding_position_loss: 1.7043
Epoch 66/1000

Epoch 00066: val_loss did not improve
 - 5s - loss: 10.3097 - out_stats_loss: 4.5612 - out_counts_loss: 1.4546 - out_mean_covariance_loss: 54.7324 - out_fielding_position_loss: 1.5573 - val_loss: 11.5218 - val_out_stats_loss: 5.0056 - val_out_counts_loss: 1.8362 - val_out_mean_covariance_loss: 59.3348 - val_out_fielding_position_loss: 1.7132
Epoch 67/1000

Epoch 00067: val_loss did not improve
 - 5s - loss: 10.2170 - out_stats_loss: 4.5248 - out_counts_loss: 1.4500 - out_mean_covariance_loss: 54.0556 - out_fielding_position_loss: 1.5395 - val_loss: 11.5500 - val_out_stats_loss: 5.0066 - val_out_counts_loss: 1.8570 - val_out_mean_covariance_loss: 59.4740 - val_out_fielding_position_loss: 1.7127
Epoch 68/1000

Epoch 00068: val_loss did not improve
 - 5s - loss: 10.1754 - out_stats_loss: 4.5019 - out_counts_loss: 1.4459 - out_mean_covariance_loss: 53.7456 - out_fielding_position_loss: 1.5403 - val_loss: 11.5130 - val_out_stats_loss: 5.0053 - val_out_counts_loss: 1.8387 - val_out_mean_covariance_loss: 59.3086 - val_out_fielding_position_loss: 1.7035
Epoch 69/1000

Epoch 00069: val_loss did not improve
 - 5s - loss: 10.1891 - out_stats_loss: 4.5281 - out_counts_loss: 1.4318 - out_mean_covariance_loss: 54.0171 - out_fielding_position_loss: 1.5283 - val_loss: 11.6299 - val_out_stats_loss: 5.0717 - val_out_counts_loss: 1.8752 - val_out_mean_covariance_loss: 59.5747 - val_out_fielding_position_loss: 1.7043
Epoch 70/1000

Epoch 00070: val_loss did not improve
 - 5s - loss: 10.1644 - out_stats_loss: 4.5165 - out_counts_loss: 1.4311 - out_mean_covariance_loss: 53.8256 - out_fielding_position_loss: 1.5256 - val_loss: 11.5631 - val_out_stats_loss: 5.0220 - val_out_counts_loss: 1.8677 - val_out_mean_covariance_loss: 59.4189 - val_out_fielding_position_loss: 1.7024
Epoch 71/1000

Epoch 00071: val_loss did not improve
 - 5s - loss: 10.1248 - out_stats_loss: 4.4971 - out_counts_loss: 1.4262 - out_mean_covariance_loss: 53.6484 - out_fielding_position_loss: 1.5190 - val_loss: 11.5290 - val_out_stats_loss: 5.0041 - val_out_counts_loss: 1.8560 - val_out_mean_covariance_loss: 59.3393 - val_out_fielding_position_loss: 1.7019
Epoch 72/1000

Epoch 00072: val_loss did not improve
 - 5s - loss: 10.1298 - out_stats_loss: 4.4971 - out_counts_loss: 1.4214 - out_mean_covariance_loss: 53.7096 - out_fielding_position_loss: 1.5258 - val_loss: 11.5618 - val_out_stats_loss: 5.0206 - val_out_counts_loss: 1.8766 - val_out_mean_covariance_loss: 59.2200 - val_out_fielding_position_loss: 1.7036
Epoch 73/1000

Epoch 00073: val_loss did not improve
 - 5s - loss: 10.0893 - out_stats_loss: 4.4995 - out_counts_loss: 1.4058 - out_mean_covariance_loss: 53.5117 - out_fielding_position_loss: 1.5085 - val_loss: 11.6655 - val_out_stats_loss: 5.0498 - val_out_counts_loss: 1.9344 - val_out_mean_covariance_loss: 59.4006 - val_out_fielding_position_loss: 1.7112
Epoch 74/1000

Epoch 00074: val_loss did not improve
 - 5s - loss: 10.0830 - out_stats_loss: 4.4810 - out_counts_loss: 1.4127 - out_mean_covariance_loss: 53.4879 - out_fielding_position_loss: 1.5149 - val_loss: 11.5332 - val_out_stats_loss: 5.0017 - val_out_counts_loss: 1.8715 - val_out_mean_covariance_loss: 59.2898 - val_out_fielding_position_loss: 1.6955
Epoch 75/1000

Epoch 00075: val_loss did not improve
 - 5s - loss: 10.0649 - out_stats_loss: 4.4769 - out_counts_loss: 1.4069 - out_mean_covariance_loss: 53.3930 - out_fielding_position_loss: 1.5116 - val_loss: 11.5387 - val_out_stats_loss: 5.0043 - val_out_counts_loss: 1.8673 - val_out_mean_covariance_loss: 59.4002 - val_out_fielding_position_loss: 1.6971
Epoch 76/1000

Epoch 00076: val_loss did not improve
 - 5s - loss: 10.0502 - out_stats_loss: 4.4752 - out_counts_loss: 1.4025 - out_mean_covariance_loss: 53.3911 - out_fielding_position_loss: 1.5029 - val_loss: 11.5267 - val_out_stats_loss: 5.0077 - val_out_counts_loss: 1.8638 - val_out_mean_covariance_loss: 59.3369 - val_out_fielding_position_loss: 1.6884
Epoch 77/1000

Epoch 00077: val_loss did not improve
 - 5s - loss: 9.9809 - out_stats_loss: 4.4547 - out_counts_loss: 1.3842 - out_mean_covariance_loss: 52.9637 - out_fielding_position_loss: 1.4938 - val_loss: 11.5518 - val_out_stats_loss: 5.0093 - val_out_counts_loss: 1.8848 - val_out_mean_covariance_loss: 59.3137 - val_out_fielding_position_loss: 1.6920
Epoch 78/1000

Epoch 00078: val_loss did not improve
 - 5s - loss: 9.9962 - out_stats_loss: 4.4549 - out_counts_loss: 1.4030 - out_mean_covariance_loss: 53.0029 - out_fielding_position_loss: 1.4881 - val_loss: 11.5645 - val_out_stats_loss: 5.0131 - val_out_counts_loss: 1.8910 - val_out_mean_covariance_loss: 59.3441 - val_out_fielding_position_loss: 1.6933
Epoch 79/1000

Epoch 00079: val_loss did not improve
 - 5s - loss: 9.9791 - out_stats_loss: 4.4636 - out_counts_loss: 1.3752 - out_mean_covariance_loss: 53.1690 - out_fielding_position_loss: 1.4819 - val_loss: 11.5677 - val_out_stats_loss: 5.0228 - val_out_counts_loss: 1.8944 - val_out_mean_covariance_loss: 59.2615 - val_out_fielding_position_loss: 1.6873
Epoch 80/1000

Epoch 00080: val_loss did not improve
 - 5s - loss: 9.9906 - out_stats_loss: 4.4708 - out_counts_loss: 1.3826 - out_mean_covariance_loss: 53.1993 - out_fielding_position_loss: 1.4773 - val_loss: 11.5915 - val_out_stats_loss: 5.0275 - val_out_counts_loss: 1.9089 - val_out_mean_covariance_loss: 59.3022 - val_out_fielding_position_loss: 1.6900
Epoch 81/1000

Epoch 00081: val_loss did not improve
 - 5s - loss: 9.9275 - out_stats_loss: 4.4420 - out_counts_loss: 1.3691 - out_mean_covariance_loss: 52.7910 - out_fielding_position_loss: 1.4769 - val_loss: 11.6292 - val_out_stats_loss: 5.0345 - val_out_counts_loss: 1.9272 - val_out_mean_covariance_loss: 59.4237 - val_out_fielding_position_loss: 1.6963
Epoch 82/1000

Epoch 00082: val_loss did not improve
 - 4s - loss: 9.9618 - out_stats_loss: 4.4577 - out_counts_loss: 1.3720 - out_mean_covariance_loss: 53.0637 - out_fielding_position_loss: 1.4789 - val_loss: 11.5878 - val_out_stats_loss: 5.0182 - val_out_counts_loss: 1.9184 - val_out_mean_covariance_loss: 59.2705 - val_out_fielding_position_loss: 1.6876
Epoch 83/1000

Epoch 00083: val_loss did not improve
 - 5s - loss: 9.9036 - out_stats_loss: 4.4347 - out_counts_loss: 1.3679 - out_mean_covariance_loss: 52.6813 - out_fielding_position_loss: 1.4669 - val_loss: 11.6237 - val_out_stats_loss: 5.0521 - val_out_counts_loss: 1.9252 - val_out_mean_covariance_loss: 59.2106 - val_out_fielding_position_loss: 1.6859
Epoch 84/1000

Epoch 00084: val_loss did not improve
 - 5s - loss: 9.9158 - out_stats_loss: 4.4500 - out_counts_loss: 1.3594 - out_mean_covariance_loss: 52.7739 - out_fielding_position_loss: 1.4677 - val_loss: 11.5770 - val_out_stats_loss: 5.0195 - val_out_counts_loss: 1.9052 - val_out_mean_covariance_loss: 59.2830 - val_out_fielding_position_loss: 1.6880
Epoch 85/1000

Epoch 00085: val_loss did not improve
 - 5s - loss: 9.8649 - out_stats_loss: 4.4345 - out_counts_loss: 1.3516 - out_mean_covariance_loss: 52.4889 - out_fielding_position_loss: 1.4544 - val_loss: 11.6031 - val_out_stats_loss: 5.0300 - val_out_counts_loss: 1.9245 - val_out_mean_covariance_loss: 59.2563 - val_out_fielding_position_loss: 1.6857
Epoch 86/1000

Epoch 00086: val_loss did not improve
 - 5s - loss: 9.8260 - out_stats_loss: 4.4071 - out_counts_loss: 1.3462 - out_mean_covariance_loss: 52.4420 - out_fielding_position_loss: 1.4506 - val_loss: 11.6199 - val_out_stats_loss: 5.0254 - val_out_counts_loss: 1.9487 - val_out_mean_covariance_loss: 59.3508 - val_out_fielding_position_loss: 1.6782
Epoch 87/1000

Epoch 00087: val_loss did not improve
 - 5s - loss: 9.8265 - out_stats_loss: 4.4168 - out_counts_loss: 1.3396 - out_mean_covariance_loss: 52.3732 - out_fielding_position_loss: 1.4514 - val_loss: 11.7693 - val_out_stats_loss: 5.0929 - val_out_counts_loss: 2.0025 - val_out_mean_covariance_loss: 59.5528 - val_out_fielding_position_loss: 1.6962
Epoch 88/1000

Epoch 00088: val_loss did not improve
 - 5s - loss: 9.8066 - out_stats_loss: 4.4095 - out_counts_loss: 1.3447 - out_mean_covariance_loss: 52.0255 - out_fielding_position_loss: 1.4511 - val_loss: 11.6466 - val_out_stats_loss: 5.0528 - val_out_counts_loss: 1.9416 - val_out_mean_covariance_loss: 59.2911 - val_out_fielding_position_loss: 1.6876
Epoch 89/1000

Epoch 00089: val_loss did not improve
 - 5s - loss: 9.7582 - out_stats_loss: 4.3887 - out_counts_loss: 1.3401 - out_mean_covariance_loss: 51.7794 - out_fielding_position_loss: 1.4404 - val_loss: 11.6286 - val_out_stats_loss: 5.0397 - val_out_counts_loss: 1.9304 - val_out_mean_covariance_loss: 59.5337 - val_out_fielding_position_loss: 1.6818
Epoch 90/1000

Epoch 00090: val_loss did not improve
 - 5s - loss: 9.7935 - out_stats_loss: 4.4124 - out_counts_loss: 1.3225 - out_mean_covariance_loss: 52.4660 - out_fielding_position_loss: 1.4352 - val_loss: 11.7120 - val_out_stats_loss: 5.0680 - val_out_counts_loss: 1.9797 - val_out_mean_covariance_loss: 59.5445 - val_out_fielding_position_loss: 1.6871
Epoch 91/1000

Epoch 00091: val_loss did not improve
 - 5s - loss: 9.7624 - out_stats_loss: 4.3944 - out_counts_loss: 1.3198 - out_mean_covariance_loss: 52.1879 - out_fielding_position_loss: 1.4387 - val_loss: 11.7457 - val_out_stats_loss: 5.0711 - val_out_counts_loss: 1.9966 - val_out_mean_covariance_loss: 59.7106 - val_out_fielding_position_loss: 1.6925
Epoch 92/1000

Epoch 00092: val_loss did not improve
 - 5s - loss: 9.7167 - out_stats_loss: 4.3786 - out_counts_loss: 1.3206 - out_mean_covariance_loss: 51.7178 - out_fielding_position_loss: 1.4317 - val_loss: 11.6515 - val_out_stats_loss: 5.0442 - val_out_counts_loss: 1.9584 - val_out_mean_covariance_loss: 59.4597 - val_out_fielding_position_loss: 1.6759
Epoch 93/1000

Epoch 00093: val_loss did not improve
 - 5s - loss: 9.7006 - out_stats_loss: 4.3745 - out_counts_loss: 1.3163 - out_mean_covariance_loss: 51.7307 - out_fielding_position_loss: 1.4233 - val_loss: 11.6782 - val_out_stats_loss: 5.0590 - val_out_counts_loss: 1.9612 - val_out_mean_covariance_loss: 59.5843 - val_out_fielding_position_loss: 1.6788
Epoch 94/1000

Epoch 00094: val_loss did not improve
 - 5s - loss: 9.7327 - out_stats_loss: 4.3866 - out_counts_loss: 1.3250 - out_mean_covariance_loss: 51.8130 - out_fielding_position_loss: 1.4305 - val_loss: 11.6654 - val_out_stats_loss: 5.0528 - val_out_counts_loss: 1.9638 - val_out_mean_covariance_loss: 59.3725 - val_out_fielding_position_loss: 1.6802
Epoch 95/1000

Epoch 00095: val_loss did not improve
 - 5s - loss: 9.7146 - out_stats_loss: 4.3883 - out_counts_loss: 1.3168 - out_mean_covariance_loss: 51.7949 - out_fielding_position_loss: 1.4197 - val_loss: 11.7839 - val_out_stats_loss: 5.1106 - val_out_counts_loss: 1.9992 - val_out_mean_covariance_loss: 59.8446 - val_out_fielding_position_loss: 1.6819
Epoch 96/1000

Epoch 00096: val_loss did not improve
 - 5s - loss: 9.7368 - out_stats_loss: 4.4065 - out_counts_loss: 1.3108 - out_mean_covariance_loss: 52.0395 - out_fielding_position_loss: 1.4175 - val_loss: 11.6504 - val_out_stats_loss: 5.0470 - val_out_counts_loss: 1.9593 - val_out_mean_covariance_loss: 59.3991 - val_out_fielding_position_loss: 1.6742
Epoch 97/1000

Epoch 00097: val_loss did not improve
 - 5s - loss: 9.6898 - out_stats_loss: 4.3903 - out_counts_loss: 1.2959 - out_mean_covariance_loss: 51.7137 - out_fielding_position_loss: 1.4179 - val_loss: 11.7034 - val_out_stats_loss: 5.0648 - val_out_counts_loss: 1.9855 - val_out_mean_covariance_loss: 59.4702 - val_out_fielding_position_loss: 1.6797
/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Years: [1958,2016]
Shift: 1
Fold: 4
Training into models/bc/shift1/max2016/simple-rnn/3.h5
/usr/local/lib/python3.5/dist-packages/keras/legacy/layers.py:533: UserWarning: The `MaxoutDense` layer is deprecated and will be removed after 06/2017.
  warnings.warn('The `MaxoutDense` layer is deprecated '
