__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
in_age (InputLayer)             (None, None, 2)      0                                            
__________________________________________________________________________________________________
in_bio (InputLayer)             (None, None, 7)      0                                            
__________________________________________________________________________________________________
in_fielding_position (InputLaye (None, None, 2)      0                                            
__________________________________________________________________________________________________
in_out_fielding_position (Input (None, None, 12)     0                                            
__________________________________________________________________________________________________
in_out_league_offense (InputLay (None, None, 9)      0                                            
__________________________________________________________________________________________________
in_out_park_factors (InputLayer (None, None, 8)      0                                            
__________________________________________________________________________________________________
in_out_plate_discipline (InputL (None, None, 8)      0                                            
__________________________________________________________________________________________________
in_out_running (InputLayer)     (None, None, 18)     0                                            
__________________________________________________________________________________________________
in_out_saber (InputLayer)       (None, None, 14)     0                                            
__________________________________________________________________________________________________
in_out_stats_extended (InputLay (None, None, 36)     0                                            
__________________________________________________________________________________________________
in_park_factors (InputLayer)    (None, None, 8)      0                                            
__________________________________________________________________________________________________
masked_in_age (Masking)         (None, None, 2)      0           in_age[0][0]                     
__________________________________________________________________________________________________
masked_in_bio (Masking)         (None, None, 7)      0           in_bio[0][0]                     
__________________________________________________________________________________________________
masked_in_fielding_position (Ma (None, None, 2)      0           in_fielding_position[0][0]       
__________________________________________________________________________________________________
masked_in_out_fielding_position (None, None, 12)     0           in_out_fielding_position[0][0]   
__________________________________________________________________________________________________
masked_in_out_league_offense (M (None, None, 9)      0           in_out_league_offense[0][0]      
__________________________________________________________________________________________________
masked_in_out_park_factors (Mas (None, None, 8)      0           in_out_park_factors[0][0]        
__________________________________________________________________________________________________
masked_in_out_plate_discipline  (None, None, 8)      0           in_out_plate_discipline[0][0]    
__________________________________________________________________________________________________
masked_in_out_running (Masking) (None, None, 18)     0           in_out_running[0][0]             
__________________________________________________________________________________________________
masked_in_out_saber (Masking)   (None, None, 14)     0           in_out_saber[0][0]               
__________________________________________________________________________________________________
masked_in_out_stats_extended (M (None, None, 36)     0           in_out_stats_extended[0][0]      
__________________________________________________________________________________________________
masked_in_park_factors (Masking (None, None, 8)      0           in_park_factors[0][0]            
__________________________________________________________________________________________________
time_distributed_2 (TimeDistrib (None, None, 1)      0           masked_in_age[0][0]              
__________________________________________________________________________________________________
time_distributed_8 (TimeDistrib (None, None, 6)      0           masked_in_bio[0][0]              
__________________________________________________________________________________________________
time_distributed_9 (TimeDistrib (None, None, 1)      0           masked_in_fielding_position[0][0]
__________________________________________________________________________________________________
time_distributed_6 (TimeDistrib (None, None, 11)     0           masked_in_out_fielding_position[0
__________________________________________________________________________________________________
time_distributed_7 (TimeDistrib (None, None, 8)      0           masked_in_out_league_offense[0][0
__________________________________________________________________________________________________
time_distributed_3 (TimeDistrib (None, None, 7)      0           masked_in_out_park_factors[0][0] 
__________________________________________________________________________________________________
time_distributed_10 (TimeDistri (None, None, 7)      0           masked_in_out_plate_discipline[0]
__________________________________________________________________________________________________
time_distributed_5 (TimeDistrib (None, None, 17)     0           masked_in_out_running[0][0]      
__________________________________________________________________________________________________
time_distributed_4 (TimeDistrib (None, None, 13)     0           masked_in_out_saber[0][0]        
__________________________________________________________________________________________________
time_distributed_1 (TimeDistrib (None, None, 35)     0           masked_in_out_stats_extended[0][0
__________________________________________________________________________________________________
time_distributed_11 (TimeDistri (None, None, 7)      0           masked_in_park_factors[0][0]     
__________________________________________________________________________________________________
norm_in_age (BatchNormalization (None, None, 1)      4           time_distributed_2[0][0]         
__________________________________________________________________________________________________
norm_in_bio (BatchNormalization (None, None, 6)      24          time_distributed_8[0][0]         
__________________________________________________________________________________________________
norm_in_fielding_position (Batc (None, None, 1)      4           time_distributed_9[0][0]         
__________________________________________________________________________________________________
norm_in_out_fielding_position ( (None, None, 11)     44          time_distributed_6[0][0]         
__________________________________________________________________________________________________
norm_in_out_league_offense (Bat (None, None, 8)      32          time_distributed_7[0][0]         
__________________________________________________________________________________________________
norm_in_out_park_factors (Batch (None, None, 7)      28          time_distributed_3[0][0]         
__________________________________________________________________________________________________
norm_in_out_plate_discipline (B (None, None, 7)      28          time_distributed_10[0][0]        
__________________________________________________________________________________________________2018-02-06 21:10:12.480921: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-02-06 21:10:19.560981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: eca0:00:00.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2018-02-06 21:10:19.561027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: eca0:00:00.0, compute capability: 3.7)

norm_in_out_running (BatchNorma (None, None, 17)     68          time_distributed_5[0][0]         
__________________________________________________________________________________________________
norm_in_out_saber (BatchNormali (None, None, 13)     52          time_distributed_4[0][0]         
__________________________________________________________________________________________________
norm_in_out_stats_extended (Bat (None, None, 35)     140         time_distributed_1[0][0]         
__________________________________________________________________________________________________
norm_in_park_factors (BatchNorm (None, None, 7)      28          time_distributed_11[0][0]        
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, None, 113)    0           norm_in_age[0][0]                
                                                                 norm_in_bio[0][0]                
                                                                 norm_in_fielding_position[0][0]  
                                                                 norm_in_out_fielding_position[0][
                                                                 norm_in_out_league_offense[0][0] 
                                                                 norm_in_out_park_factors[0][0]   
                                                                 norm_in_out_plate_discipline[0][0
                                                                 norm_in_out_running[0][0]        
                                                                 norm_in_out_saber[0][0]          
                                                                 norm_in_out_stats_extended[0][0] 
                                                                 norm_in_park_factors[0][0]       
__________________________________________________________________________________________________
gru_1 (GRU)                     (None, None, 113)    76953       concatenate_1[0][0]              
__________________________________________________________________________________________________
gru_2 (GRU)                     (None, None, 113)    76953       gru_1[0][0]                      
__________________________________________________________________________________________________
mv_out_stats (TimeDistributed)  (None, None, 5)      4560        gru_2[0][0]                      
__________________________________________________________________________________________________
mv_out_counts (TimeDistributed) (None, None, 3)      2736        gru_2[0][0]                      
__________________________________________________________________________________________________
mv_out_mean_covariance (TimeDis (None, None, 72)     65664       gru_2[0][0]                      
__________________________________________________________________________________________________
mv_out_fielding_position (TimeD (None, None, 11)     10032       gru_2[0][0]                      
__________________________________________________________________________________________________
out_stats (Activation)          (None, None, 5)      0           mv_out_stats[0][0]               
__________________________________________________________________________________________________
out_counts (Activation)         (None, None, 3)      0           mv_out_counts[0][0]              
__________________________________________________________________________________________________
out_mean_covariance (Activation (None, None, 72)     0           mv_out_mean_covariance[0][0]     
__________________________________________________________________________________________________
out_fielding_position (Activati (None, None, 11)     0           mv_out_fielding_position[0][0]   
==================================================================================================
Total params: 237,350
Trainable params: 237,124
Non-trainable params: 226
__________________________________________________________________________________________________
Train on 5879 samples, validate on 1409 samples
Epoch 1/1000

Epoch 00001: val_loss improved from inf to 18.03182, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 16s - loss: 20.0325 - out_stats_loss: 6.9801 - out_counts_loss: 3.3837 - out_mean_covariance_loss: 103.8437 - out_fielding_position_loss: 4.4765 - val_loss: 18.0318 - val_out_stats_loss: 6.4173 - val_out_counts_loss: 2.5461 - val_out_mean_covariance_loss: 97.4109 - val_out_fielding_position_loss: 4.1979
Epoch 2/1000

Epoch 00002: val_loss improved from 18.03182 to 15.46063, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 16.6067 - out_stats_loss: 5.8024 - out_counts_loss: 2.3157 - out_mean_covariance_loss: 89.1346 - out_fielding_position_loss: 4.0319 - val_loss: 15.4606 - val_out_stats_loss: 5.4147 - val_out_counts_loss: 2.0658 - val_out_mean_covariance_loss: 83.7125 - val_out_fielding_position_loss: 3.7945
Epoch 3/1000

Epoch 00003: val_loss improved from 15.46063 to 14.05993, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 14.7559 - out_stats_loss: 5.1283 - out_counts_loss: 2.0775 - out_mean_covariance_loss: 78.7658 - out_fielding_position_loss: 3.6117 - val_loss: 14.0599 - val_out_stats_loss: 4.9636 - val_out_counts_loss: 1.9250 - val_out_mean_covariance_loss: 75.7815 - val_out_fielding_position_loss: 3.3822
Epoch 4/1000

Epoch 00004: val_loss improved from 14.05993 to 13.13709, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 13.6415 - out_stats_loss: 4.8009 - out_counts_loss: 1.9665 - out_mean_covariance_loss: 72.9070 - out_fielding_position_loss: 3.2287 - val_loss: 13.1371 - val_out_stats_loss: 4.7435 - val_out_counts_loss: 1.8197 - val_out_mean_covariance_loss: 71.4521 - val_out_fielding_position_loss: 3.0013
Epoch 5/1000

Epoch 00005: val_loss improved from 13.13709 to 12.63600, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 12.9144 - out_stats_loss: 4.6287 - out_counts_loss: 1.9181 - out_mean_covariance_loss: 69.1968 - out_fielding_position_loss: 2.9076 - val_loss: 12.6360 - val_out_stats_loss: 4.6667 - val_out_counts_loss: 1.8223 - val_out_mean_covariance_loss: 69.3569 - val_out_fielding_position_loss: 2.6792
Epoch 6/1000

Epoch 00006: val_loss improved from 12.63600 to 12.22061, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 12.5274 - out_stats_loss: 4.5990 - out_counts_loss: 1.8887 - out_mean_covariance_loss: 68.2072 - out_fielding_position_loss: 2.6293 - val_loss: 12.2206 - val_out_stats_loss: 4.5911 - val_out_counts_loss: 1.7931 - val_out_mean_covariance_loss: 67.7127 - val_out_fielding_position_loss: 2.4508
Epoch 7/1000

Epoch 00007: val_loss improved from 12.22061 to 11.93742, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 12.1252 - out_stats_loss: 4.5149 - out_counts_loss: 1.8699 - out_mean_covariance_loss: 66.4130 - out_fielding_position_loss: 2.4197 - val_loss: 11.9374 - val_out_stats_loss: 4.5501 - val_out_counts_loss: 1.7808 - val_out_mean_covariance_loss: 66.7706 - val_out_fielding_position_loss: 2.2680
Epoch 8/1000

Epoch 00008: val_loss improved from 11.93742 to 11.74586, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 11.8969 - out_stats_loss: 4.4789 - out_counts_loss: 1.8638 - out_mean_covariance_loss: 65.5641 - out_fielding_position_loss: 2.2760 - val_loss: 11.7459 - val_out_stats_loss: 4.5175 - val_out_counts_loss: 1.7781 - val_out_mean_covariance_loss: 66.0953 - val_out_fielding_position_loss: 2.1455
Epoch 9/1000

Epoch 00009: val_loss improved from 11.74586 to 11.59147, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 11.6636 - out_stats_loss: 4.4253 - out_counts_loss: 1.8427 - out_mean_covariance_loss: 64.5928 - out_fielding_position_loss: 2.1660 - val_loss: 11.5915 - val_out_stats_loss: 4.4774 - val_out_counts_loss: 1.7857 - val_out_mean_covariance_loss: 65.4317 - val_out_fielding_position_loss: 2.0568
Epoch 10/1000

Epoch 00010: val_loss improved from 11.59147 to 11.50646, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 11.6526 - out_stats_loss: 4.4271 - out_counts_loss: 1.8678 - out_mean_covariance_loss: 64.6811 - out_fielding_position_loss: 2.1236 - val_loss: 11.5065 - val_out_stats_loss: 4.4553 - val_out_counts_loss: 1.7924 - val_out_mean_covariance_loss: 64.9484 - val_out_fielding_position_loss: 2.0114
Epoch 11/1000

Epoch 00011: val_loss improved from 11.50646 to 11.36392, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 11.3962 - out_stats_loss: 4.3537 - out_counts_loss: 1.8232 - out_mean_covariance_loss: 63.2551 - out_fielding_position_loss: 2.0566 - val_loss: 11.3639 - val_out_stats_loss: 4.4098 - val_out_counts_loss: 1.7631 - val_out_mean_covariance_loss: 64.4002 - val_out_fielding_position_loss: 1.9709
Epoch 12/1000

Epoch 00012: val_loss improved from 11.36392 to 11.29707, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 11.2788 - out_stats_loss: 4.3167 - out_counts_loss: 1.8116 - out_mean_covariance_loss: 62.7131 - out_fielding_position_loss: 2.0148 - val_loss: 11.2971 - val_out_stats_loss: 4.3871 - val_out_counts_loss: 1.7646 - val_out_mean_covariance_loss: 63.9696 - val_out_fielding_position_loss: 1.9469
Epoch 13/1000

Epoch 00013: val_loss improved from 11.29707 to 11.22884, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 11.1977 - out_stats_loss: 4.2868 - out_counts_loss: 1.8043 - out_mean_covariance_loss: 62.2315 - out_fielding_position_loss: 1.9949 - val_loss: 11.2288 - val_out_stats_loss: 4.3667 - val_out_counts_loss: 1.7578 - val_out_mean_covariance_loss: 63.6325 - val_out_fielding_position_loss: 1.9227
Epoch 14/1000

Epoch 00014: val_loss improved from 11.22884 to 11.19931, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 11.1625 - out_stats_loss: 4.2730 - out_counts_loss: 1.8045 - out_mean_covariance_loss: 62.1163 - out_fielding_position_loss: 1.9792 - val_loss: 11.1993 - val_out_stats_loss: 4.3495 - val_out_counts_loss: 1.7661 - val_out_mean_covariance_loss: 63.4078 - val_out_fielding_position_loss: 1.9134
Epoch 15/1000

Epoch 00015: val_loss improved from 11.19931 to 11.12334, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 11.0513 - out_stats_loss: 4.2429 - out_counts_loss: 1.7796 - out_mean_covariance_loss: 61.5261 - out_fielding_position_loss: 1.9525 - val_loss: 11.1233 - val_out_stats_loss: 4.3280 - val_out_counts_loss: 1.7466 - val_out_mean_covariance_loss: 62.9877 - val_out_fielding_position_loss: 1.8994
Epoch 16/1000

Epoch 00016: val_loss improved from 11.12334 to 11.10116, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 11.0675 - out_stats_loss: 4.2667 - out_counts_loss: 1.7905 - out_mean_covariance_loss: 61.7706 - out_fielding_position_loss: 1.9218 - val_loss: 11.1012 - val_out_stats_loss: 4.3264 - val_out_counts_loss: 1.7470 - val_out_mean_covariance_loss: 62.8905 - val_out_fielding_position_loss: 1.8832
Epoch 17/1000

Epoch 00017: val_loss improved from 11.10116 to 11.09355, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 10.9381 - out_stats_loss: 4.2152 - out_counts_loss: 1.7680 - out_mean_covariance_loss: 60.8629 - out_fielding_position_loss: 1.9117 - val_loss: 11.0935 - val_out_stats_loss: 4.3188 - val_out_counts_loss: 1.7584 - val_out_mean_covariance_loss: 62.6267 - val_out_fielding_position_loss: 1.8849
Epoch 18/1000

Epoch 00018: val_loss improved from 11.09355 to 11.04292, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 10.9417 - out_stats_loss: 4.2161 - out_counts_loss: 1.7617 - out_mean_covariance_loss: 60.9975 - out_fielding_position_loss: 1.9140 - val_loss: 11.0429 - val_out_stats_loss: 4.3025 - val_out_counts_loss: 1.7485 - val_out_mean_covariance_loss: 62.4015 - val_out_fielding_position_loss: 1.8719
Epoch 19/1000

Epoch 00019: val_loss improved from 11.04292 to 11.01166, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 10.8160 - out_stats_loss: 4.1583 - out_counts_loss: 1.7574 - out_mean_covariance_loss: 60.0410 - out_fielding_position_loss: 1.8983 - val_loss: 11.0117 - val_out_stats_loss: 4.2928 - val_out_counts_loss: 1.7408 - val_out_mean_covariance_loss: 62.2874 - val_out_fielding_position_loss: 1.8637
Epoch 20/1000

Epoch 00020: val_loss improved from 11.01166 to 10.97664, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 10.8074 - out_stats_loss: 4.1764 - out_counts_loss: 1.7460 - out_mean_covariance_loss: 60.1577 - out_fielding_position_loss: 1.8771 - val_loss: 10.9766 - val_out_stats_loss: 4.2802 - val_out_counts_loss: 1.7326 - val_out_mean_covariance_loss: 62.1179 - val_out_fielding_position_loss: 1.8579
Epoch 21/1000

Epoch 00021: val_loss improved from 10.97664 to 10.96571, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 10.7656 - out_stats_loss: 4.1569 - out_counts_loss: 1.7397 - out_mean_covariance_loss: 59.8771 - out_fielding_position_loss: 1.8752 - val_loss: 10.9657 - val_out_stats_loss: 4.2775 - val_out_counts_loss: 1.7375 - val_out_mean_covariance_loss: 61.9425 - val_out_fielding_position_loss: 1.8536
Epoch 22/1000

Epoch 00022: val_loss improved from 10.96571 to 10.95596, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 10.7250 - out_stats_loss: 4.1396 - out_counts_loss: 1.7296 - out_mean_covariance_loss: 59.8933 - out_fielding_position_loss: 1.8611 - val_loss: 10.9560 - val_out_stats_loss: 4.2819 - val_out_counts_loss: 1.7295 - val_out_mean_covariance_loss: 61.9868 - val_out_fielding_position_loss: 1.8453
Epoch 23/1000

Epoch 00023: val_loss improved from 10.95596 to 10.90286, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 10.7376 - out_stats_loss: 4.1543 - out_counts_loss: 1.7379 - out_mean_covariance_loss: 59.9175 - out_fielding_position_loss: 1.8495 - val_loss: 10.9029 - val_out_stats_loss: 4.2554 - val_out_counts_loss: 1.7256 - val_out_mean_covariance_loss: 61.6892 - val_out_fielding_position_loss: 1.8374
Epoch 24/1000

Epoch 00024: val_loss improved from 10.90286 to 10.88354, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 10.6412 - out_stats_loss: 4.1243 - out_counts_loss: 1.7076 - out_mean_covariance_loss: 59.4587 - out_fielding_position_loss: 1.8364 - val_loss: 10.8835 - val_out_stats_loss: 4.2478 - val_out_counts_loss: 1.7269 - val_out_mean_covariance_loss: 61.5491 - val_out_fielding_position_loss: 1.8314
Epoch 25/1000

Epoch 00025: val_loss improved from 10.88354 to 10.87122, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 10.6694 - out_stats_loss: 4.1478 - out_counts_loss: 1.7067 - out_mean_covariance_loss: 59.8520 - out_fielding_position_loss: 1.8223 - val_loss: 10.8712 - val_out_stats_loss: 4.2455 - val_out_counts_loss: 1.7308 - val_out_mean_covariance_loss: 61.3679 - val_out_fielding_position_loss: 1.8265
Epoch 26/1000

Epoch 00026: val_loss improved from 10.87122 to 10.85326, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 10.6342 - out_stats_loss: 4.1269 - out_counts_loss: 1.7073 - out_mean_covariance_loss: 59.4322 - out_fielding_position_loss: 1.8285 - val_loss: 10.8533 - val_out_stats_loss: 4.2395 - val_out_counts_loss: 1.7242 - val_out_mean_covariance_loss: 61.3175 - val_out_fielding_position_loss: 1.8236
Epoch 27/1000

Epoch 00027: val_loss did not improve
 - 5s - loss: 10.5665 - out_stats_loss: 4.0953 - out_counts_loss: 1.6932 - out_mean_covariance_loss: 59.2620 - out_fielding_position_loss: 1.8149 - val_loss: 10.8786 - val_out_stats_loss: 4.2485 - val_out_counts_loss: 1.7375 - val_out_mean_covariance_loss: 61.4402 - val_out_fielding_position_loss: 1.8206
Epoch 28/1000

Epoch 00028: val_loss did not improve
 - 5s - loss: 10.5937 - out_stats_loss: 4.1251 - out_counts_loss: 1.7003 - out_mean_covariance_loss: 59.6376 - out_fielding_position_loss: 1.7864 - val_loss: 10.8830 - val_out_stats_loss: 4.2597 - val_out_counts_loss: 1.7430 - val_out_mean_covariance_loss: 61.3609 - val_out_fielding_position_loss: 1.8123
Epoch 29/1000

Epoch 00029: val_loss improved from 10.85326 to 10.83798, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 10.5524 - out_stats_loss: 4.1089 - out_counts_loss: 1.6976 - out_mean_covariance_loss: 58.9711 - out_fielding_position_loss: 1.7973 - val_loss: 10.8380 - val_out_stats_loss: 4.2417 - val_out_counts_loss: 1.7245 - val_out_mean_covariance_loss: 61.1758 - val_out_fielding_position_loss: 1.8130
Epoch 30/1000

Epoch 00030: val_loss improved from 10.83798 to 10.80686, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 10.4679 - out_stats_loss: 4.0774 - out_counts_loss: 1.6717 - out_mean_covariance_loss: 58.6901 - out_fielding_position_loss: 1.7844 - val_loss: 10.8069 - val_out_stats_loss: 4.2284 - val_out_counts_loss: 1.7252 - val_out_mean_covariance_loss: 60.9821 - val_out_fielding_position_loss: 1.8042
Epoch 31/1000

Epoch 00031: val_loss did not improve
 - 5s - loss: 10.4290 - out_stats_loss: 4.0693 - out_counts_loss: 1.6691 - out_mean_covariance_loss: 58.4220 - out_fielding_position_loss: 1.7695 - val_loss: 10.8136 - val_out_stats_loss: 4.2392 - val_out_counts_loss: 1.7238 - val_out_mean_covariance_loss: 61.0053 - val_out_fielding_position_loss: 1.8004
Epoch 32/1000

Epoch 00032: val_loss improved from 10.80686 to 10.77869, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 10.4185 - out_stats_loss: 4.0636 - out_counts_loss: 1.6624 - out_mean_covariance_loss: 58.4257 - out_fielding_position_loss: 1.7712 - val_loss: 10.7787 - val_out_stats_loss: 4.2197 - val_out_counts_loss: 1.7218 - val_out_mean_covariance_loss: 60.7689 - val_out_fielding_position_loss: 1.7988
Epoch 33/1000

Epoch 00033: val_loss did not improve
 - 5s - loss: 10.3495 - out_stats_loss: 4.0422 - out_counts_loss: 1.6522 - out_mean_covariance_loss: 58.0098 - out_fielding_position_loss: 1.7546 - val_loss: 10.7911 - val_out_stats_loss: 4.2308 - val_out_counts_loss: 1.7238 - val_out_mean_covariance_loss: 60.8895 - val_out_fielding_position_loss: 1.7921
Epoch 34/1000

Epoch 00034: val_loss did not improve
 - 5s - loss: 10.4077 - out_stats_loss: 4.0745 - out_counts_loss: 1.6447 - out_mean_covariance_loss: 58.6067 - out_fielding_position_loss: 1.7582 - val_loss: 10.8002 - val_out_stats_loss: 4.2241 - val_out_counts_loss: 1.7472 - val_out_mean_covariance_loss: 60.8023 - val_out_fielding_position_loss: 1.7888
Epoch 35/1000

Epoch 00035: val_loss did not improve
 - 5s - loss: 10.3142 - out_stats_loss: 4.0414 - out_counts_loss: 1.6428 - out_mean_covariance_loss: 57.8119 - out_fielding_position_loss: 1.7394 - val_loss: 10.7829 - val_out_stats_loss: 4.2260 - val_out_counts_loss: 1.7319 - val_out_mean_covariance_loss: 60.8569 - val_out_fielding_position_loss: 1.7822
Epoch 36/1000

Epoch 00036: val_loss improved from 10.77869 to 10.76212, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 10.2901 - out_stats_loss: 4.0286 - out_counts_loss: 1.6361 - out_mean_covariance_loss: 57.7778 - out_fielding_position_loss: 1.7365 - val_loss: 10.7621 - val_out_stats_loss: 4.2150 - val_out_counts_loss: 1.7296 - val_out_mean_covariance_loss: 60.7111 - val_out_fielding_position_loss: 1.7819
Epoch 37/1000

Epoch 00037: val_loss improved from 10.76212 to 10.74276, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 10.2715 - out_stats_loss: 4.0262 - out_counts_loss: 1.6258 - out_mean_covariance_loss: 57.7799 - out_fielding_position_loss: 1.7304 - val_loss: 10.7428 - val_out_stats_loss: 4.2121 - val_out_counts_loss: 1.7272 - val_out_mean_covariance_loss: 60.5968 - val_out_fielding_position_loss: 1.7737
Epoch 38/1000

Epoch 00038: val_loss improved from 10.74276 to 10.72999, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 10.2417 - out_stats_loss: 4.0243 - out_counts_loss: 1.6218 - out_mean_covariance_loss: 57.6927 - out_fielding_position_loss: 1.7110 - val_loss: 10.7300 - val_out_stats_loss: 4.2115 - val_out_counts_loss: 1.7202 - val_out_mean_covariance_loss: 60.5647 - val_out_fielding_position_loss: 1.7701
Epoch 39/1000

Epoch 00039: val_loss did not improve
 - 5s - loss: 10.2044 - out_stats_loss: 4.0086 - out_counts_loss: 1.6148 - out_mean_covariance_loss: 57.2388 - out_fielding_position_loss: 1.7191 - val_loss: 10.7356 - val_out_stats_loss: 4.2109 - val_out_counts_loss: 1.7313 - val_out_mean_covariance_loss: 60.4608 - val_out_fielding_position_loss: 1.7703
Epoch 40/1000

Epoch 00040: val_loss improved from 10.72999 to 10.71805, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 10.1933 - out_stats_loss: 4.0137 - out_counts_loss: 1.6092 - out_mean_covariance_loss: 57.4371 - out_fielding_position_loss: 1.6985 - val_loss: 10.7180 - val_out_stats_loss: 4.2068 - val_out_counts_loss: 1.7300 - val_out_mean_covariance_loss: 60.3298 - val_out_fielding_position_loss: 1.7647
Epoch 41/1000

Epoch 00041: val_loss improved from 10.71805 to 10.70866, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 10.1506 - out_stats_loss: 3.9996 - out_counts_loss: 1.6021 - out_mean_covariance_loss: 57.1649 - out_fielding_position_loss: 1.6906 - val_loss: 10.7087 - val_out_stats_loss: 4.2035 - val_out_counts_loss: 1.7281 - val_out_mean_covariance_loss: 60.3408 - val_out_fielding_position_loss: 1.7600
Epoch 42/1000

Epoch 00042: val_loss did not improve
 - 5s - loss: 10.1264 - out_stats_loss: 3.9940 - out_counts_loss: 1.5895 - out_mean_covariance_loss: 57.1351 - out_fielding_position_loss: 1.6862 - val_loss: 10.7298 - val_out_stats_loss: 4.2143 - val_out_counts_loss: 1.7410 - val_out_mean_covariance_loss: 60.3010 - val_out_fielding_position_loss: 1.7594
Epoch 43/1000

Epoch 00043: val_loss did not improve
 - 5s - loss: 10.0551 - out_stats_loss: 3.9733 - out_counts_loss: 1.5744 - out_mean_covariance_loss: 56.5979 - out_fielding_position_loss: 1.6775 - val_loss: 10.7141 - val_out_stats_loss: 4.2128 - val_out_counts_loss: 1.7359 - val_out_mean_covariance_loss: 60.2376 - val_out_fielding_position_loss: 1.7535
Epoch 44/1000

Epoch 00044: val_loss improved from 10.70866 to 10.69911, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 10.0656 - out_stats_loss: 3.9869 - out_counts_loss: 1.5818 - out_mean_covariance_loss: 56.6648 - out_fielding_position_loss: 1.6636 - val_loss: 10.6991 - val_out_stats_loss: 4.2043 - val_out_counts_loss: 1.7357 - val_out_mean_covariance_loss: 60.1516 - val_out_fielding_position_loss: 1.7515
Epoch 45/1000

Epoch 00045: val_loss did not improve
 - 5s - loss: 10.0407 - out_stats_loss: 3.9805 - out_counts_loss: 1.5675 - out_mean_covariance_loss: 56.6903 - out_fielding_position_loss: 1.6582 - val_loss: 10.7500 - val_out_stats_loss: 4.2253 - val_out_counts_loss: 1.7606 - val_out_mean_covariance_loss: 60.2288 - val_out_fielding_position_loss: 1.7527
Epoch 46/1000

Epoch 00046: val_loss improved from 10.69911 to 10.69889, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 10.0562 - out_stats_loss: 3.9802 - out_counts_loss: 1.5600 - out_mean_covariance_loss: 57.0696 - out_fielding_position_loss: 1.6624 - val_loss: 10.6989 - val_out_stats_loss: 4.2057 - val_out_counts_loss: 1.7455 - val_out_mean_covariance_loss: 60.0304 - val_out_fielding_position_loss: 1.7462
Epoch 47/1000

Epoch 00047: val_loss did not improve
 - 5s - loss: 9.9432 - out_stats_loss: 3.9385 - out_counts_loss: 1.5522 - out_mean_covariance_loss: 55.9789 - out_fielding_position_loss: 1.6536 - val_loss: 10.7026 - val_out_stats_loss: 4.2102 - val_out_counts_loss: 1.7411 - val_out_mean_covariance_loss: 60.1133 - val_out_fielding_position_loss: 1.7457
Epoch 48/1000

Epoch 00048: val_loss did not improve
 - 5s - loss: 9.9534 - out_stats_loss: 3.9516 - out_counts_loss: 1.5488 - out_mean_covariance_loss: 56.2651 - out_fielding_position_loss: 1.6397 - val_loss: 10.7729 - val_out_stats_loss: 4.2287 - val_out_counts_loss: 1.7924 - val_out_mean_covariance_loss: 60.1428 - val_out_fielding_position_loss: 1.7447
Epoch 49/1000

Epoch 00049: val_loss did not improve
 - 5s - loss: 9.9272 - out_stats_loss: 3.9369 - out_counts_loss: 1.5503 - out_mean_covariance_loss: 55.9727 - out_fielding_position_loss: 1.6413 - val_loss: 10.7074 - val_out_stats_loss: 4.2105 - val_out_counts_loss: 1.7560 - val_out_mean_covariance_loss: 60.0469 - val_out_fielding_position_loss: 1.7386
Epoch 50/1000

Epoch 00050: val_loss improved from 10.69889 to 10.66517, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 9.9177 - out_stats_loss: 3.9362 - out_counts_loss: 1.5510 - out_mean_covariance_loss: 55.7843 - out_fielding_position_loss: 1.6413 - val_loss: 10.6652 - val_out_stats_loss: 4.1983 - val_out_counts_loss: 1.7461 - val_out_mean_covariance_loss: 59.7972 - val_out_fielding_position_loss: 1.7309
Epoch 51/1000

Epoch 00051: val_loss did not improve
 - 5s - loss: 9.9011 - out_stats_loss: 3.9394 - out_counts_loss: 1.5360 - out_mean_covariance_loss: 55.9882 - out_fielding_position_loss: 1.6263 - val_loss: 10.7092 - val_out_stats_loss: 4.2232 - val_out_counts_loss: 1.7560 - val_out_mean_covariance_loss: 59.9495 - val_out_fielding_position_loss: 1.7326
Epoch 52/1000

Epoch 00052: val_loss did not improve
 - 5s - loss: 9.8948 - out_stats_loss: 3.9421 - out_counts_loss: 1.5277 - out_mean_covariance_loss: 55.9077 - out_fielding_position_loss: 1.6296 - val_loss: 10.6893 - val_out_stats_loss: 4.2038 - val_out_counts_loss: 1.7586 - val_out_mean_covariance_loss: 59.9020 - val_out_fielding_position_loss: 1.7317
Epoch 53/1000

Epoch 00053: val_loss did not improve
 - 5s - loss: 9.8862 - out_stats_loss: 3.9458 - out_counts_loss: 1.5178 - out_mean_covariance_loss: 56.1519 - out_fielding_position_loss: 1.6150 - val_loss: 10.7005 - val_out_stats_loss: 4.2142 - val_out_counts_loss: 1.7694 - val_out_mean_covariance_loss: 59.7798 - val_out_fielding_position_loss: 1.7279
Epoch 54/1000

Epoch 00054: val_loss did not improve
 - 5s - loss: 9.8314 - out_stats_loss: 3.9165 - out_counts_loss: 1.5212 - out_mean_covariance_loss: 55.6327 - out_fielding_position_loss: 1.6120 - val_loss: 10.6892 - val_out_stats_loss: 4.2014 - val_out_counts_loss: 1.7730 - val_out_mean_covariance_loss: 59.7623 - val_out_fielding_position_loss: 1.7266
Epoch 55/1000

Epoch 00055: val_loss did not improve
 - 5s - loss: 9.7996 - out_stats_loss: 3.9196 - out_counts_loss: 1.5066 - out_mean_covariance_loss: 55.5113 - out_fielding_position_loss: 1.5979 - val_loss: 10.6948 - val_out_stats_loss: 4.2093 - val_out_counts_loss: 1.7757 - val_out_mean_covariance_loss: 59.7613 - val_out_fielding_position_loss: 1.7218
Epoch 56/1000

Epoch 00056: val_loss did not improve
 - 5s - loss: 9.8242 - out_stats_loss: 3.9173 - out_counts_loss: 1.5170 - out_mean_covariance_loss: 55.7222 - out_fielding_position_loss: 1.6038 - val_loss: 10.7080 - val_out_stats_loss: 4.2036 - val_out_counts_loss: 1.7923 - val_out_mean_covariance_loss: 59.7997 - val_out_fielding_position_loss: 1.7220
Epoch 57/1000

Epoch 00057: val_loss did not improve
 - 5s - loss: 9.8118 - out_stats_loss: 3.9391 - out_counts_loss: 1.4953 - out_mean_covariance_loss: 55.9797 - out_fielding_position_loss: 1.5784 - val_loss: 10.7073 - val_out_stats_loss: 4.2173 - val_out_counts_loss: 1.7877 - val_out_mean_covariance_loss: 59.6291 - val_out_fielding_position_loss: 1.7209
Epoch 58/1000

Epoch 00058: val_loss did not improve
 - 5s - loss: 9.7466 - out_stats_loss: 3.9050 - out_counts_loss: 1.4911 - out_mean_covariance_loss: 55.1870 - out_fielding_position_loss: 1.5911 - val_loss: 10.7398 - val_out_stats_loss: 4.2210 - val_out_counts_loss: 1.8156 - val_out_mean_covariance_loss: 59.7047 - val_out_fielding_position_loss: 1.7180
Epoch 59/1000

Epoch 00059: val_loss improved from 10.66517 to 10.65633, saving model to models/bc/shift1/max2016/simple-rnn/2.h5
 - 5s - loss: 9.7322 - out_stats_loss: 3.9012 - out_counts_loss: 1.4984 - out_mean_covariance_loss: 55.0618 - out_fielding_position_loss: 1.5795 - val_loss: 10.6563 - val_out_stats_loss: 4.2002 - val_out_counts_loss: 1.7705 - val_out_mean_covariance_loss: 59.4660 - val_out_fielding_position_loss: 1.7123
Epoch 60/1000

Epoch 00060: val_loss did not improve
 - 5s - loss: 9.7101 - out_stats_loss: 3.9019 - out_counts_loss: 1.4742 - out_mean_covariance_loss: 55.1844 - out_fielding_position_loss: 1.5748 - val_loss: 10.6723 - val_out_stats_loss: 4.2022 - val_out_counts_loss: 1.7837 - val_out_mean_covariance_loss: 59.4854 - val_out_fielding_position_loss: 1.7121
Epoch 61/1000

Epoch 00061: val_loss did not improve
 - 5s - loss: 9.6937 - out_stats_loss: 3.8883 - out_counts_loss: 1.4699 - out_mean_covariance_loss: 55.0790 - out_fielding_position_loss: 1.5815 - val_loss: 10.6810 - val_out_stats_loss: 4.2108 - val_out_counts_loss: 1.7874 - val_out_mean_covariance_loss: 59.4562 - val_out_fielding_position_loss: 1.7100
Epoch 62/1000

Epoch 00062: val_loss did not improve
 - 5s - loss: 9.6698 - out_stats_loss: 3.8956 - out_counts_loss: 1.4628 - out_mean_covariance_loss: 55.0977 - out_fielding_position_loss: 1.5565 - val_loss: 10.6618 - val_out_stats_loss: 4.1989 - val_out_counts_loss: 1.7860 - val_out_mean_covariance_loss: 59.4253 - val_out_fielding_position_loss: 1.7056
Epoch 63/1000

Epoch 00063: val_loss did not improve
 - 5s - loss: 9.6205 - out_stats_loss: 3.8722 - out_counts_loss: 1.4602 - out_mean_covariance_loss: 54.5960 - out_fielding_position_loss: 1.5583 - val_loss: 10.6687 - val_out_stats_loss: 4.2053 - val_out_counts_loss: 1.7941 - val_out_mean_covariance_loss: 59.3256 - val_out_fielding_position_loss: 1.7031
Epoch 64/1000

Epoch 00064: val_loss did not improve
 - 5s - loss: 9.6199 - out_stats_loss: 3.8782 - out_counts_loss: 1.4512 - out_mean_covariance_loss: 54.7350 - out_fielding_position_loss: 1.5538 - val_loss: 10.6683 - val_out_stats_loss: 4.2027 - val_out_counts_loss: 1.7914 - val_out_mean_covariance_loss: 59.3444 - val_out_fielding_position_loss: 1.7070
Epoch 65/1000

Epoch 00065: val_loss did not improve
 - 5s - loss: 9.5568 - out_stats_loss: 3.8513 - out_counts_loss: 1.4578 - out_mean_covariance_loss: 54.0792 - out_fielding_position_loss: 1.5438 - val_loss: 10.7007 - val_out_stats_loss: 4.2116 - val_out_counts_loss: 1.8210 - val_out_mean_covariance_loss: 59.2681 - val_out_fielding_position_loss: 1.7047
Epoch 66/1000

Epoch 00066: val_loss did not improve
 - 5s - loss: 9.5605 - out_stats_loss: 3.8675 - out_counts_loss: 1.4391 - out_mean_covariance_loss: 54.3714 - out_fielding_position_loss: 1.5353 - val_loss: 10.6929 - val_out_stats_loss: 4.2029 - val_out_counts_loss: 1.8125 - val_out_mean_covariance_loss: 59.4007 - val_out_fielding_position_loss: 1.7074
Epoch 67/1000

Epoch 00067: val_loss did not improve
 - 5s - loss: 9.4896 - out_stats_loss: 3.8340 - out_counts_loss: 1.4297 - out_mean_covariance_loss: 53.7147 - out_fielding_position_loss: 1.5403 - val_loss: 10.7032 - val_out_stats_loss: 4.2031 - val_out_counts_loss: 1.8263 - val_out_mean_covariance_loss: 59.3722 - val_out_fielding_position_loss: 1.7052
Epoch 68/1000

Epoch 00068: val_loss did not improve
 - 5s - loss: 9.4993 - out_stats_loss: 3.8432 - out_counts_loss: 1.4364 - out_mean_covariance_loss: 53.9467 - out_fielding_position_loss: 1.5224 - val_loss: 10.7572 - val_out_stats_loss: 4.2206 - val_out_counts_loss: 1.8592 - val_out_mean_covariance_loss: 59.3297 - val_out_fielding_position_loss: 1.7110
Epoch 69/1000

Epoch 00069: val_loss did not improve
 - 5s - loss: 9.5142 - out_stats_loss: 3.8456 - out_counts_loss: 1.4261 - out_mean_covariance_loss: 54.1756 - out_fielding_position_loss: 1.5336 - val_loss: 10.6876 - val_out_stats_loss: 4.1992 - val_out_counts_loss: 1.8265 - val_out_mean_covariance_loss: 59.3575 - val_out_fielding_position_loss: 1.6940
Epoch 70/1000

Epoch 00070: val_loss did not improve
 - 5s - loss: 9.4905 - out_stats_loss: 3.8458 - out_counts_loss: 1.4266 - out_mean_covariance_loss: 53.8382 - out_fielding_position_loss: 1.5262 - val_loss: 10.7022 - val_out_stats_loss: 4.2043 - val_out_counts_loss: 1.8318 - val_out_mean_covariance_loss: 59.2846 - val_out_fielding_position_loss: 1.7018
Epoch 71/1000

Epoch 00071: val_loss did not improve
 - 5s - loss: 9.4786 - out_stats_loss: 3.8461 - out_counts_loss: 1.4063 - out_mean_covariance_loss: 54.1681 - out_fielding_position_loss: 1.5178 - val_loss: 10.6898 - val_out_stats_loss: 4.2041 - val_out_counts_loss: 1.8273 - val_out_mean_covariance_loss: 59.1882 - val_out_fielding_position_loss: 1.6990
Epoch 72/1000

Epoch 00072: val_loss did not improve
 - 5s - loss: 9.4231 - out_stats_loss: 3.8197 - out_counts_loss: 1.4081 - out_mean_covariance_loss: 53.6439 - out_fielding_position_loss: 1.5131 - val_loss: 10.6905 - val_out_stats_loss: 4.2034 - val_out_counts_loss: 1.8353 - val_out_mean_covariance_loss: 59.1166 - val_out_fielding_position_loss: 1.6960
Epoch 73/1000

Epoch 00073: val_loss did not improve
 - 5s - loss: 9.4002 - out_stats_loss: 3.8241 - out_counts_loss: 1.3984 - out_mean_covariance_loss: 53.3557 - out_fielding_position_loss: 1.5099 - val_loss: 10.7549 - val_out_stats_loss: 4.2298 - val_out_counts_loss: 1.8640 - val_out_mean_covariance_loss: 59.2527 - val_out_fielding_position_loss: 1.6985
Epoch 74/1000

Epoch 00074: val_loss did not improve
 - 5s - loss: 9.3729 - out_stats_loss: 3.8059 - out_counts_loss: 1.3962 - out_mean_covariance_loss: 53.2766 - out_fielding_position_loss: 1.5069 - val_loss: 10.7480 - val_out_stats_loss: 4.2322 - val_out_counts_loss: 1.8502 - val_out_mean_covariance_loss: 59.4041 - val_out_fielding_position_loss: 1.6955
Epoch 75/1000

Epoch 00075: val_loss did not improve
 - 5s - loss: 9.3600 - out_stats_loss: 3.8039 - out_counts_loss: 1.3963 - out_mean_covariance_loss: 53.0706 - out_fielding_position_loss: 1.5063 - val_loss: 10.6922 - val_out_stats_loss: 4.2001 - val_out_counts_loss: 1.8379 - val_out_mean_covariance_loss: 59.2834 - val_out_fielding_position_loss: 1.6901
Epoch 76/1000

Epoch 00076: val_loss did not improve
 - 5s - loss: 9.3048 - out_stats_loss: 3.7886 - out_counts_loss: 1.3833 - out_mean_covariance_loss: 52.6593 - out_fielding_position_loss: 1.5000 - val_loss: 10.6974 - val_out_stats_loss: 4.2019 - val_out_counts_loss: 1.8476 - val_out_mean_covariance_loss: 59.1869 - val_out_fielding_position_loss: 1.6885
Epoch 77/1000

Epoch 00077: val_loss did not improve
 - 5s - loss: 9.3935 - out_stats_loss: 3.8325 - out_counts_loss: 1.3836 - out_mean_covariance_loss: 53.6385 - out_fielding_position_loss: 1.4955 - val_loss: 10.7583 - val_out_stats_loss: 4.2192 - val_out_counts_loss: 1.8739 - val_out_mean_covariance_loss: 59.3493 - val_out_fielding_position_loss: 1.6976
Epoch 78/1000

Epoch 00078: val_loss did not improve
 - 5s - loss: 9.2733 - out_stats_loss: 3.7815 - out_counts_loss: 1.3744 - out_mean_covariance_loss: 52.6983 - out_fielding_position_loss: 1.4825 - val_loss: 10.7754 - val_out_stats_loss: 4.2266 - val_out_counts_loss: 1.8945 - val_out_mean_covariance_loss: 59.1485 - val_out_fielding_position_loss: 1.6969
Epoch 79/1000

Epoch 00079: val_loss did not improve
 - 5s - loss: 9.3139 - out_stats_loss: 3.8017 - out_counts_loss: 1.3767 - out_mean_covariance_loss: 52.9950 - out_fielding_position_loss: 1.4858 - val_loss: 10.8013 - val_out_stats_loss: 4.2366 - val_out_counts_loss: 1.9025 - val_out_mean_covariance_loss: 59.2483 - val_out_fielding_position_loss: 1.6997
Epoch 80/1000

Epoch 00080: val_loss did not improve
 - 5s - loss: 9.2979 - out_stats_loss: 3.7926 - out_counts_loss: 1.3763 - out_mean_covariance_loss: 53.0613 - out_fielding_position_loss: 1.4759 - val_loss: 10.7436 - val_out_stats_loss: 4.2220 - val_out_counts_loss: 1.8752 - val_out_mean_covariance_loss: 59.1464 - val_out_fielding_position_loss: 1.6891
Epoch 81/1000

Epoch 00081: val_loss did not improve
 - 5s - loss: 9.2850 - out_stats_loss: 3.7990 - out_counts_loss: 1.3552 - out_mean_covariance_loss: 53.0357 - out_fielding_position_loss: 1.4791 - val_loss: 10.7361 - val_out_stats_loss: 4.2159 - val_out_counts_loss: 1.8727 - val_out_mean_covariance_loss: 59.2285 - val_out_fielding_position_loss: 1.6861
Epoch 82/1000

Epoch 00082: val_loss did not improve
 - 5s - loss: 9.2763 - out_stats_loss: 3.8008 - out_counts_loss: 1.3585 - out_mean_covariance_loss: 52.9850 - out_fielding_position_loss: 1.4678 - val_loss: 10.7692 - val_out_stats_loss: 4.2322 - val_out_counts_loss: 1.8802 - val_out_mean_covariance_loss: 59.4029 - val_out_fielding_position_loss: 1.6866
Epoch 83/1000

Epoch 00083: val_loss did not improve
 - 5s - loss: 9.2549 - out_stats_loss: 3.7902 - out_counts_loss: 1.3624 - out_mean_covariance_loss: 52.6901 - out_fielding_position_loss: 1.4678 - val_loss: 10.7541 - val_out_stats_loss: 4.2105 - val_out_counts_loss: 1.8866 - val_out_mean_covariance_loss: 59.3489 - val_out_fielding_position_loss: 1.6895
Epoch 84/1000

Epoch 00084: val_loss did not improve
 - 5s - loss: 9.1837 - out_stats_loss: 3.7571 - out_counts_loss: 1.3461 - out_mean_covariance_loss: 52.2890 - out_fielding_position_loss: 1.4660 - val_loss: 10.7782 - val_out_stats_loss: 4.2266 - val_out_counts_loss: 1.8938 - val_out_mean_covariance_loss: 59.3747 - val_out_fielding_position_loss: 1.6890
Epoch 85/1000

Epoch 00085: val_loss did not improve
 - 5s - loss: 9.1796 - out_stats_loss: 3.7658 - out_counts_loss: 1.3441 - out_mean_covariance_loss: 52.2288 - out_fielding_position_loss: 1.4583 - val_loss: 10.8115 - val_out_stats_loss: 4.2290 - val_out_counts_loss: 1.9181 - val_out_mean_covariance_loss: 59.3379 - val_out_fielding_position_loss: 1.6975
Epoch 86/1000

Epoch 00086: val_loss did not improve
 - 5s - loss: 9.2782 - out_stats_loss: 3.8098 - out_counts_loss: 1.3436 - out_mean_covariance_loss: 53.2452 - out_fielding_position_loss: 1.4625 - val_loss: 10.7984 - val_out_stats_loss: 4.2334 - val_out_counts_loss: 1.9080 - val_out_mean_covariance_loss: 59.3135 - val_out_fielding_position_loss: 1.6913
Epoch 87/1000

Epoch 00087: val_loss did not improve
 - 5s - loss: 9.1726 - out_stats_loss: 3.7629 - out_counts_loss: 1.3369 - out_mean_covariance_loss: 52.3963 - out_fielding_position_loss: 1.4529 - val_loss: 10.8039 - val_out_stats_loss: 4.2340 - val_out_counts_loss: 1.9122 - val_out_mean_covariance_loss: 59.3920 - val_out_fielding_position_loss: 1.6881
Epoch 88/1000

Epoch 00088: val_loss did not improve
 - 5s - loss: 9.1252 - out_stats_loss: 3.7512 - out_counts_loss: 1.3273 - out_mean_covariance_loss: 52.1157 - out_fielding_position_loss: 1.4409 - val_loss: 10.7949 - val_out_stats_loss: 4.2285 - val_out_counts_loss: 1.9101 - val_out_mean_covariance_loss: 59.4775 - val_out_fielding_position_loss: 1.6824
Epoch 89/1000

Epoch 00089: val_loss did not improve
 - 5s - loss: 9.1470 - out_stats_loss: 3.7535 - out_counts_loss: 1.3348 - out_mean_covariance_loss: 52.0167 - out_fielding_position_loss: 1.4579 - val_loss: 10.7889 - val_out_stats_loss: 4.2251 - val_out_counts_loss: 1.9124 - val_out_mean_covariance_loss: 59.3084 - val_out_fielding_position_loss: 1.6861
Epoch 90/1000

Epoch 00090: val_loss did not improve
 - 5s - loss: 9.1275 - out_stats_loss: 3.7590 - out_counts_loss: 1.3177 - out_mean_covariance_loss: 52.1968 - out_fielding_position_loss: 1.4410 - val_loss: 10.8303 - val_out_stats_loss: 4.2436 - val_out_counts_loss: 1.9227 - val_out_mean_covariance_loss: 59.4288 - val_out_fielding_position_loss: 1.6925
Epoch 91/1000

Epoch 00091: val_loss did not improve
 - 5s - loss: 9.1476 - out_stats_loss: 3.7720 - out_counts_loss: 1.3135 - out_mean_covariance_loss: 52.5333 - out_fielding_position_loss: 1.4354 - val_loss: 10.8863 - val_out_stats_loss: 4.2636 - val_out_counts_loss: 1.9381 - val_out_mean_covariance_loss: 59.7015 - val_out_fielding_position_loss: 1.6995
Epoch 92/1000

Epoch 00092: val_loss did not improve
 - 5s - loss: 9.0788 - out_stats_loss: 3.7453 - out_counts_loss: 1.3134 - out_mean_covariance_loss: 51.7998 - out_fielding_position_loss: 1.4301 - val_loss: 10.8893 - val_out_stats_loss: 4.2640 - val_out_counts_loss: 1.9550 - val_out_mean_covariance_loss: 59.5464 - val_out_fielding_position_loss: 1.6930
Epoch 93/1000

Epoch 00093: val_loss did not improve
 - 5s - loss: 9.0406 - out_stats_loss: 3.7279 - out_counts_loss: 1.3056 - out_mean_covariance_loss: 51.6593 - out_fielding_position_loss: 1.4242 - val_loss: 10.8275 - val_out_stats_loss: 4.2407 - val_out_counts_loss: 1.9323 - val_out_mean_covariance_loss: 59.4356 - val_out_fielding_position_loss: 1.6827
Epoch 94/1000

Epoch 00094: val_loss did not improve
 - 5s - loss: 9.0466 - out_stats_loss: 3.7359 - out_counts_loss: 1.3064 - out_mean_covariance_loss: 51.5655 - out_fielding_position_loss: 1.4261 - val_loss: 10.8986 - val_out_stats_loss: 4.2659 - val_out_counts_loss: 1.9679 - val_out_mean_covariance_loss: 59.4499 - val_out_fielding_position_loss: 1.6923
Epoch 95/1000

Epoch 00095: val_loss did not improve
 - 5s - loss: 9.1062 - out_stats_loss: 3.7682 - out_counts_loss: 1.3022 - out_mean_covariance_loss: 52.1530 - out_fielding_position_loss: 1.4281 - val_loss: 10.8960 - val_out_stats_loss: 4.2560 - val_out_counts_loss: 1.9607 - val_out_mean_covariance_loss: 59.6225 - val_out_fielding_position_loss: 1.6982
Epoch 96/1000

Epoch 00096: val_loss did not improve
 - 5s - loss: 9.0519 - out_stats_loss: 3.7338 - out_counts_loss: 1.3110 - out_mean_covariance_loss: 51.5613 - out_fielding_position_loss: 1.4290 - val_loss: 10.8455 - val_out_stats_loss: 4.2427 - val_out_counts_loss: 1.9397 - val_out_mean_covariance_loss: 59.5096 - val_out_fielding_position_loss: 1.6877
Epoch 97/1000

Epoch 00097: val_loss did not improve
 - 5s - loss: 9.0007 - out_stats_loss: 3.7191 - out_counts_loss: 1.2913 - out_mean_covariance_loss: 51.4362 - out_fielding_position_loss: 1.4184 - val_loss: 10.9133 - val_out_stats_loss: 4.2651 - val_out_counts_loss: 1.9798 - val_out_mean_covariance_loss: 59.5469 - val_out_fielding_position_loss: 1.6910
Epoch 98/1000

Epoch 00098: val_loss did not improve
 - 5s - loss: 9.0534 - out_stats_loss: 3.7433 - out_counts_loss: 1.3023 - out_mean_covariance_loss: 51.7804 - out_fielding_position_loss: 1.4188 - val_loss: 10.8539 - val_out_stats_loss: 4.2428 - val_out_counts_loss: 1.9491 - val_out_mean_covariance_loss: 59.5132 - val_out_fielding_position_loss: 1.6864
Epoch 99/1000

Epoch 00099: val_loss did not improve
 - 5s - loss: 8.9926 - out_stats_loss: 3.7310 - out_counts_loss: 1.2838 - out_mean_covariance_loss: 51.3714 - out_fielding_position_loss: 1.4092 - val_loss: 10.9170 - val_out_stats_loss: 4.2568 - val_out_counts_loss: 1.9844 - val_out_mean_covariance_loss: 59.8143 - val_out_fielding_position_loss: 1.6851
Epoch 100/1000

Epoch 00100: val_loss did not improve
 - 5s - loss: 8.9480 - out_stats_loss: 3.7030 - out_counts_loss: 1.2832 - out_mean_covariance_loss: 51.1538 - out_fielding_position_loss: 1.4041 - val_loss: 10.8905 - val_out_stats_loss: 4.2582 - val_out_counts_loss: 1.9641 - val_out_mean_covariance_loss: 59.5984 - val_out_fielding_position_loss: 1.6883
Epoch 101/1000

Epoch 00101: val_loss did not improve
 - 5s - loss: 8.9176 - out_stats_loss: 3.7001 - out_counts_loss: 1.2798 - out_mean_covariance_loss: 50.7977 - out_fielding_position_loss: 1.3978 - val_loss: 10.8689 - val_out_stats_loss: 4.2461 - val_out_counts_loss: 1.9552 - val_out_mean_covariance_loss: 59.7007 - val_out_fielding_position_loss: 1.6826
Epoch 102/1000

Epoch 00102: val_loss did not improve
 - 5s - loss: 8.9224 - out_stats_loss: 3.7006 - out_counts_loss: 1.2708 - out_mean_covariance_loss: 51.0627 - out_fielding_position_loss: 1.3979 - val_loss: 10.9202 - val_out_stats_loss: 4.2593 - val_out_counts_loss: 1.9755 - val_out_mean_covariance_loss: 60.0433 - val_out_fielding_position_loss: 1.6832
Epoch 103/1000

Epoch 00103: val_loss did not improve
 - 5s - loss: 8.9016 - out_stats_loss: 3.6945 - out_counts_loss: 1.2621 - out_mean_covariance_loss: 50.7936 - out_fielding_position_loss: 1.4053 - val_loss: 10.9260 - val_out_stats_loss: 4.2623 - val_out_counts_loss: 1.9727 - val_out_mean_covariance_loss: 59.9370 - val_out_fielding_position_loss: 1.6941
Epoch 104/1000

Epoch 00104: val_loss did not improve
 - 5s - loss: 8.9015 - out_stats_loss: 3.6993 - out_counts_loss: 1.2694 - out_mean_covariance_loss: 50.8098 - out_fielding_position_loss: 1.3922 - val_loss: 10.9151 - val_out_stats_loss: 4.2653 - val_out_counts_loss: 1.9610 - val_out_mean_covariance_loss: 59.9829 - val_out_fielding_position_loss: 1.6896
Epoch 105/1000

Epoch 00105: val_loss did not improve
 - 5s - loss: 8.8711 - out_stats_loss: 3.6852 - out_counts_loss: 1.2568 - out_mean_covariance_loss: 50.7615 - out_fielding_position_loss: 1.3911 - val_loss: 10.9452 - val_out_stats_loss: 4.2604 - val_out_counts_loss: 1.9930 - val_out_mean_covariance_loss: 60.0097 - val_out_fielding_position_loss: 1.6913
Epoch 106/1000

Epoch 00106: val_loss did not improve
 - 5s - loss: 8.8951 - out_stats_loss: 3.6978 - out_counts_loss: 1.2563 - out_mean_covariance_loss: 50.9736 - out_fielding_position_loss: 1.3923 - val_loss: 10.9540 - val_out_stats_loss: 4.2693 - val_out_counts_loss: 1.9881 - val_out_mean_covariance_loss: 60.2001 - val_out_fielding_position_loss: 1.6867
Epoch 107/1000

Epoch 00107: val_loss did not improve
 - 5s - loss: 8.9169 - out_stats_loss: 3.7053 - out_counts_loss: 1.2677 - out_mean_covariance_loss: 51.0468 - out_fielding_position_loss: 1.3916 - val_loss: 10.9331 - val_out_stats_loss: 4.2634 - val_out_counts_loss: 1.9891 - val_out_mean_covariance_loss: 59.9655 - val_out_fielding_position_loss: 1.6823
Epoch 108/1000

Epoch 00108: val_loss did not improve
 - 5s - loss: 8.8616 - out_stats_loss: 3.6850 - out_counts_loss: 1.2564 - out_mean_covariance_loss: 50.7051 - out_fielding_position_loss: 1.3850 - val_loss: 10.9628 - val_out_stats_loss: 4.2702 - val_out_counts_loss: 1.9909 - val_out_mean_covariance_loss: 60.1785 - val_out_fielding_position_loss: 1.6928
Epoch 109/1000

Epoch 00109: val_loss did not improve
 - 5s - loss: 8.8479 - out_stats_loss: 3.6878 - out_counts_loss: 1.2446 - out_mean_covariance_loss: 50.7666 - out_fielding_position_loss: 1.3772 - val_loss: 10.9927 - val_out_stats_loss: 4.2834 - val_out_counts_loss: 2.0178 - val_out_mean_covariance_loss: 60.1218 - val_out_fielding_position_loss: 1.6854
/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Years: [1958,2016]
Shift: 1
Fold: 4
Training into models/bc/shift1/max2016/simple-rnn/2.h5
/usr/local/lib/python3.5/dist-packages/keras/legacy/layers.py:533: UserWarning: The `MaxoutDense` layer is deprecated and will be removed after 06/2017.
  warnings.warn('The `MaxoutDense` layer is deprecated '
