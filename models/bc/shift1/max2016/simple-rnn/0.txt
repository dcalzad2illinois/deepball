__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
in_age (InputLayer)             (None, None, 2)      0                                            
__________________________________________________________________________________________________
in_bio (InputLayer)             (None, None, 7)      0                                            
__________________________________________________________________________________________________
in_fielding_position (InputLaye (None, None, 2)      0                                            
__________________________________________________________________________________________________
in_out_fielding_position (Input (None, None, 12)     0                                            
__________________________________________________________________________________________________
in_out_league_offense (InputLay (None, None, 9)      0                                            
__________________________________________________________________________________________________
in_out_park_factors (InputLayer (None, None, 8)      0                                            
__________________________________________________________________________________________________
in_out_plate_discipline (InputL (None, None, 8)      0                                            
__________________________________________________________________________________________________
in_out_running (InputLayer)     (None, None, 18)     0                                            
__________________________________________________________________________________________________
in_out_saber (InputLayer)       (None, None, 14)     0                                            
__________________________________________________________________________________________________
in_out_stats_extended (InputLay (None, None, 36)     0                                            
__________________________________________________________________________________________________
in_park_factors (InputLayer)    (None, None, 8)      0                                            
__________________________________________________________________________________________________
masked_in_age (Masking)         (None, None, 2)      0           in_age[0][0]                     
__________________________________________________________________________________________________
masked_in_bio (Masking)         (None, None, 7)      0           in_bio[0][0]                     
__________________________________________________________________________________________________
masked_in_fielding_position (Ma (None, None, 2)      0           in_fielding_position[0][0]       
__________________________________________________________________________________________________
masked_in_out_fielding_position (None, None, 12)     0           in_out_fielding_position[0][0]   
__________________________________________________________________________________________________
masked_in_out_league_offense (M (None, None, 9)      0           in_out_league_offense[0][0]      
__________________________________________________________________________________________________
masked_in_out_park_factors (Mas (None, None, 8)      0           in_out_park_factors[0][0]        
__________________________________________________________________________________________________
masked_in_out_plate_discipline  (None, None, 8)      0           in_out_plate_discipline[0][0]    
__________________________________________________________________________________________________
masked_in_out_running (Masking) (None, None, 18)     0           in_out_running[0][0]             
__________________________________________________________________________________________________
masked_in_out_saber (Masking)   (None, None, 14)     0           in_out_saber[0][0]               
__________________________________________________________________________________________________
masked_in_out_stats_extended (M (None, None, 36)     0           in_out_stats_extended[0][0]      
__________________________________________________________________________________________________
masked_in_park_factors (Masking (None, None, 8)      0           in_park_factors[0][0]            
__________________________________________________________________________________________________
time_distributed_6 (TimeDistrib (None, None, 1)      0           masked_in_age[0][0]              
__________________________________________________________________________________________________
time_distributed_8 (TimeDistrib (None, None, 6)      0           masked_in_bio[0][0]              
__________________________________________________________________________________________________
time_distributed_9 (TimeDistrib (None, None, 1)      0           masked_in_fielding_position[0][0]
__________________________________________________________________________________________________
time_distributed_5 (TimeDistrib (None, None, 11)     0           masked_in_out_fielding_position[0
__________________________________________________________________________________________________
time_distributed_4 (TimeDistrib (None, None, 8)      0           masked_in_out_league_offense[0][0
__________________________________________________________________________________________________
time_distributed_3 (TimeDistrib (None, None, 7)      0           masked_in_out_park_factors[0][0] 
__________________________________________________________________________________________________
time_distributed_10 (TimeDistri (None, None, 7)      0           masked_in_out_plate_discipline[0]
__________________________________________________________________________________________________
time_distributed_7 (TimeDistrib (None, None, 17)     0           masked_in_out_running[0][0]      
__________________________________________________________________________________________________
time_distributed_2 (TimeDistrib (None, None, 13)     0           masked_in_out_saber[0][0]        
__________________________________________________________________________________________________
time_distributed_1 (TimeDistrib (None, None, 35)     0           masked_in_out_stats_extended[0][0
__________________________________________________________________________________________________
time_distributed_11 (TimeDistri (None, None, 7)      0           masked_in_park_factors[0][0]     
__________________________________________________________________________________________________
norm_in_age (BatchNormalization (None, None, 1)      4           time_distributed_6[0][0]         
__________________________________________________________________________________________________
norm_in_bio (BatchNormalization (None, None, 6)      24          time_distributed_8[0][0]         
__________________________________________________________________________________________________
norm_in_fielding_position (Batc (None, None, 1)      4           time_distributed_9[0][0]         
__________________________________________________________________________________________________
norm_in_out_fielding_position ( (None, None, 11)     44          time_distributed_5[0][0]         
__________________________________________________________________________________________________
norm_in_out_league_offense (Bat (None, None, 8)      32          time_distributed_4[0][0]         
__________________________________________________________________________________________________
norm_in_out_park_factors (Batch (None, None, 7)      28          time_distributed_3[0][0]         
__________________________________________________________________________________________________
norm_in_out_plate_discipline (B (None, None, 7)      28          time_distributed_10[0][0]        
__________________________________________________________________________________________________2018-02-06 06:18:08.478227: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-02-06 06:18:15.114757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: eca0:00:00.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2018-02-06 06:18:15.114803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: eca0:00:00.0, compute capability: 3.7)

norm_in_out_running (BatchNorma (None, None, 17)     68          time_distributed_7[0][0]         
__________________________________________________________________________________________________
norm_in_out_saber (BatchNormali (None, None, 13)     52          time_distributed_2[0][0]         
__________________________________________________________________________________________________
norm_in_out_stats_extended (Bat (None, None, 35)     140         time_distributed_1[0][0]         
__________________________________________________________________________________________________
norm_in_park_factors (BatchNorm (None, None, 7)      28          time_distributed_11[0][0]        
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, None, 113)    0           norm_in_age[0][0]                
                                                                 norm_in_bio[0][0]                
                                                                 norm_in_fielding_position[0][0]  
                                                                 norm_in_out_fielding_position[0][
                                                                 norm_in_out_league_offense[0][0] 
                                                                 norm_in_out_park_factors[0][0]   
                                                                 norm_in_out_plate_discipline[0][0
                                                                 norm_in_out_running[0][0]        
                                                                 norm_in_out_saber[0][0]          
                                                                 norm_in_out_stats_extended[0][0] 
                                                                 norm_in_park_factors[0][0]       
__________________________________________________________________________________________________
gru_1 (GRU)                     (None, None, 113)    76953       concatenate_1[0][0]              
__________________________________________________________________________________________________
gru_2 (GRU)                     (None, None, 113)    76953       gru_1[0][0]                      
__________________________________________________________________________________________________
mv_out_stats (TimeDistributed)  (None, None, 5)      4560        gru_2[0][0]                      
__________________________________________________________________________________________________
mv_out_counts (TimeDistributed) (None, None, 3)      2736        gru_2[0][0]                      
__________________________________________________________________________________________________
mv_out_mean_covariance (TimeDis (None, None, 72)     65664       gru_2[0][0]                      
__________________________________________________________________________________________________
mv_out_fielding_position (TimeD (None, None, 11)     10032       gru_2[0][0]                      
__________________________________________________________________________________________________
out_stats (Activation)          (None, None, 5)      0           mv_out_stats[0][0]               
__________________________________________________________________________________________________
out_counts (Activation)         (None, None, 3)      0           mv_out_counts[0][0]              
__________________________________________________________________________________________________
out_mean_covariance (Activation (None, None, 72)     0           mv_out_mean_covariance[0][0]     
__________________________________________________________________________________________________
out_fielding_position (Activati (None, None, 11)     0           mv_out_fielding_position[0][0]   
==================================================================================================
Total params: 237,350
Trainable params: 237,124
Non-trainable params: 226
__________________________________________________________________________________________________
Train on 5879 samples, validate on 1409 samples
Epoch 1/1000

Epoch 00001: val_loss improved from inf to 18.45199, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 15s - loss: 20.3365 - out_stats_loss: 7.0835 - out_counts_loss: 3.5314 - out_mean_covariance_loss: 104.7366 - out_fielding_position_loss: 4.4848 - val_loss: 18.4520 - val_out_stats_loss: 6.5962 - val_out_counts_loss: 2.7091 - val_out_mean_covariance_loss: 98.7460 - val_out_fielding_position_loss: 4.2094
Epoch 2/1000

Epoch 00002: val_loss improved from 18.45199 to 15.68824, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 5s - loss: 16.8759 - out_stats_loss: 5.9343 - out_counts_loss: 2.3915 - out_mean_covariance_loss: 90.6261 - out_fielding_position_loss: 4.0188 - val_loss: 15.6882 - val_out_stats_loss: 5.5222 - val_out_counts_loss: 2.1149 - val_out_mean_covariance_loss: 85.2831 - val_out_fielding_position_loss: 3.7869
Epoch 3/1000

Epoch 00003: val_loss improved from 15.68824 to 14.15290, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 5s - loss: 14.8871 - out_stats_loss: 5.1926 - out_counts_loss: 2.0985 - out_mean_covariance_loss: 79.6977 - out_fielding_position_loss: 3.6112 - val_loss: 14.1529 - val_out_stats_loss: 5.0177 - val_out_counts_loss: 1.9368 - val_out_mean_covariance_loss: 76.5678 - val_out_fielding_position_loss: 3.3700
Epoch 4/1000

Epoch 00004: val_loss improved from 14.15290 to 13.21179, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 5s - loss: 13.6549 - out_stats_loss: 4.8116 - out_counts_loss: 1.9767 - out_mean_covariance_loss: 72.8879 - out_fielding_position_loss: 3.2223 - val_loss: 13.2118 - val_out_stats_loss: 4.7723 - val_out_counts_loss: 1.8384 - val_out_mean_covariance_loss: 72.0361 - val_out_fielding_position_loss: 2.9993
Epoch 5/1000

Epoch 00005: val_loss improved from 13.21179 to 12.63288, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 5s - loss: 12.9987 - out_stats_loss: 4.6762 - out_counts_loss: 1.9286 - out_mean_covariance_loss: 69.9913 - out_fielding_position_loss: 2.8943 - val_loss: 12.6329 - val_out_stats_loss: 4.6657 - val_out_counts_loss: 1.8101 - val_out_mean_covariance_loss: 69.5401 - val_out_fielding_position_loss: 2.6801
Epoch 6/1000

Epoch 00006: val_loss improved from 12.63288 to 12.21271, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 5s - loss: 12.5010 - out_stats_loss: 4.5916 - out_counts_loss: 1.9004 - out_mean_covariance_loss: 67.8316 - out_fielding_position_loss: 2.6174 - val_loss: 12.2127 - val_out_stats_loss: 4.5960 - val_out_counts_loss: 1.7881 - val_out_mean_covariance_loss: 68.1227 - val_out_fielding_position_loss: 2.4225
Epoch 7/1000

Epoch 00007: val_loss improved from 12.21271 to 11.97467, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 5s - loss: 12.1013 - out_stats_loss: 4.5202 - out_counts_loss: 1.8760 - out_mean_covariance_loss: 66.4171 - out_fielding_position_loss: 2.3842 - val_loss: 11.9747 - val_out_stats_loss: 4.5716 - val_out_counts_loss: 1.7894 - val_out_mean_covariance_loss: 67.2254 - val_out_fielding_position_loss: 2.2524
Epoch 8/1000

Epoch 00008: val_loss improved from 11.97467 to 11.71845, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 5s - loss: 11.8434 - out_stats_loss: 4.4527 - out_counts_loss: 1.8671 - out_mean_covariance_loss: 65.4549 - out_fielding_position_loss: 2.2508 - val_loss: 11.7185 - val_out_stats_loss: 4.5057 - val_out_counts_loss: 1.7758 - val_out_mean_covariance_loss: 66.3173 - val_out_fielding_position_loss: 2.1211
Epoch 9/1000

Epoch 00009: val_loss improved from 11.71845 to 11.63460, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 5s - loss: 11.7243 - out_stats_loss: 4.4507 - out_counts_loss: 1.8556 - out_mean_covariance_loss: 65.2111 - out_fielding_position_loss: 2.1574 - val_loss: 11.6346 - val_out_stats_loss: 4.4917 - val_out_counts_loss: 1.8010 - val_out_mean_covariance_loss: 65.8889 - val_out_fielding_position_loss: 2.0475
Epoch 10/1000

Epoch 00010: val_loss improved from 11.63460 to 11.45450, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 5s - loss: 11.5357 - out_stats_loss: 4.3802 - out_counts_loss: 1.8365 - out_mean_covariance_loss: 64.2474 - out_fielding_position_loss: 2.1066 - val_loss: 11.4545 - val_out_stats_loss: 4.4378 - val_out_counts_loss: 1.7668 - val_out_mean_covariance_loss: 65.1093 - val_out_fielding_position_loss: 1.9945
Epoch 11/1000

Epoch 00011: val_loss improved from 11.45450 to 11.39377, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 5s - loss: 11.4227 - out_stats_loss: 4.3608 - out_counts_loss: 1.8327 - out_mean_covariance_loss: 63.7386 - out_fielding_position_loss: 2.0424 - val_loss: 11.3938 - val_out_stats_loss: 4.4271 - val_out_counts_loss: 1.7656 - val_out_mean_covariance_loss: 64.7560 - val_out_fielding_position_loss: 1.9633
Epoch 12/1000

Epoch 00012: val_loss improved from 11.39377 to 11.32415, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 5s - loss: 11.3424 - out_stats_loss: 4.3421 - out_counts_loss: 1.8206 - out_mean_covariance_loss: 63.5173 - out_fielding_position_loss: 2.0039 - val_loss: 11.3242 - val_out_stats_loss: 4.3888 - val_out_counts_loss: 1.7812 - val_out_mean_covariance_loss: 64.2998 - val_out_fielding_position_loss: 1.9392
Epoch 13/1000

Epoch 00013: val_loss improved from 11.32415 to 11.25283, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 5s - loss: 11.2274 - out_stats_loss: 4.2919 - out_counts_loss: 1.8177 - out_mean_covariance_loss: 62.6826 - out_fielding_position_loss: 1.9836 - val_loss: 11.2528 - val_out_stats_loss: 4.3737 - val_out_counts_loss: 1.7560 - val_out_mean_covariance_loss: 64.0285 - val_out_fielding_position_loss: 1.9216
Epoch 14/1000

Epoch 00014: val_loss improved from 11.25283 to 11.23156, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 5s - loss: 11.1515 - out_stats_loss: 4.2640 - out_counts_loss: 1.8073 - out_mean_covariance_loss: 62.1562 - out_fielding_position_loss: 1.9725 - val_loss: 11.2316 - val_out_stats_loss: 4.3633 - val_out_counts_loss: 1.7734 - val_out_mean_covariance_loss: 63.8424 - val_out_fielding_position_loss: 1.9028
Epoch 15/1000

Epoch 00015: val_loss improved from 11.23156 to 11.16890, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 5s - loss: 11.0577 - out_stats_loss: 4.2344 - out_counts_loss: 1.7875 - out_mean_covariance_loss: 61.7760 - out_fielding_position_loss: 1.9470 - val_loss: 11.1689 - val_out_stats_loss: 4.3541 - val_out_counts_loss: 1.7504 - val_out_mean_covariance_loss: 63.4114 - val_out_fielding_position_loss: 1.8938
Epoch 16/1000

Epoch 00016: val_loss improved from 11.16890 to 11.13859, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 5s - loss: 11.0128 - out_stats_loss: 4.2182 - out_counts_loss: 1.7955 - out_mean_covariance_loss: 61.5079 - out_fielding_position_loss: 1.9237 - val_loss: 11.1386 - val_out_stats_loss: 4.3442 - val_out_counts_loss: 1.7456 - val_out_mean_covariance_loss: 63.2957 - val_out_fielding_position_loss: 1.8840
Epoch 17/1000

Epoch 00017: val_loss improved from 11.13859 to 11.06568, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 5s - loss: 10.9390 - out_stats_loss: 4.1939 - out_counts_loss: 1.7818 - out_mean_covariance_loss: 60.9667 - out_fielding_position_loss: 1.9150 - val_loss: 11.0657 - val_out_stats_loss: 4.3089 - val_out_counts_loss: 1.7394 - val_out_mean_covariance_loss: 62.9612 - val_out_fielding_position_loss: 1.8694
Epoch 18/1000

Epoch 00018: val_loss improved from 11.06568 to 11.05390, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 5s - loss: 10.9571 - out_stats_loss: 4.2076 - out_counts_loss: 1.7750 - out_mean_covariance_loss: 61.1608 - out_fielding_position_loss: 1.9164 - val_loss: 11.0539 - val_out_stats_loss: 4.2967 - val_out_counts_loss: 1.7538 - val_out_mean_covariance_loss: 62.7333 - val_out_fielding_position_loss: 1.8668
Epoch 19/1000

Epoch 00019: val_loss improved from 11.05390 to 11.01201, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 5s - loss: 10.9274 - out_stats_loss: 4.2013 - out_counts_loss: 1.7697 - out_mean_covariance_loss: 61.0429 - out_fielding_position_loss: 1.9042 - val_loss: 11.0120 - val_out_stats_loss: 4.2866 - val_out_counts_loss: 1.7429 - val_out_mean_covariance_loss: 62.5399 - val_out_fielding_position_loss: 1.8555
Epoch 20/1000

Epoch 00020: val_loss improved from 11.01201 to 11.01062, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 5s - loss: 10.7928 - out_stats_loss: 4.1548 - out_counts_loss: 1.7433 - out_mean_covariance_loss: 60.2870 - out_fielding_position_loss: 1.8804 - val_loss: 11.0106 - val_out_stats_loss: 4.2948 - val_out_counts_loss: 1.7445 - val_out_mean_covariance_loss: 62.3640 - val_out_fielding_position_loss: 1.8532
Epoch 21/1000

Epoch 00021: val_loss improved from 11.01062 to 10.94712, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 5s - loss: 10.7897 - out_stats_loss: 4.1510 - out_counts_loss: 1.7607 - out_mean_covariance_loss: 60.0567 - out_fielding_position_loss: 1.8752 - val_loss: 10.9471 - val_out_stats_loss: 4.2650 - val_out_counts_loss: 1.7322 - val_out_mean_covariance_loss: 62.1519 - val_out_fielding_position_loss: 1.8424
Epoch 22/1000

Epoch 00022: val_loss did not improve
 - 5s - loss: 10.7406 - out_stats_loss: 4.1324 - out_counts_loss: 1.7554 - out_mean_covariance_loss: 59.8708 - out_fielding_position_loss: 1.8592 - val_loss: 11.0168 - val_out_stats_loss: 4.2864 - val_out_counts_loss: 1.7719 - val_out_mean_covariance_loss: 62.3287 - val_out_fielding_position_loss: 1.8421
Epoch 23/1000

Epoch 00023: val_loss improved from 10.94712 to 10.91348, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 5s - loss: 10.7721 - out_stats_loss: 4.1554 - out_counts_loss: 1.7445 - out_mean_covariance_loss: 60.3135 - out_fielding_position_loss: 1.8566 - val_loss: 10.9135 - val_out_stats_loss: 4.2502 - val_out_counts_loss: 1.7382 - val_out_mean_covariance_loss: 61.8145 - val_out_fielding_position_loss: 1.8344
Epoch 24/1000

Epoch 00024: val_loss improved from 10.91348 to 10.90906, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 5s - loss: 10.6740 - out_stats_loss: 4.1137 - out_counts_loss: 1.7347 - out_mean_covariance_loss: 59.4928 - out_fielding_position_loss: 1.8509 - val_loss: 10.9091 - val_out_stats_loss: 4.2566 - val_out_counts_loss: 1.7319 - val_out_mean_covariance_loss: 61.8436 - val_out_fielding_position_loss: 1.8284
Epoch 25/1000

Epoch 00025: val_loss did not improve
 - 5s - loss: 10.6597 - out_stats_loss: 4.1203 - out_counts_loss: 1.7217 - out_mean_covariance_loss: 59.6525 - out_fielding_position_loss: 1.8350 - val_loss: 10.9551 - val_out_stats_loss: 4.2735 - val_out_counts_loss: 1.7624 - val_out_mean_covariance_loss: 61.8849 - val_out_fielding_position_loss: 1.8249
Epoch 26/1000

Epoch 00026: val_loss did not improve
 - 5s - loss: 10.6120 - out_stats_loss: 4.1128 - out_counts_loss: 1.7187 - out_mean_covariance_loss: 59.3287 - out_fielding_position_loss: 1.8141 - val_loss: 10.9092 - val_out_stats_loss: 4.2487 - val_out_counts_loss: 1.7456 - val_out_mean_covariance_loss: 61.8896 - val_out_fielding_position_loss: 1.8204
Epoch 27/1000

Epoch 00027: val_loss improved from 10.90906 to 10.83905, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 5s - loss: 10.5607 - out_stats_loss: 4.0772 - out_counts_loss: 1.7178 - out_mean_covariance_loss: 59.0556 - out_fielding_position_loss: 1.8129 - val_loss: 10.8391 - val_out_stats_loss: 4.2275 - val_out_counts_loss: 1.7264 - val_out_mean_covariance_loss: 61.3765 - val_out_fielding_position_loss: 1.8163
Epoch 28/1000

Epoch 00028: val_loss improved from 10.83905 to 10.82141, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 5s - loss: 10.5523 - out_stats_loss: 4.0844 - out_counts_loss: 1.7132 - out_mean_covariance_loss: 58.9962 - out_fielding_position_loss: 1.8049 - val_loss: 10.8214 - val_out_stats_loss: 4.2246 - val_out_counts_loss: 1.7213 - val_out_mean_covariance_loss: 61.2425 - val_out_fielding_position_loss: 1.8134
Epoch 29/1000

Epoch 00029: val_loss did not improve
 - 5s - loss: 10.5413 - out_stats_loss: 4.0936 - out_counts_loss: 1.6967 - out_mean_covariance_loss: 59.1941 - out_fielding_position_loss: 1.7913 - val_loss: 10.8281 - val_out_stats_loss: 4.2225 - val_out_counts_loss: 1.7306 - val_out_mean_covariance_loss: 61.3014 - val_out_fielding_position_loss: 1.8100
Epoch 30/1000

Epoch 00030: val_loss improved from 10.82141 to 10.79156, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 5s - loss: 10.5189 - out_stats_loss: 4.0791 - out_counts_loss: 1.6988 - out_mean_covariance_loss: 59.1304 - out_fielding_position_loss: 1.7845 - val_loss: 10.7916 - val_out_stats_loss: 4.2116 - val_out_counts_loss: 1.7203 - val_out_mean_covariance_loss: 61.1296 - val_out_fielding_position_loss: 1.8031
Epoch 31/1000

Epoch 00031: val_loss improved from 10.79156 to 10.78113, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 5s - loss: 10.4289 - out_stats_loss: 4.0494 - out_counts_loss: 1.6833 - out_mean_covariance_loss: 58.4228 - out_fielding_position_loss: 1.7750 - val_loss: 10.7811 - val_out_stats_loss: 4.2102 - val_out_counts_loss: 1.7210 - val_out_mean_covariance_loss: 61.0175 - val_out_fielding_position_loss: 1.7991
Epoch 32/1000

Epoch 00032: val_loss improved from 10.78113 to 10.77649, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 5s - loss: 10.4527 - out_stats_loss: 4.0577 - out_counts_loss: 1.6862 - out_mean_covariance_loss: 58.6805 - out_fielding_position_loss: 1.7748 - val_loss: 10.7765 - val_out_stats_loss: 4.2081 - val_out_counts_loss: 1.7242 - val_out_mean_covariance_loss: 60.9366 - val_out_fielding_position_loss: 1.7974
Epoch 33/1000

Epoch 00033: val_loss did not improve
 - 5s - loss: 10.4513 - out_stats_loss: 4.0639 - out_counts_loss: 1.6795 - out_mean_covariance_loss: 58.6591 - out_fielding_position_loss: 1.7750 - val_loss: 10.7965 - val_out_stats_loss: 4.2205 - val_out_counts_loss: 1.7306 - val_out_mean_covariance_loss: 61.0403 - val_out_fielding_position_loss: 1.7935
Epoch 34/1000

Epoch 00034: val_loss did not improve
 - 5s - loss: 10.4369 - out_stats_loss: 4.0740 - out_counts_loss: 1.6773 - out_mean_covariance_loss: 58.6446 - out_fielding_position_loss: 1.7533 - val_loss: 10.8440 - val_out_stats_loss: 4.2226 - val_out_counts_loss: 1.7754 - val_out_mean_covariance_loss: 60.9962 - val_out_fielding_position_loss: 1.7962
Epoch 35/1000

Epoch 00035: val_loss did not improve
 - 5s - loss: 10.4370 - out_stats_loss: 4.0719 - out_counts_loss: 1.6529 - out_mean_covariance_loss: 59.1758 - out_fielding_position_loss: 1.7535 - val_loss: 10.7871 - val_out_stats_loss: 4.2086 - val_out_counts_loss: 1.7460 - val_out_mean_covariance_loss: 60.8676 - val_out_fielding_position_loss: 1.7891
Epoch 36/1000

Epoch 00036: val_loss improved from 10.77649 to 10.73562, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 5s - loss: 10.3471 - out_stats_loss: 4.0350 - out_counts_loss: 1.6621 - out_mean_covariance_loss: 58.0797 - out_fielding_position_loss: 1.7461 - val_loss: 10.7356 - val_out_stats_loss: 4.1978 - val_out_counts_loss: 1.7213 - val_out_mean_covariance_loss: 60.6252 - val_out_fielding_position_loss: 1.7853
Epoch 37/1000

Epoch 00037: val_loss did not improve
 - 5s - loss: 10.2967 - out_stats_loss: 4.0204 - out_counts_loss: 1.6475 - out_mean_covariance_loss: 57.8490 - out_fielding_position_loss: 1.7364 - val_loss: 10.7536 - val_out_stats_loss: 4.2053 - val_out_counts_loss: 1.7320 - val_out_mean_covariance_loss: 60.6293 - val_out_fielding_position_loss: 1.7849
Epoch 38/1000

Epoch 00038: val_loss did not improve
 - 5s - loss: 10.3185 - out_stats_loss: 4.0324 - out_counts_loss: 1.6585 - out_mean_covariance_loss: 58.0105 - out_fielding_position_loss: 1.7272 - val_loss: 10.7363 - val_out_stats_loss: 4.1980 - val_out_counts_loss: 1.7294 - val_out_mean_covariance_loss: 60.6222 - val_out_fielding_position_loss: 1.7777
Epoch 39/1000

Epoch 00039: val_loss did not improve
 - 5s - loss: 10.2546 - out_stats_loss: 4.0144 - out_counts_loss: 1.6347 - out_mean_covariance_loss: 57.8592 - out_fielding_position_loss: 1.7126 - val_loss: 10.7377 - val_out_stats_loss: 4.2050 - val_out_counts_loss: 1.7251 - val_out_mean_covariance_loss: 60.6100 - val_out_fielding_position_loss: 1.7771
Epoch 40/1000

Epoch 00040: val_loss improved from 10.73562 to 10.73208, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 5s - loss: 10.2415 - out_stats_loss: 4.0084 - out_counts_loss: 1.6367 - out_mean_covariance_loss: 57.7075 - out_fielding_position_loss: 1.7110 - val_loss: 10.7321 - val_out_stats_loss: 4.1991 - val_out_counts_loss: 1.7363 - val_out_mean_covariance_loss: 60.4515 - val_out_fielding_position_loss: 1.7741
Epoch 41/1000

Epoch 00041: val_loss did not improve
 - 5s - loss: 10.2341 - out_stats_loss: 4.0130 - out_counts_loss: 1.6316 - out_mean_covariance_loss: 57.6681 - out_fielding_position_loss: 1.7061 - val_loss: 10.7498 - val_out_stats_loss: 4.2081 - val_out_counts_loss: 1.7428 - val_out_mean_covariance_loss: 60.5341 - val_out_fielding_position_loss: 1.7722
Epoch 42/1000

Epoch 00042: val_loss did not improve
 - 5s - loss: 10.1665 - out_stats_loss: 3.9868 - out_counts_loss: 1.6212 - out_mean_covariance_loss: 57.1754 - out_fielding_position_loss: 1.6997 - val_loss: 10.7413 - val_out_stats_loss: 4.1985 - val_out_counts_loss: 1.7505 - val_out_mean_covariance_loss: 60.4122 - val_out_fielding_position_loss: 1.7717
Epoch 43/1000

Epoch 00043: val_loss did not improve
 - 5s - loss: 10.1593 - out_stats_loss: 3.9841 - out_counts_loss: 1.6241 - out_mean_covariance_loss: 57.1228 - out_fielding_position_loss: 1.6950 - val_loss: 10.7400 - val_out_stats_loss: 4.2097 - val_out_counts_loss: 1.7380 - val_out_mean_covariance_loss: 60.5441 - val_out_fielding_position_loss: 1.7652
Epoch 44/1000

Epoch 00044: val_loss improved from 10.73208 to 10.69865, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 5s - loss: 10.0986 - out_stats_loss: 3.9682 - out_counts_loss: 1.6017 - out_mean_covariance_loss: 56.8580 - out_fielding_position_loss: 1.6857 - val_loss: 10.6986 - val_out_stats_loss: 4.1881 - val_out_counts_loss: 1.7316 - val_out_mean_covariance_loss: 60.3067 - val_out_fielding_position_loss: 1.7636
Epoch 45/1000

Epoch 00045: val_loss improved from 10.69865 to 10.68617, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 5s - loss: 10.1149 - out_stats_loss: 3.9765 - out_counts_loss: 1.6001 - out_mean_covariance_loss: 57.1576 - out_fielding_position_loss: 1.6804 - val_loss: 10.6862 - val_out_stats_loss: 4.1864 - val_out_counts_loss: 1.7294 - val_out_mean_covariance_loss: 60.2114 - val_out_fielding_position_loss: 1.7597
Epoch 46/1000

Epoch 00046: val_loss did not improve
 - 5s - loss: 10.0403 - out_stats_loss: 3.9580 - out_counts_loss: 1.5873 - out_mean_covariance_loss: 56.5911 - out_fielding_position_loss: 1.6653 - val_loss: 10.7087 - val_out_stats_loss: 4.1990 - val_out_counts_loss: 1.7405 - val_out_mean_covariance_loss: 60.2676 - val_out_fielding_position_loss: 1.7558
Epoch 47/1000

Epoch 00047: val_loss did not improve
 - 5s - loss: 10.0637 - out_stats_loss: 3.9784 - out_counts_loss: 1.5758 - out_mean_covariance_loss: 57.0212 - out_fielding_position_loss: 1.6585 - val_loss: 10.7269 - val_out_stats_loss: 4.2070 - val_out_counts_loss: 1.7507 - val_out_mean_covariance_loss: 60.3562 - val_out_fielding_position_loss: 1.7514
Epoch 48/1000

Epoch 00048: val_loss improved from 10.68617 to 10.68195, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 5s - loss: 10.0964 - out_stats_loss: 3.9879 - out_counts_loss: 1.5863 - out_mean_covariance_loss: 57.2696 - out_fielding_position_loss: 1.6588 - val_loss: 10.6819 - val_out_stats_loss: 4.1809 - val_out_counts_loss: 1.7414 - val_out_mean_covariance_loss: 60.0494 - val_out_fielding_position_loss: 1.7572
Epoch 49/1000

Epoch 00049: val_loss improved from 10.68195 to 10.67981, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 5s - loss: 10.0060 - out_stats_loss: 3.9661 - out_counts_loss: 1.5689 - out_mean_covariance_loss: 56.6227 - out_fielding_position_loss: 1.6398 - val_loss: 10.6798 - val_out_stats_loss: 4.1894 - val_out_counts_loss: 1.7373 - val_out_mean_covariance_loss: 60.0471 - val_out_fielding_position_loss: 1.7507
Epoch 50/1000

Epoch 00050: val_loss did not improve
 - 5s - loss: 9.9948 - out_stats_loss: 3.9542 - out_counts_loss: 1.5743 - out_mean_covariance_loss: 56.4400 - out_fielding_position_loss: 1.6443 - val_loss: 10.7131 - val_out_stats_loss: 4.1910 - val_out_counts_loss: 1.7605 - val_out_mean_covariance_loss: 60.2572 - val_out_fielding_position_loss: 1.7487
Epoch 51/1000

Epoch 00051: val_loss did not improve
 - 5s - loss: 9.9580 - out_stats_loss: 3.9369 - out_counts_loss: 1.5715 - out_mean_covariance_loss: 56.3677 - out_fielding_position_loss: 1.6313 - val_loss: 10.8126 - val_out_stats_loss: 4.2246 - val_out_counts_loss: 1.8186 - val_out_mean_covariance_loss: 60.2756 - val_out_fielding_position_loss: 1.7556
Epoch 52/1000

Epoch 00052: val_loss did not improve
 - 5s - loss: 9.9300 - out_stats_loss: 3.9416 - out_counts_loss: 1.5596 - out_mean_covariance_loss: 56.0868 - out_fielding_position_loss: 1.6244 - val_loss: 10.6932 - val_out_stats_loss: 4.1983 - val_out_counts_loss: 1.7459 - val_out_mean_covariance_loss: 60.1070 - val_out_fielding_position_loss: 1.7436
Epoch 53/1000

Epoch 00053: val_loss improved from 10.67981 to 10.67328, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 5s - loss: 9.9539 - out_stats_loss: 3.9525 - out_counts_loss: 1.5577 - out_mean_covariance_loss: 56.3226 - out_fielding_position_loss: 1.6276 - val_loss: 10.6733 - val_out_stats_loss: 4.1857 - val_out_counts_loss: 1.7491 - val_out_mean_covariance_loss: 59.9980 - val_out_fielding_position_loss: 1.7386
Epoch 54/1000

Epoch 00054: val_loss did not improve
 - 5s - loss: 9.8710 - out_stats_loss: 3.9215 - out_counts_loss: 1.5376 - out_mean_covariance_loss: 55.9952 - out_fielding_position_loss: 1.6121 - val_loss: 10.7149 - val_out_stats_loss: 4.1941 - val_out_counts_loss: 1.7704 - val_out_mean_covariance_loss: 60.1830 - val_out_fielding_position_loss: 1.7413
Epoch 55/1000

Epoch 00055: val_loss improved from 10.67328 to 10.67238, saving model to models/bc/shift1/max2016/simple-rnn/0.h5
 - 5s - loss: 9.8808 - out_stats_loss: 3.9312 - out_counts_loss: 1.5313 - out_mean_covariance_loss: 56.2563 - out_fielding_position_loss: 1.6055 - val_loss: 10.6724 - val_out_stats_loss: 4.1864 - val_out_counts_loss: 1.7524 - val_out_mean_covariance_loss: 59.9802 - val_out_fielding_position_loss: 1.7345
Epoch 56/1000

Epoch 00056: val_loss did not improve
 - 5s - loss: 9.8573 - out_stats_loss: 3.9284 - out_counts_loss: 1.5222 - out_mean_covariance_loss: 56.1335 - out_fielding_position_loss: 1.6000 - val_loss: 10.6992 - val_out_stats_loss: 4.1988 - val_out_counts_loss: 1.7593 - val_out_mean_covariance_loss: 60.1244 - val_out_fielding_position_loss: 1.7349
Epoch 57/1000

Epoch 00057: val_loss did not improve
 - 5s - loss: 9.8075 - out_stats_loss: 3.9059 - out_counts_loss: 1.5241 - out_mean_covariance_loss: 55.7412 - out_fielding_position_loss: 1.5904 - val_loss: 10.6972 - val_out_stats_loss: 4.1932 - val_out_counts_loss: 1.7745 - val_out_mean_covariance_loss: 60.0003 - val_out_fielding_position_loss: 1.7295
Epoch 58/1000

Epoch 00058: val_loss did not improve
 - 5s - loss: 9.7780 - out_stats_loss: 3.8906 - out_counts_loss: 1.5211 - out_mean_covariance_loss: 55.4614 - out_fielding_position_loss: 1.5931 - val_loss: 10.7179 - val_out_stats_loss: 4.2039 - val_out_counts_loss: 1.7793 - val_out_mean_covariance_loss: 60.0428 - val_out_fielding_position_loss: 1.7325
Epoch 59/1000

Epoch 00059: val_loss did not improve
 - 5s - loss: 9.7687 - out_stats_loss: 3.8927 - out_counts_loss: 1.5107 - out_mean_covariance_loss: 55.4223 - out_fielding_position_loss: 1.5942 - val_loss: 10.6893 - val_out_stats_loss: 4.1957 - val_out_counts_loss: 1.7691 - val_out_mean_covariance_loss: 59.9347 - val_out_fielding_position_loss: 1.7278
Epoch 60/1000

Epoch 00060: val_loss did not improve
 - 5s - loss: 9.8233 - out_stats_loss: 3.9264 - out_counts_loss: 1.5022 - out_mean_covariance_loss: 56.2124 - out_fielding_position_loss: 1.5840 - val_loss: 10.7066 - val_out_stats_loss: 4.1993 - val_out_counts_loss: 1.7790 - val_out_mean_covariance_loss: 59.9510 - val_out_fielding_position_loss: 1.7308
Epoch 61/1000

Epoch 00061: val_loss did not improve
 - 5s - loss: 9.7545 - out_stats_loss: 3.9105 - out_counts_loss: 1.4898 - out_mean_covariance_loss: 55.7299 - out_fielding_position_loss: 1.5678 - val_loss: 10.7210 - val_out_stats_loss: 4.2137 - val_out_counts_loss: 1.7791 - val_out_mean_covariance_loss: 60.0239 - val_out_fielding_position_loss: 1.7270
Epoch 62/1000

Epoch 00062: val_loss did not improve
 - 5s - loss: 9.7540 - out_stats_loss: 3.9001 - out_counts_loss: 1.5163 - out_mean_covariance_loss: 55.3118 - out_fielding_position_loss: 1.5720 - val_loss: 10.7448 - val_out_stats_loss: 4.2135 - val_out_counts_loss: 1.8023 - val_out_mean_covariance_loss: 60.0466 - val_out_fielding_position_loss: 1.7267
Epoch 63/1000

Epoch 00063: val_loss did not improve
 - 5s - loss: 9.6687 - out_stats_loss: 3.8806 - out_counts_loss: 1.4807 - out_mean_covariance_loss: 55.1057 - out_fielding_position_loss: 1.5521 - val_loss: 10.7573 - val_out_stats_loss: 4.2321 - val_out_counts_loss: 1.7936 - val_out_mean_covariance_loss: 60.1238 - val_out_fielding_position_loss: 1.7254
Epoch 64/1000

Epoch 00064: val_loss did not improve
 - 5s - loss: 9.6480 - out_stats_loss: 3.8767 - out_counts_loss: 1.4740 - out_mean_covariance_loss: 54.9591 - out_fielding_position_loss: 1.5493 - val_loss: 10.7072 - val_out_stats_loss: 4.1995 - val_out_counts_loss: 1.7907 - val_out_mean_covariance_loss: 59.9376 - val_out_fielding_position_loss: 1.7201
Epoch 65/1000

Epoch 00065: val_loss did not improve
 - 5s - loss: 9.6424 - out_stats_loss: 3.8652 - out_counts_loss: 1.4738 - out_mean_covariance_loss: 54.9604 - out_fielding_position_loss: 1.5553 - val_loss: 10.7108 - val_out_stats_loss: 4.1982 - val_out_counts_loss: 1.7944 - val_out_mean_covariance_loss: 59.8923 - val_out_fielding_position_loss: 1.7235
Epoch 66/1000

Epoch 00066: val_loss did not improve
 - 5s - loss: 9.5963 - out_stats_loss: 3.8588 - out_counts_loss: 1.4642 - out_mean_covariance_loss: 54.5809 - out_fielding_position_loss: 1.5442 - val_loss: 10.7139 - val_out_stats_loss: 4.2050 - val_out_counts_loss: 1.7980 - val_out_mean_covariance_loss: 59.8591 - val_out_fielding_position_loss: 1.7179
Epoch 67/1000

Epoch 00067: val_loss did not improve
 - 5s - loss: 9.6484 - out_stats_loss: 3.8800 - out_counts_loss: 1.4641 - out_mean_covariance_loss: 55.1961 - out_fielding_position_loss: 1.5444 - val_loss: 10.7721 - val_out_stats_loss: 4.2310 - val_out_counts_loss: 1.8161 - val_out_mean_covariance_loss: 60.1181 - val_out_fielding_position_loss: 1.7191
Epoch 68/1000

Epoch 00068: val_loss did not improve
 - 5s - loss: 9.6402 - out_stats_loss: 3.8799 - out_counts_loss: 1.4552 - out_mean_covariance_loss: 55.0772 - out_fielding_position_loss: 1.5512 - val_loss: 10.7280 - val_out_stats_loss: 4.2097 - val_out_counts_loss: 1.8069 - val_out_mean_covariance_loss: 59.9200 - val_out_fielding_position_loss: 1.7154
Epoch 69/1000

Epoch 00069: val_loss did not improve
 - 5s - loss: 9.5965 - out_stats_loss: 3.8670 - out_counts_loss: 1.4499 - out_mean_covariance_loss: 54.9888 - out_fielding_position_loss: 1.5302 - val_loss: 10.7629 - val_out_stats_loss: 4.2247 - val_out_counts_loss: 1.8209 - val_out_mean_covariance_loss: 60.0492 - val_out_fielding_position_loss: 1.7149
Epoch 70/1000

Epoch 00070: val_loss did not improve
 - 5s - loss: 9.5725 - out_stats_loss: 3.8628 - out_counts_loss: 1.4467 - out_mean_covariance_loss: 54.8372 - out_fielding_position_loss: 1.5211 - val_loss: 10.7633 - val_out_stats_loss: 4.2220 - val_out_counts_loss: 1.8237 - val_out_mean_covariance_loss: 60.0691 - val_out_fielding_position_loss: 1.7141
Epoch 71/1000

Epoch 00071: val_loss did not improve
 - 5s - loss: 9.5801 - out_stats_loss: 3.8671 - out_counts_loss: 1.4499 - out_mean_covariance_loss: 54.8308 - out_fielding_position_loss: 1.5215 - val_loss: 10.7646 - val_out_stats_loss: 4.2230 - val_out_counts_loss: 1.8267 - val_out_mean_covariance_loss: 59.9645 - val_out_fielding_position_loss: 1.7167
Epoch 72/1000

Epoch 00072: val_loss did not improve
 - 5s - loss: 9.5103 - out_stats_loss: 3.8382 - out_counts_loss: 1.4328 - out_mean_covariance_loss: 54.3615 - out_fielding_position_loss: 1.5212 - val_loss: 10.7896 - val_out_stats_loss: 4.2296 - val_out_counts_loss: 1.8442 - val_out_mean_covariance_loss: 60.0450 - val_out_fielding_position_loss: 1.7136
Epoch 73/1000

Epoch 00073: val_loss did not improve
 - 5s - loss: 9.4912 - out_stats_loss: 3.8388 - out_counts_loss: 1.4279 - out_mean_covariance_loss: 54.3075 - out_fielding_position_loss: 1.5091 - val_loss: 10.7796 - val_out_stats_loss: 4.2293 - val_out_counts_loss: 1.8343 - val_out_mean_covariance_loss: 60.1037 - val_out_fielding_position_loss: 1.7109
Epoch 74/1000

Epoch 00074: val_loss did not improve
 - 5s - loss: 9.4760 - out_stats_loss: 3.8328 - out_counts_loss: 1.4264 - out_mean_covariance_loss: 54.2223 - out_fielding_position_loss: 1.5057 - val_loss: 10.8426 - val_out_stats_loss: 4.2476 - val_out_counts_loss: 1.8678 - val_out_mean_covariance_loss: 60.1755 - val_out_fielding_position_loss: 1.7184
Epoch 75/1000

Epoch 00075: val_loss did not improve
 - 5s - loss: 9.4877 - out_stats_loss: 3.8473 - out_counts_loss: 1.4119 - out_mean_covariance_loss: 54.4197 - out_fielding_position_loss: 1.5075 - val_loss: 10.8303 - val_out_stats_loss: 4.2367 - val_out_counts_loss: 1.8690 - val_out_mean_covariance_loss: 60.1345 - val_out_fielding_position_loss: 1.7179
Epoch 76/1000

Epoch 00076: val_loss did not improve
 - 5s - loss: 9.4057 - out_stats_loss: 3.8167 - out_counts_loss: 1.4127 - out_mean_covariance_loss: 53.6999 - out_fielding_position_loss: 1.4913 - val_loss: 10.7528 - val_out_stats_loss: 4.2145 - val_out_counts_loss: 1.8366 - val_out_mean_covariance_loss: 59.9351 - val_out_fielding_position_loss: 1.7049
Epoch 77/1000

Epoch 00077: val_loss did not improve
 - 5s - loss: 9.4182 - out_stats_loss: 3.8201 - out_counts_loss: 1.4116 - out_mean_covariance_loss: 53.9314 - out_fielding_position_loss: 1.4899 - val_loss: 10.7823 - val_out_stats_loss: 4.2269 - val_out_counts_loss: 1.8477 - val_out_mean_covariance_loss: 59.9844 - val_out_fielding_position_loss: 1.7085
Epoch 78/1000

Epoch 00078: val_loss did not improve
 - 5s - loss: 9.4322 - out_stats_loss: 3.8303 - out_counts_loss: 1.4044 - out_mean_covariance_loss: 54.0823 - out_fielding_position_loss: 1.4934 - val_loss: 10.7688 - val_out_stats_loss: 4.2236 - val_out_counts_loss: 1.8409 - val_out_mean_covariance_loss: 60.0369 - val_out_fielding_position_loss: 1.7025
Epoch 79/1000

Epoch 00079: val_loss did not improve
 - 5s - loss: 9.4125 - out_stats_loss: 3.8288 - out_counts_loss: 1.4050 - out_mean_covariance_loss: 54.0033 - out_fielding_position_loss: 1.4785 - val_loss: 10.8974 - val_out_stats_loss: 4.2554 - val_out_counts_loss: 1.9157 - val_out_mean_covariance_loss: 60.2217 - val_out_fielding_position_loss: 1.7152
Epoch 80/1000

Epoch 00080: val_loss did not improve
 - 5s - loss: 9.4120 - out_stats_loss: 3.8277 - out_counts_loss: 1.4067 - out_mean_covariance_loss: 54.0417 - out_fielding_position_loss: 1.4754 - val_loss: 10.8857 - val_out_stats_loss: 4.2539 - val_out_counts_loss: 1.9045 - val_out_mean_covariance_loss: 60.2026 - val_out_fielding_position_loss: 1.7171
Epoch 81/1000

Epoch 00081: val_loss did not improve
 - 5s - loss: 9.3646 - out_stats_loss: 3.8131 - out_counts_loss: 1.3849 - out_mean_covariance_loss: 53.8727 - out_fielding_position_loss: 1.4729 - val_loss: 10.8544 - val_out_stats_loss: 4.2478 - val_out_counts_loss: 1.8912 - val_out_mean_covariance_loss: 60.0836 - val_out_fielding_position_loss: 1.7112
Epoch 82/1000

Epoch 00082: val_loss did not improve
 - 5s - loss: 9.3514 - out_stats_loss: 3.8108 - out_counts_loss: 1.3791 - out_mean_covariance_loss: 53.8533 - out_fielding_position_loss: 1.4688 - val_loss: 10.8026 - val_out_stats_loss: 4.2294 - val_out_counts_loss: 1.8723 - val_out_mean_covariance_loss: 60.0053 - val_out_fielding_position_loss: 1.7006
Epoch 83/1000

Epoch 00083: val_loss did not improve
 - 5s - loss: 9.3208 - out_stats_loss: 3.8029 - out_counts_loss: 1.3680 - out_mean_covariance_loss: 53.7998 - out_fielding_position_loss: 1.4599 - val_loss: 10.8821 - val_out_stats_loss: 4.2484 - val_out_counts_loss: 1.9091 - val_out_mean_covariance_loss: 60.2421 - val_out_fielding_position_loss: 1.7124
Epoch 84/1000

Epoch 00084: val_loss did not improve
 - 5s - loss: 9.3167 - out_stats_loss: 3.8045 - out_counts_loss: 1.3634 - out_mean_covariance_loss: 53.6678 - out_fielding_position_loss: 1.4654 - val_loss: 10.8114 - val_out_stats_loss: 4.2288 - val_out_counts_loss: 1.8806 - val_out_mean_covariance_loss: 60.0758 - val_out_fielding_position_loss: 1.6983
Epoch 85/1000

Epoch 00085: val_loss did not improve
 - 5s - loss: 9.2986 - out_stats_loss: 3.8029 - out_counts_loss: 1.3559 - out_mean_covariance_loss: 53.8230 - out_fielding_position_loss: 1.4486 - val_loss: 10.8451 - val_out_stats_loss: 4.2463 - val_out_counts_loss: 1.8943 - val_out_mean_covariance_loss: 60.0497 - val_out_fielding_position_loss: 1.7020
Epoch 86/1000

Epoch 00086: val_loss did not improve
 - 5s - loss: 9.2678 - out_stats_loss: 3.7895 - out_counts_loss: 1.3620 - out_mean_covariance_loss: 53.3911 - out_fielding_position_loss: 1.4467 - val_loss: 10.8478 - val_out_stats_loss: 4.2431 - val_out_counts_loss: 1.8963 - val_out_mean_covariance_loss: 60.1571 - val_out_fielding_position_loss: 1.7005
Epoch 87/1000

Epoch 00087: val_loss did not improve
 - 5s - loss: 9.2352 - out_stats_loss: 3.7769 - out_counts_loss: 1.3439 - out_mean_covariance_loss: 53.3767 - out_fielding_position_loss: 1.4455 - val_loss: 10.8672 - val_out_stats_loss: 4.2469 - val_out_counts_loss: 1.9057 - val_out_mean_covariance_loss: 60.2003 - val_out_fielding_position_loss: 1.7046
Epoch 88/1000

Epoch 00088: val_loss did not improve
 - 5s - loss: 9.2455 - out_stats_loss: 3.7813 - out_counts_loss: 1.3563 - out_mean_covariance_loss: 53.2736 - out_fielding_position_loss: 1.4441 - val_loss: 10.9285 - val_out_stats_loss: 4.2664 - val_out_counts_loss: 1.9348 - val_out_mean_covariance_loss: 60.3691 - val_out_fielding_position_loss: 1.7088
Epoch 89/1000

Epoch 00089: val_loss did not improve
 - 5s - loss: 9.2673 - out_stats_loss: 3.8065 - out_counts_loss: 1.3439 - out_mean_covariance_loss: 53.6269 - out_fielding_position_loss: 1.4356 - val_loss: 10.8968 - val_out_stats_loss: 4.2540 - val_out_counts_loss: 1.9265 - val_out_mean_covariance_loss: 60.2417 - val_out_fielding_position_loss: 1.7042
Epoch 90/1000

Epoch 00090: val_loss did not improve
 - 5s - loss: 9.1900 - out_stats_loss: 3.7646 - out_counts_loss: 1.3450 - out_mean_covariance_loss: 52.9066 - out_fielding_position_loss: 1.4351 - val_loss: 10.8743 - val_out_stats_loss: 4.2514 - val_out_counts_loss: 1.9139 - val_out_mean_covariance_loss: 60.2648 - val_out_fielding_position_loss: 1.6958
Epoch 91/1000

Epoch 00091: val_loss did not improve
 - 5s - loss: 9.1618 - out_stats_loss: 3.7619 - out_counts_loss: 1.3334 - out_mean_covariance_loss: 52.8044 - out_fielding_position_loss: 1.4263 - val_loss: 10.8758 - val_out_stats_loss: 4.2476 - val_out_counts_loss: 1.9212 - val_out_mean_covariance_loss: 60.2067 - val_out_fielding_position_loss: 1.6967
Epoch 92/1000

Epoch 00092: val_loss did not improve
 - 5s - loss: 9.1625 - out_stats_loss: 3.7645 - out_counts_loss: 1.3222 - out_mean_covariance_loss: 53.0483 - out_fielding_position_loss: 1.4233 - val_loss: 10.8905 - val_out_stats_loss: 4.2447 - val_out_counts_loss: 1.9308 - val_out_mean_covariance_loss: 60.3091 - val_out_fielding_position_loss: 1.6996
Epoch 93/1000

Epoch 00093: val_loss did not improve
 - 5s - loss: 9.1620 - out_stats_loss: 3.7704 - out_counts_loss: 1.3181 - out_mean_covariance_loss: 53.0620 - out_fielding_position_loss: 1.4205 - val_loss: 10.8968 - val_out_stats_loss: 4.2455 - val_out_counts_loss: 1.9343 - val_out_mean_covariance_loss: 60.3588 - val_out_fielding_position_loss: 1.6991
Epoch 94/1000

Epoch 00094: val_loss did not improve
 - 5s - loss: 9.1252 - out_stats_loss: 3.7470 - out_counts_loss: 1.3211 - out_mean_covariance_loss: 52.8859 - out_fielding_position_loss: 1.4129 - val_loss: 10.9567 - val_out_stats_loss: 4.2707 - val_out_counts_loss: 1.9651 - val_out_mean_covariance_loss: 60.4367 - val_out_fielding_position_loss: 1.6991
Epoch 95/1000

Epoch 00095: val_loss did not improve
 - 5s - loss: 9.1662 - out_stats_loss: 3.7763 - out_counts_loss: 1.3158 - out_mean_covariance_loss: 53.1705 - out_fielding_position_loss: 1.4155 - val_loss: 11.0188 - val_out_stats_loss: 4.2836 - val_out_counts_loss: 1.9927 - val_out_mean_covariance_loss: 60.5156 - val_out_fielding_position_loss: 1.7168
Epoch 96/1000

Epoch 00096: val_loss did not improve
 - 5s - loss: 9.1658 - out_stats_loss: 3.7671 - out_counts_loss: 1.3333 - out_mean_covariance_loss: 53.0258 - out_fielding_position_loss: 1.4142 - val_loss: 10.9841 - val_out_stats_loss: 4.2692 - val_out_counts_loss: 1.9808 - val_out_mean_covariance_loss: 60.5505 - val_out_fielding_position_loss: 1.7065
Epoch 97/1000

Epoch 00097: val_loss did not improve
 - 5s - loss: 9.1643 - out_stats_loss: 3.7669 - out_counts_loss: 1.3227 - out_mean_covariance_loss: 53.2057 - out_fielding_position_loss: 1.4143 - val_loss: 10.9158 - val_out_stats_loss: 4.2589 - val_out_counts_loss: 1.9372 - val_out_mean_covariance_loss: 60.5068 - val_out_fielding_position_loss: 1.6944
Epoch 98/1000

Epoch 00098: val_loss did not improve
 - 5s - loss: 9.0650 - out_stats_loss: 3.7392 - out_counts_loss: 1.2970 - out_mean_covariance_loss: 52.5530 - out_fielding_position_loss: 1.4012 - val_loss: 10.9609 - val_out_stats_loss: 4.2722 - val_out_counts_loss: 1.9689 - val_out_mean_covariance_loss: 60.4463 - val_out_fielding_position_loss: 1.6975
Epoch 99/1000

Epoch 00099: val_loss did not improve
 - 5s - loss: 9.0619 - out_stats_loss: 3.7390 - out_counts_loss: 1.3028 - out_mean_covariance_loss: 52.5219 - out_fielding_position_loss: 1.3940 - val_loss: 10.9807 - val_out_stats_loss: 4.2788 - val_out_counts_loss: 1.9726 - val_out_mean_covariance_loss: 60.5276 - val_out_fielding_position_loss: 1.7029
Epoch 100/1000

Epoch 00100: val_loss did not improve
 - 5s - loss: 9.0648 - out_stats_loss: 3.7398 - out_counts_loss: 1.2963 - out_mean_covariance_loss: 52.6863 - out_fielding_position_loss: 1.3944 - val_loss: 10.9230 - val_out_stats_loss: 4.2530 - val_out_counts_loss: 1.9568 - val_out_mean_covariance_loss: 60.3106 - val_out_fielding_position_loss: 1.6976
Epoch 101/1000

Epoch 00101: val_loss did not improve
 - 5s - loss: 9.0536 - out_stats_loss: 3.7408 - out_counts_loss: 1.3002 - out_mean_covariance_loss: 52.4022 - out_fielding_position_loss: 1.3924 - val_loss: 10.9497 - val_out_stats_loss: 4.2612 - val_out_counts_loss: 1.9752 - val_out_mean_covariance_loss: 60.2862 - val_out_fielding_position_loss: 1.6990
Epoch 102/1000

Epoch 00102: val_loss did not improve
 - 5s - loss: 9.0476 - out_stats_loss: 3.7455 - out_counts_loss: 1.2956 - out_mean_covariance_loss: 52.4540 - out_fielding_position_loss: 1.3838 - val_loss: 10.9607 - val_out_stats_loss: 4.2610 - val_out_counts_loss: 1.9799 - val_out_mean_covariance_loss: 60.6190 - val_out_fielding_position_loss: 1.6888
Epoch 103/1000

Epoch 00103: val_loss did not improve
 - 5s - loss: 9.0397 - out_stats_loss: 3.7352 - out_counts_loss: 1.2982 - out_mean_covariance_loss: 52.4747 - out_fielding_position_loss: 1.3826 - val_loss: 10.9530 - val_out_stats_loss: 4.2665 - val_out_counts_loss: 1.9764 - val_out_mean_covariance_loss: 60.4132 - val_out_fielding_position_loss: 1.6894
Epoch 104/1000

Epoch 00104: val_loss did not improve
 - 5s - loss: 9.0169 - out_stats_loss: 3.7380 - out_counts_loss: 1.2785 - out_mean_covariance_loss: 52.4298 - out_fielding_position_loss: 1.3789 - val_loss: 11.0014 - val_out_stats_loss: 4.2736 - val_out_counts_loss: 2.0031 - val_out_mean_covariance_loss: 60.5863 - val_out_fielding_position_loss: 1.6954
Epoch 105/1000

Epoch 00105: val_loss did not improve
 - 5s - loss: 8.9767 - out_stats_loss: 3.7213 - out_counts_loss: 1.2768 - out_mean_covariance_loss: 52.2426 - out_fielding_position_loss: 1.3665 - val_loss: 10.9821 - val_out_stats_loss: 4.2717 - val_out_counts_loss: 1.9892 - val_out_mean_covariance_loss: 60.5096 - val_out_fielding_position_loss: 1.6958
/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Years: [1958,2016]
Shift: 1
Fold: 4
Training into models/bc/shift1/max2016/simple-rnn/0.h5
/usr/local/lib/python3.5/dist-packages/keras/legacy/layers.py:533: UserWarning: The `MaxoutDense` layer is deprecated and will be removed after 06/2017.
  warnings.warn('The `MaxoutDense` layer is deprecated '
