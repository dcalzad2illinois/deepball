__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
in_age (InputLayer)             (None, None, 2)      0                                            
__________________________________________________________________________________________________
in_bio (InputLayer)             (None, None, 7)      0                                            
__________________________________________________________________________________________________
in_fielding_position (InputLaye (None, None, 2)      0                                            
__________________________________________________________________________________________________
in_out_fielding_position (Input (None, None, 12)     0                                            
__________________________________________________________________________________________________
in_out_league_offense (InputLay (None, None, 9)      0                                            
__________________________________________________________________________________________________
in_out_park_factors (InputLayer (None, None, 8)      0                                            
__________________________________________________________________________________________________
in_out_plate_discipline (InputL (None, None, 8)      0                                            
__________________________________________________________________________________________________
in_out_running (InputLayer)     (None, None, 18)     0                                            
__________________________________________________________________________________________________
in_out_saber (InputLayer)       (None, None, 14)     0                                            
__________________________________________________________________________________________________
in_out_stats_extended (InputLay (None, None, 36)     0                                            
__________________________________________________________________________________________________
in_park_factors (InputLayer)    (None, None, 8)      0                                            
__________________________________________________________________________________________________
masked_in_age (Masking)         (None, None, 2)      0           in_age[0][0]                     
__________________________________________________________________________________________________
masked_in_bio (Masking)         (None, None, 7)      0           in_bio[0][0]                     
__________________________________________________________________________________________________
masked_in_fielding_position (Ma (None, None, 2)      0           in_fielding_position[0][0]       
__________________________________________________________________________________________________
masked_in_out_fielding_position (None, None, 12)     0           in_out_fielding_position[0][0]   
__________________________________________________________________________________________________
masked_in_out_league_offense (M (None, None, 9)      0           in_out_league_offense[0][0]      
__________________________________________________________________________________________________
masked_in_out_park_factors (Mas (None, None, 8)      0           in_out_park_factors[0][0]        
__________________________________________________________________________________________________
masked_in_out_plate_discipline  (None, None, 8)      0           in_out_plate_discipline[0][0]    
__________________________________________________________________________________________________
masked_in_out_running (Masking) (None, None, 18)     0           in_out_running[0][0]             
__________________________________________________________________________________________________
masked_in_out_saber (Masking)   (None, None, 14)     0           in_out_saber[0][0]               
__________________________________________________________________________________________________
masked_in_out_stats_extended (M (None, None, 36)     0           in_out_stats_extended[0][0]      
__________________________________________________________________________________________________
masked_in_park_factors (Masking (None, None, 8)      0           in_park_factors[0][0]            
__________________________________________________________________________________________________
time_distributed_6 (TimeDistrib (None, None, 1)      0           masked_in_age[0][0]              
__________________________________________________________________________________________________
time_distributed_11 (TimeDistri (None, None, 6)      0           masked_in_bio[0][0]              
__________________________________________________________________________________________________
time_distributed_7 (TimeDistrib (None, None, 1)      0           masked_in_fielding_position[0][0]
__________________________________________________________________________________________________
time_distributed_1 (TimeDistrib (None, None, 11)     0           masked_in_out_fielding_position[0
__________________________________________________________________________________________________
time_distributed_8 (TimeDistrib (None, None, 8)      0           masked_in_out_league_offense[0][0
__________________________________________________________________________________________________
time_distributed_10 (TimeDistri (None, None, 7)      0           masked_in_out_park_factors[0][0] 
__________________________________________________________________________________________________
time_distributed_3 (TimeDistrib (None, None, 7)      0           masked_in_out_plate_discipline[0]
__________________________________________________________________________________________________
time_distributed_4 (TimeDistrib (None, None, 17)     0           masked_in_out_running[0][0]      
__________________________________________________________________________________________________
time_distributed_2 (TimeDistrib (None, None, 13)     0           masked_in_out_saber[0][0]        
__________________________________________________________________________________________________
time_distributed_5 (TimeDistrib (None, None, 35)     0           masked_in_out_stats_extended[0][0
__________________________________________________________________________________________________
time_distributed_9 (TimeDistrib (None, None, 7)      0           masked_in_park_factors[0][0]     
__________________________________________________________________________________________________
norm_in_age (BatchNormalization (None, None, 1)      4           time_distributed_6[0][0]         
__________________________________________________________________________________________________
norm_in_bio (BatchNormalization (None, None, 6)      24          time_distributed_11[0][0]        
__________________________________________________________________________________________________
norm_in_fielding_position (Batc (None, None, 1)      4           time_distributed_7[0][0]         
__________________________________________________________________________________________________
norm_in_out_fielding_position ( (None, None, 11)     44          time_distributed_1[0][0]         
__________________________________________________________________________________________________
norm_in_out_league_offense (Bat (None, None, 8)      32          time_distributed_8[0][0]         
__________________________________________________________________________________________________
norm_in_out_park_factors (Batch (None, None, 7)      28          time_distributed_10[0][0]        
__________________________________________________________________________________________________
norm_in_out_plate_discipline (B (None, None, 7)      28          time_distributed_3[0][0]         
__________________________________________________________________________________________________2018-02-06 03:52:51.326884: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-02-06 03:52:58.010737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: eca0:00:00.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2018-02-06 03:52:58.010780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: eca0:00:00.0, compute capability: 3.7)

norm_in_out_running (BatchNorma (None, None, 17)     68          time_distributed_4[0][0]         
__________________________________________________________________________________________________
norm_in_out_saber (BatchNormali (None, None, 13)     52          time_distributed_2[0][0]         
__________________________________________________________________________________________________
norm_in_out_stats_extended (Bat (None, None, 35)     140         time_distributed_5[0][0]         
__________________________________________________________________________________________________
norm_in_park_factors (BatchNorm (None, None, 7)      28          time_distributed_9[0][0]         
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, None, 113)    0           norm_in_age[0][0]                
                                                                 norm_in_bio[0][0]                
                                                                 norm_in_fielding_position[0][0]  
                                                                 norm_in_out_fielding_position[0][
                                                                 norm_in_out_league_offense[0][0] 
                                                                 norm_in_out_park_factors[0][0]   
                                                                 norm_in_out_plate_discipline[0][0
                                                                 norm_in_out_running[0][0]        
                                                                 norm_in_out_saber[0][0]          
                                                                 norm_in_out_stats_extended[0][0] 
                                                                 norm_in_park_factors[0][0]       
__________________________________________________________________________________________________
gru_1 (GRU)                     (None, None, 113)    76953       concatenate_1[0][0]              
__________________________________________________________________________________________________
gru_2 (GRU)                     (None, None, 113)    76953       gru_1[0][0]                      
__________________________________________________________________________________________________
mv_out_stats (TimeDistributed)  (None, None, 5)      4560        gru_2[0][0]                      
__________________________________________________________________________________________________
mv_out_counts (TimeDistributed) (None, None, 3)      2736        gru_2[0][0]                      
__________________________________________________________________________________________________
mv_out_mean_covariance (TimeDis (None, None, 72)     65664       gru_2[0][0]                      
__________________________________________________________________________________________________
mv_out_fielding_position (TimeD (None, None, 11)     10032       gru_2[0][0]                      
__________________________________________________________________________________________________
out_stats (Activation)          (None, None, 5)      0           mv_out_stats[0][0]               
__________________________________________________________________________________________________
out_counts (Activation)         (None, None, 3)      0           mv_out_counts[0][0]              
__________________________________________________________________________________________________
out_mean_covariance (Activation (None, None, 72)     0           mv_out_mean_covariance[0][0]     
__________________________________________________________________________________________________
out_fielding_position (Activati (None, None, 11)     0           mv_out_fielding_position[0][0]   
==================================================================================================
Total params: 237,350
Trainable params: 237,124
Non-trainable params: 226
__________________________________________________________________________________________________
Train on 5748 samples, validate on 1385 samples
Epoch 1/1000

Epoch 00001: val_loss improved from inf to 18.47722, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 15s - loss: 20.3351 - out_stats_loss: 7.0618 - out_counts_loss: 3.5332 - out_mean_covariance_loss: 104.5885 - out_fielding_position_loss: 4.5107 - val_loss: 18.4772 - val_out_stats_loss: 6.5440 - val_out_counts_loss: 2.7361 - val_out_mean_covariance_loss: 98.8750 - val_out_fielding_position_loss: 4.2534
Epoch 2/1000

Epoch 00002: val_loss improved from 18.47722 to 15.80076, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 16.9692 - out_stats_loss: 5.9533 - out_counts_loss: 2.4211 - out_mean_covariance_loss: 90.7705 - out_fielding_position_loss: 4.0563 - val_loss: 15.8008 - val_out_stats_loss: 5.5639 - val_out_counts_loss: 2.1418 - val_out_mean_covariance_loss: 85.2915 - val_out_fielding_position_loss: 3.8305
Epoch 3/1000

Epoch 00003: val_loss improved from 15.80076 to 14.32222, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 14.9440 - out_stats_loss: 5.2126 - out_counts_loss: 2.1228 - out_mean_covariance_loss: 78.7197 - out_fielding_position_loss: 3.6727 - val_loss: 14.3222 - val_out_stats_loss: 5.0679 - val_out_counts_loss: 1.9869 - val_out_mean_covariance_loss: 76.4905 - val_out_fielding_position_loss: 3.4429
Epoch 4/1000

Epoch 00004: val_loss improved from 14.32222 to 13.36760, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 13.7488 - out_stats_loss: 4.8450 - out_counts_loss: 1.9942 - out_mean_covariance_loss: 72.5159 - out_fielding_position_loss: 3.2838 - val_loss: 13.3676 - val_out_stats_loss: 4.8305 - val_out_counts_loss: 1.8683 - val_out_mean_covariance_loss: 71.8506 - val_out_fielding_position_loss: 3.0762
Epoch 5/1000

Epoch 00005: val_loss improved from 13.36760 to 12.80022, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 13.0141 - out_stats_loss: 4.6868 - out_counts_loss: 1.9269 - out_mean_covariance_loss: 69.3443 - out_fielding_position_loss: 2.9333 - val_loss: 12.8002 - val_out_stats_loss: 4.7284 - val_out_counts_loss: 1.8322 - val_out_mean_covariance_loss: 69.8575 - val_out_fielding_position_loss: 2.7467
Epoch 6/1000

Epoch 00006: val_loss improved from 12.80022 to 12.41970, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 12.5738 - out_stats_loss: 4.6179 - out_counts_loss: 1.9029 - out_mean_covariance_loss: 67.7753 - out_fielding_position_loss: 2.6642 - val_loss: 12.4197 - val_out_stats_loss: 4.6758 - val_out_counts_loss: 1.8163 - val_out_mean_covariance_loss: 68.5381 - val_out_fielding_position_loss: 2.5007
Epoch 7/1000

Epoch 00007: val_loss improved from 12.41970 to 12.20009, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 12.2204 - out_stats_loss: 4.5448 - out_counts_loss: 1.8919 - out_mean_covariance_loss: 66.4067 - out_fielding_position_loss: 2.4635 - val_loss: 12.2001 - val_out_stats_loss: 4.6536 - val_out_counts_loss: 1.8355 - val_out_mean_covariance_loss: 67.9615 - val_out_fielding_position_loss: 2.3129
Epoch 8/1000

Epoch 00008: val_loss improved from 12.20009 to 11.92264, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 11.9787 - out_stats_loss: 4.5112 - out_counts_loss: 1.8885 - out_mean_covariance_loss: 65.3757 - out_fielding_position_loss: 2.3102 - val_loss: 11.9226 - val_out_stats_loss: 4.5896 - val_out_counts_loss: 1.7953 - val_out_mean_covariance_loss: 66.8316 - val_out_fielding_position_loss: 2.1962
Epoch 9/1000

Epoch 00009: val_loss improved from 11.92264 to 11.74873, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 11.7514 - out_stats_loss: 4.4654 - out_counts_loss: 1.8647 - out_mean_covariance_loss: 64.4646 - out_fielding_position_loss: 2.1981 - val_loss: 11.7487 - val_out_stats_loss: 4.5441 - val_out_counts_loss: 1.7913 - val_out_mean_covariance_loss: 66.1699 - val_out_fielding_position_loss: 2.1049
Epoch 10/1000

Epoch 00010: val_loss improved from 11.74873 to 11.63375, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 11.6002 - out_stats_loss: 4.4197 - out_counts_loss: 1.8416 - out_mean_covariance_loss: 64.2665 - out_fielding_position_loss: 2.1256 - val_loss: 11.6337 - val_out_stats_loss: 4.5139 - val_out_counts_loss: 1.7888 - val_out_mean_covariance_loss: 65.8014 - val_out_fielding_position_loss: 2.0409
Epoch 11/1000

Epoch 00011: val_loss improved from 11.63375 to 11.51243, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 11.5085 - out_stats_loss: 4.4019 - out_counts_loss: 1.8424 - out_mean_covariance_loss: 63.7867 - out_fielding_position_loss: 2.0749 - val_loss: 11.5124 - val_out_stats_loss: 4.4749 - val_out_counts_loss: 1.7782 - val_out_mean_covariance_loss: 65.1991 - val_out_fielding_position_loss: 1.9993
Epoch 12/1000

Epoch 00012: val_loss improved from 11.51243 to 11.45611, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 11.3601 - out_stats_loss: 4.3581 - out_counts_loss: 1.8119 - out_mean_covariance_loss: 63.2409 - out_fielding_position_loss: 2.0280 - val_loss: 11.4561 - val_out_stats_loss: 4.4696 - val_out_counts_loss: 1.7754 - val_out_mean_covariance_loss: 64.9167 - val_out_fielding_position_loss: 1.9653
Epoch 13/1000

Epoch 00013: val_loss improved from 11.45611 to 11.37068, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 11.2699 - out_stats_loss: 4.3237 - out_counts_loss: 1.8201 - out_mean_covariance_loss: 62.6920 - out_fielding_position_loss: 1.9915 - val_loss: 11.3707 - val_out_stats_loss: 4.4271 - val_out_counts_loss: 1.7696 - val_out_mean_covariance_loss: 64.6041 - val_out_fielding_position_loss: 1.9438
Epoch 14/1000

Epoch 00014: val_loss improved from 11.37068 to 11.32955, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 11.2366 - out_stats_loss: 4.3219 - out_counts_loss: 1.8029 - out_mean_covariance_loss: 62.5979 - out_fielding_position_loss: 1.9819 - val_loss: 11.3295 - val_out_stats_loss: 4.4212 - val_out_counts_loss: 1.7639 - val_out_mean_covariance_loss: 64.2618 - val_out_fielding_position_loss: 1.9313
Epoch 15/1000

Epoch 00015: val_loss improved from 11.32955 to 11.26968, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 11.1557 - out_stats_loss: 4.2962 - out_counts_loss: 1.7953 - out_mean_covariance_loss: 62.2063 - out_fielding_position_loss: 1.9538 - val_loss: 11.2697 - val_out_stats_loss: 4.3953 - val_out_counts_loss: 1.7620 - val_out_mean_covariance_loss: 63.9865 - val_out_fielding_position_loss: 1.9130
Epoch 16/1000

Epoch 00016: val_loss improved from 11.26968 to 11.20833, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 11.0466 - out_stats_loss: 4.2467 - out_counts_loss: 1.7840 - out_mean_covariance_loss: 61.4338 - out_fielding_position_loss: 1.9442 - val_loss: 11.2083 - val_out_stats_loss: 4.3773 - val_out_counts_loss: 1.7485 - val_out_mean_covariance_loss: 63.6802 - val_out_fielding_position_loss: 1.8985
Epoch 17/1000

Epoch 00017: val_loss improved from 11.20833 to 11.17564, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 10.9915 - out_stats_loss: 4.2327 - out_counts_loss: 1.7756 - out_mean_covariance_loss: 61.0129 - out_fielding_position_loss: 1.9326 - val_loss: 11.1756 - val_out_stats_loss: 4.3638 - val_out_counts_loss: 1.7504 - val_out_mean_covariance_loss: 63.4197 - val_out_fielding_position_loss: 1.8904
Epoch 18/1000

Epoch 00018: val_loss improved from 11.17564 to 11.15374, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 11.0106 - out_stats_loss: 4.2468 - out_counts_loss: 1.7806 - out_mean_covariance_loss: 61.3676 - out_fielding_position_loss: 1.9149 - val_loss: 11.1537 - val_out_stats_loss: 4.3508 - val_out_counts_loss: 1.7481 - val_out_mean_covariance_loss: 63.3205 - val_out_fielding_position_loss: 1.8889
Epoch 19/1000

Epoch 00019: val_loss improved from 11.15374 to 11.12648, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 10.9107 - out_stats_loss: 4.2060 - out_counts_loss: 1.7799 - out_mean_covariance_loss: 60.6454 - out_fielding_position_loss: 1.8926 - val_loss: 11.1265 - val_out_stats_loss: 4.3517 - val_out_counts_loss: 1.7472 - val_out_mean_covariance_loss: 63.0172 - val_out_fielding_position_loss: 1.8768
Epoch 20/1000

Epoch 00020: val_loss improved from 11.12648 to 11.08846, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 10.8799 - out_stats_loss: 4.1947 - out_counts_loss: 1.7613 - out_mean_covariance_loss: 60.5280 - out_fielding_position_loss: 1.8975 - val_loss: 11.0885 - val_out_stats_loss: 4.3326 - val_out_counts_loss: 1.7418 - val_out_mean_covariance_loss: 62.8942 - val_out_fielding_position_loss: 1.8693
Epoch 21/1000

Epoch 00021: val_loss improved from 11.08846 to 11.07025, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 10.7682 - out_stats_loss: 4.1608 - out_counts_loss: 1.7485 - out_mean_covariance_loss: 59.7315 - out_fielding_position_loss: 1.8724 - val_loss: 11.0702 - val_out_stats_loss: 4.3185 - val_out_counts_loss: 1.7528 - val_out_mean_covariance_loss: 62.7301 - val_out_fielding_position_loss: 1.8625
Epoch 22/1000

Epoch 00022: val_loss improved from 11.07025 to 11.05031, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 10.8025 - out_stats_loss: 4.1727 - out_counts_loss: 1.7478 - out_mean_covariance_loss: 60.2389 - out_fielding_position_loss: 1.8700 - val_loss: 11.0503 - val_out_stats_loss: 4.3227 - val_out_counts_loss: 1.7348 - val_out_mean_covariance_loss: 62.6749 - val_out_fielding_position_loss: 1.8590
Epoch 23/1000

Epoch 00023: val_loss improved from 11.05031 to 11.03186, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 10.7645 - out_stats_loss: 4.1632 - out_counts_loss: 1.7497 - out_mean_covariance_loss: 59.9995 - out_fielding_position_loss: 1.8516 - val_loss: 11.0319 - val_out_stats_loss: 4.3162 - val_out_counts_loss: 1.7425 - val_out_mean_covariance_loss: 62.5223 - val_out_fielding_position_loss: 1.8471
Epoch 24/1000

Epoch 00024: val_loss improved from 11.03186 to 10.98548, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 10.7551 - out_stats_loss: 4.1694 - out_counts_loss: 1.7361 - out_mean_covariance_loss: 59.9740 - out_fielding_position_loss: 1.8509 - val_loss: 10.9855 - val_out_stats_loss: 4.2898 - val_out_counts_loss: 1.7363 - val_out_mean_covariance_loss: 62.2164 - val_out_fielding_position_loss: 1.8486
Epoch 25/1000

Epoch 00025: val_loss did not improve
 - 5s - loss: 10.6961 - out_stats_loss: 4.1495 - out_counts_loss: 1.7183 - out_mean_covariance_loss: 59.7162 - out_fielding_position_loss: 1.8425 - val_loss: 10.9866 - val_out_stats_loss: 4.2985 - val_out_counts_loss: 1.7345 - val_out_mean_covariance_loss: 62.2830 - val_out_fielding_position_loss: 1.8394
Epoch 26/1000

Epoch 00026: val_loss did not improve
 - 5s - loss: 10.6692 - out_stats_loss: 4.1310 - out_counts_loss: 1.7332 - out_mean_covariance_loss: 59.4567 - out_fielding_position_loss: 1.8322 - val_loss: 11.0207 - val_out_stats_loss: 4.2989 - val_out_counts_loss: 1.7685 - val_out_mean_covariance_loss: 62.2566 - val_out_fielding_position_loss: 1.8405
Epoch 27/1000

Epoch 00027: val_loss improved from 10.98548 to 10.93264, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 10.6278 - out_stats_loss: 4.1233 - out_counts_loss: 1.7118 - out_mean_covariance_loss: 59.2709 - out_fielding_position_loss: 1.8292 - val_loss: 10.9326 - val_out_stats_loss: 4.2835 - val_out_counts_loss: 1.7252 - val_out_mean_covariance_loss: 61.8153 - val_out_fielding_position_loss: 1.8332
Epoch 28/1000

Epoch 00028: val_loss improved from 10.93264 to 10.91576, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 10.6226 - out_stats_loss: 4.1330 - out_counts_loss: 1.7034 - out_mean_covariance_loss: 59.5479 - out_fielding_position_loss: 1.8088 - val_loss: 10.9158 - val_out_stats_loss: 4.2727 - val_out_counts_loss: 1.7282 - val_out_mean_covariance_loss: 61.7440 - val_out_fielding_position_loss: 1.8276
Epoch 29/1000

Epoch 00029: val_loss did not improve
 - 5s - loss: 10.5535 - out_stats_loss: 4.0939 - out_counts_loss: 1.7038 - out_mean_covariance_loss: 58.9219 - out_fielding_position_loss: 1.8096 - val_loss: 10.9384 - val_out_stats_loss: 4.2843 - val_out_counts_loss: 1.7418 - val_out_mean_covariance_loss: 61.7568 - val_out_fielding_position_loss: 1.8245
Epoch 30/1000

Epoch 00030: val_loss improved from 10.91576 to 10.87544, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 10.5481 - out_stats_loss: 4.1078 - out_counts_loss: 1.6938 - out_mean_covariance_loss: 59.1586 - out_fielding_position_loss: 1.7886 - val_loss: 10.8754 - val_out_stats_loss: 4.2585 - val_out_counts_loss: 1.7265 - val_out_mean_covariance_loss: 61.4900 - val_out_fielding_position_loss: 1.8159
Epoch 31/1000

Epoch 00031: val_loss did not improve
 - 5s - loss: 10.4712 - out_stats_loss: 4.0804 - out_counts_loss: 1.6800 - out_mean_covariance_loss: 58.5453 - out_fielding_position_loss: 1.7834 - val_loss: 10.8968 - val_out_stats_loss: 4.2758 - val_out_counts_loss: 1.7260 - val_out_mean_covariance_loss: 61.5982 - val_out_fielding_position_loss: 1.8151
Epoch 32/1000

Epoch 00032: val_loss improved from 10.87544 to 10.86479, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 10.4246 - out_stats_loss: 4.0613 - out_counts_loss: 1.6784 - out_mean_covariance_loss: 58.0591 - out_fielding_position_loss: 1.7819 - val_loss: 10.8648 - val_out_stats_loss: 4.2522 - val_out_counts_loss: 1.7317 - val_out_mean_covariance_loss: 61.4309 - val_out_fielding_position_loss: 1.8094
Epoch 33/1000

Epoch 00033: val_loss improved from 10.86479 to 10.85042, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 10.4316 - out_stats_loss: 4.0681 - out_counts_loss: 1.6778 - out_mean_covariance_loss: 58.3094 - out_fielding_position_loss: 1.7702 - val_loss: 10.8504 - val_out_stats_loss: 4.2503 - val_out_counts_loss: 1.7255 - val_out_mean_covariance_loss: 61.3378 - val_out_fielding_position_loss: 1.8077
Epoch 34/1000

Epoch 00034: val_loss improved from 10.85042 to 10.84846, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 10.4311 - out_stats_loss: 4.0741 - out_counts_loss: 1.6605 - out_mean_covariance_loss: 58.4588 - out_fielding_position_loss: 1.7735 - val_loss: 10.8485 - val_out_stats_loss: 4.2558 - val_out_counts_loss: 1.7256 - val_out_mean_covariance_loss: 61.2581 - val_out_fielding_position_loss: 1.8042
Epoch 35/1000

Epoch 00035: val_loss improved from 10.84846 to 10.82717, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 10.3561 - out_stats_loss: 4.0478 - out_counts_loss: 1.6502 - out_mean_covariance_loss: 57.9752 - out_fielding_position_loss: 1.7594 - val_loss: 10.8272 - val_out_stats_loss: 4.2442 - val_out_counts_loss: 1.7240 - val_out_mean_covariance_loss: 61.1632 - val_out_fielding_position_loss: 1.8008
Epoch 36/1000

Epoch 00036: val_loss did not improve
 - 5s - loss: 10.3298 - out_stats_loss: 4.0330 - out_counts_loss: 1.6533 - out_mean_covariance_loss: 57.8281 - out_fielding_position_loss: 1.7522 - val_loss: 10.8399 - val_out_stats_loss: 4.2408 - val_out_counts_loss: 1.7406 - val_out_mean_covariance_loss: 61.1747 - val_out_fielding_position_loss: 1.7998
Epoch 37/1000

Epoch 00037: val_loss did not improve
 - 5s - loss: 10.3908 - out_stats_loss: 4.0639 - out_counts_loss: 1.6543 - out_mean_covariance_loss: 58.2739 - out_fielding_position_loss: 1.7589 - val_loss: 10.8932 - val_out_stats_loss: 4.2640 - val_out_counts_loss: 1.7665 - val_out_mean_covariance_loss: 61.2837 - val_out_fielding_position_loss: 1.7985
Epoch 38/1000

Epoch 00038: val_loss improved from 10.82717 to 10.82360, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 10.3251 - out_stats_loss: 4.0483 - out_counts_loss: 1.6406 - out_mean_covariance_loss: 57.9756 - out_fielding_position_loss: 1.7375 - val_loss: 10.8236 - val_out_stats_loss: 4.2519 - val_out_counts_loss: 1.7288 - val_out_mean_covariance_loss: 61.0753 - val_out_fielding_position_loss: 1.7891
Epoch 39/1000

Epoch 00039: val_loss improved from 10.82360 to 10.80871, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 10.2280 - out_stats_loss: 4.0111 - out_counts_loss: 1.6253 - out_mean_covariance_loss: 57.2426 - out_fielding_position_loss: 1.7295 - val_loss: 10.8087 - val_out_stats_loss: 4.2493 - val_out_counts_loss: 1.7243 - val_out_mean_covariance_loss: 61.0412 - val_out_fielding_position_loss: 1.7831
Epoch 40/1000

Epoch 00040: val_loss improved from 10.80871 to 10.78166, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 10.1945 - out_stats_loss: 3.9948 - out_counts_loss: 1.6133 - out_mean_covariance_loss: 57.2692 - out_fielding_position_loss: 1.7230 - val_loss: 10.7817 - val_out_stats_loss: 4.2274 - val_out_counts_loss: 1.7291 - val_out_mean_covariance_loss: 60.8727 - val_out_fielding_position_loss: 1.7816
Epoch 41/1000

Epoch 00041: val_loss did not improve
 - 5s - loss: 10.2014 - out_stats_loss: 3.9989 - out_counts_loss: 1.6205 - out_mean_covariance_loss: 57.2638 - out_fielding_position_loss: 1.7188 - val_loss: 10.7843 - val_out_stats_loss: 4.2359 - val_out_counts_loss: 1.7316 - val_out_mean_covariance_loss: 60.8511 - val_out_fielding_position_loss: 1.7743
Epoch 42/1000

Epoch 00042: val_loss did not improve
 - 5s - loss: 10.1625 - out_stats_loss: 3.9908 - out_counts_loss: 1.6166 - out_mean_covariance_loss: 56.9668 - out_fielding_position_loss: 1.7067 - val_loss: 10.7864 - val_out_stats_loss: 4.2351 - val_out_counts_loss: 1.7358 - val_out_mean_covariance_loss: 60.8875 - val_out_fielding_position_loss: 1.7711
Epoch 43/1000

Epoch 00043: val_loss did not improve
 - 5s - loss: 10.1369 - out_stats_loss: 3.9732 - out_counts_loss: 1.6288 - out_mean_covariance_loss: 56.6236 - out_fielding_position_loss: 1.7037 - val_loss: 10.8273 - val_out_stats_loss: 4.2416 - val_out_counts_loss: 1.7649 - val_out_mean_covariance_loss: 60.9395 - val_out_fielding_position_loss: 1.7737
Epoch 44/1000

Epoch 00044: val_loss improved from 10.78166 to 10.78038, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 10.1631 - out_stats_loss: 3.9929 - out_counts_loss: 1.6058 - out_mean_covariance_loss: 57.2996 - out_fielding_position_loss: 1.6994 - val_loss: 10.7804 - val_out_stats_loss: 4.2292 - val_out_counts_loss: 1.7462 - val_out_mean_covariance_loss: 60.7546 - val_out_fielding_position_loss: 1.7672
Epoch 45/1000

Epoch 00045: val_loss improved from 10.78038 to 10.74988, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 10.1208 - out_stats_loss: 3.9947 - out_counts_loss: 1.5866 - out_mean_covariance_loss: 57.1795 - out_fielding_position_loss: 1.6805 - val_loss: 10.7499 - val_out_stats_loss: 4.2211 - val_out_counts_loss: 1.7315 - val_out_mean_covariance_loss: 60.6632 - val_out_fielding_position_loss: 1.7641
Epoch 46/1000

Epoch 00046: val_loss did not improve
 - 5s - loss: 10.1497 - out_stats_loss: 3.9999 - out_counts_loss: 1.5961 - out_mean_covariance_loss: 57.3232 - out_fielding_position_loss: 1.6875 - val_loss: 10.7660 - val_out_stats_loss: 4.2296 - val_out_counts_loss: 1.7366 - val_out_mean_covariance_loss: 60.7968 - val_out_fielding_position_loss: 1.7599
Epoch 47/1000

Epoch 00047: val_loss did not improve
 - 5s - loss: 10.0800 - out_stats_loss: 3.9875 - out_counts_loss: 1.5727 - out_mean_covariance_loss: 57.0256 - out_fielding_position_loss: 1.6684 - val_loss: 10.7960 - val_out_stats_loss: 4.2334 - val_out_counts_loss: 1.7701 - val_out_mean_covariance_loss: 60.6625 - val_out_fielding_position_loss: 1.7594
Epoch 48/1000

Epoch 00048: val_loss did not improve
 - 5s - loss: 10.0655 - out_stats_loss: 3.9741 - out_counts_loss: 1.5908 - out_mean_covariance_loss: 56.5255 - out_fielding_position_loss: 1.6743 - val_loss: 10.8040 - val_out_stats_loss: 4.2451 - val_out_counts_loss: 1.7713 - val_out_mean_covariance_loss: 60.6934 - val_out_fielding_position_loss: 1.7529
Epoch 49/1000

Epoch 00049: val_loss improved from 10.74988 to 10.74294, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 9.9877 - out_stats_loss: 3.9556 - out_counts_loss: 1.5608 - out_mean_covariance_loss: 56.1526 - out_fielding_position_loss: 1.6637 - val_loss: 10.7429 - val_out_stats_loss: 4.2222 - val_out_counts_loss: 1.7421 - val_out_mean_covariance_loss: 60.5615 - val_out_fielding_position_loss: 1.7505
Epoch 50/1000

Epoch 00050: val_loss improved from 10.74294 to 10.73715, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 9.9971 - out_stats_loss: 3.9602 - out_counts_loss: 1.5729 - out_mean_covariance_loss: 56.3310 - out_fielding_position_loss: 1.6475 - val_loss: 10.7372 - val_out_stats_loss: 4.2199 - val_out_counts_loss: 1.7446 - val_out_mean_covariance_loss: 60.4885 - val_out_fielding_position_loss: 1.7482
Epoch 51/1000

Epoch 00051: val_loss did not improve
 - 5s - loss: 9.9603 - out_stats_loss: 3.9517 - out_counts_loss: 1.5584 - out_mean_covariance_loss: 56.1689 - out_fielding_position_loss: 1.6417 - val_loss: 10.8236 - val_out_stats_loss: 4.2625 - val_out_counts_loss: 1.7855 - val_out_mean_covariance_loss: 60.5976 - val_out_fielding_position_loss: 1.7458
Epoch 52/1000

Epoch 00052: val_loss did not improve
 - 5s - loss: 9.9743 - out_stats_loss: 3.9608 - out_counts_loss: 1.5561 - out_mean_covariance_loss: 56.3918 - out_fielding_position_loss: 1.6378 - val_loss: 10.7460 - val_out_stats_loss: 4.2275 - val_out_counts_loss: 1.7529 - val_out_mean_covariance_loss: 60.4938 - val_out_fielding_position_loss: 1.7409
Epoch 53/1000

Epoch 00053: val_loss improved from 10.73715 to 10.72472, saving model to models/bc/shift1/max2015/simple-rnn/0.h5
 - 5s - loss: 9.9355 - out_stats_loss: 3.9488 - out_counts_loss: 1.5412 - out_mean_covariance_loss: 56.4024 - out_fielding_position_loss: 1.6253 - val_loss: 10.7247 - val_out_stats_loss: 4.2188 - val_out_counts_loss: 1.7457 - val_out_mean_covariance_loss: 60.4613 - val_out_fielding_position_loss: 1.7372
Epoch 54/1000

Epoch 00054: val_loss did not improve
 - 5s - loss: 9.8812 - out_stats_loss: 3.9269 - out_counts_loss: 1.5380 - out_mean_covariance_loss: 55.8528 - out_fielding_position_loss: 1.6236 - val_loss: 10.7645 - val_out_stats_loss: 4.2474 - val_out_counts_loss: 1.7559 - val_out_mean_covariance_loss: 60.5370 - val_out_fielding_position_loss: 1.7344
Epoch 55/1000

Epoch 00055: val_loss did not improve
 - 5s - loss: 9.8534 - out_stats_loss: 3.9170 - out_counts_loss: 1.5351 - out_mean_covariance_loss: 55.6149 - out_fielding_position_loss: 1.6205 - val_loss: 10.8146 - val_out_stats_loss: 4.2378 - val_out_counts_loss: 1.8097 - val_out_mean_covariance_loss: 60.5739 - val_out_fielding_position_loss: 1.7384
Epoch 56/1000

Epoch 00056: val_loss did not improve
 - 5s - loss: 9.8642 - out_stats_loss: 3.9275 - out_counts_loss: 1.5256 - out_mean_covariance_loss: 55.8790 - out_fielding_position_loss: 1.6171 - val_loss: 10.7637 - val_out_stats_loss: 4.2299 - val_out_counts_loss: 1.7771 - val_out_mean_covariance_loss: 60.4623 - val_out_fielding_position_loss: 1.7336
Epoch 57/1000

Epoch 00057: val_loss did not improve
 - 5s - loss: 9.8370 - out_stats_loss: 3.9270 - out_counts_loss: 1.5219 - out_mean_covariance_loss: 55.6992 - out_fielding_position_loss: 1.6032 - val_loss: 10.8921 - val_out_stats_loss: 4.2703 - val_out_counts_loss: 1.8477 - val_out_mean_covariance_loss: 60.7470 - val_out_fielding_position_loss: 1.7367
Epoch 58/1000

Epoch 00058: val_loss did not improve
 - 5s - loss: 9.8268 - out_stats_loss: 3.9246 - out_counts_loss: 1.5307 - out_mean_covariance_loss: 55.3275 - out_fielding_position_loss: 1.6050 - val_loss: 10.7362 - val_out_stats_loss: 4.2274 - val_out_counts_loss: 1.7673 - val_out_mean_covariance_loss: 60.3482 - val_out_fielding_position_loss: 1.7241
Epoch 59/1000

Epoch 00059: val_loss did not improve
 - 4s - loss: 9.8426 - out_stats_loss: 3.9328 - out_counts_loss: 1.5068 - out_mean_covariance_loss: 56.1024 - out_fielding_position_loss: 1.5978 - val_loss: 10.7330 - val_out_stats_loss: 4.2294 - val_out_counts_loss: 1.7654 - val_out_mean_covariance_loss: 60.2342 - val_out_fielding_position_loss: 1.7265
Epoch 60/1000

Epoch 00060: val_loss did not improve
 - 5s - loss: 9.7271 - out_stats_loss: 3.8894 - out_counts_loss: 1.4987 - out_mean_covariance_loss: 55.1160 - out_fielding_position_loss: 1.5832 - val_loss: 10.7526 - val_out_stats_loss: 4.2487 - val_out_counts_loss: 1.7652 - val_out_mean_covariance_loss: 60.3867 - val_out_fielding_position_loss: 1.7193
Epoch 61/1000

Epoch 00061: val_loss did not improve
 - 5s - loss: 9.7317 - out_stats_loss: 3.9055 - out_counts_loss: 1.4889 - out_mean_covariance_loss: 55.1638 - out_fielding_position_loss: 1.5791 - val_loss: 10.7917 - val_out_stats_loss: 4.2379 - val_out_counts_loss: 1.8116 - val_out_mean_covariance_loss: 60.4264 - val_out_fielding_position_loss: 1.7209
Epoch 62/1000

Epoch 00062: val_loss did not improve
 - 5s - loss: 9.7346 - out_stats_loss: 3.9042 - out_counts_loss: 1.4953 - out_mean_covariance_loss: 55.1895 - out_fielding_position_loss: 1.5755 - val_loss: 10.7337 - val_out_stats_loss: 4.2283 - val_out_counts_loss: 1.7776 - val_out_mean_covariance_loss: 60.2115 - val_out_fielding_position_loss: 1.7173
Epoch 63/1000

Epoch 00063: val_loss did not improve
 - 5s - loss: 9.6987 - out_stats_loss: 3.8946 - out_counts_loss: 1.4839 - out_mean_covariance_loss: 55.1255 - out_fielding_position_loss: 1.5639 - val_loss: 10.7586 - val_out_stats_loss: 4.2367 - val_out_counts_loss: 1.7970 - val_out_mean_covariance_loss: 60.2177 - val_out_fielding_position_loss: 1.7140
Epoch 64/1000

Epoch 00064: val_loss did not improve
 - 5s - loss: 9.7028 - out_stats_loss: 3.9058 - out_counts_loss: 1.4812 - out_mean_covariance_loss: 55.1277 - out_fielding_position_loss: 1.5593 - val_loss: 10.7510 - val_out_stats_loss: 4.2324 - val_out_counts_loss: 1.7954 - val_out_mean_covariance_loss: 60.2125 - val_out_fielding_position_loss: 1.7127
Epoch 65/1000

Epoch 00065: val_loss did not improve
 - 4s - loss: 9.6620 - out_stats_loss: 3.8809 - out_counts_loss: 1.4746 - out_mean_covariance_loss: 54.8893 - out_fielding_position_loss: 1.5621 - val_loss: 10.9036 - val_out_stats_loss: 4.3021 - val_out_counts_loss: 1.8495 - val_out_mean_covariance_loss: 60.7148 - val_out_fielding_position_loss: 1.7163
Epoch 66/1000

Epoch 00066: val_loss did not improve
 - 5s - loss: 9.6035 - out_stats_loss: 3.8659 - out_counts_loss: 1.4595 - out_mean_covariance_loss: 54.5826 - out_fielding_position_loss: 1.5490 - val_loss: 10.7654 - val_out_stats_loss: 4.2345 - val_out_counts_loss: 1.8135 - val_out_mean_covariance_loss: 60.1739 - val_out_fielding_position_loss: 1.7086
Epoch 67/1000

Epoch 00067: val_loss did not improve
 - 4s - loss: 9.6421 - out_stats_loss: 3.8835 - out_counts_loss: 1.4672 - out_mean_covariance_loss: 54.8220 - out_fielding_position_loss: 1.5502 - val_loss: 10.7609 - val_out_stats_loss: 4.2376 - val_out_counts_loss: 1.8062 - val_out_mean_covariance_loss: 60.2212 - val_out_fielding_position_loss: 1.7060
Epoch 68/1000

Epoch 00068: val_loss did not improve
 - 5s - loss: 9.6329 - out_stats_loss: 3.8834 - out_counts_loss: 1.4595 - out_mean_covariance_loss: 54.8736 - out_fielding_position_loss: 1.5464 - val_loss: 10.7523 - val_out_stats_loss: 4.2351 - val_out_counts_loss: 1.8049 - val_out_mean_covariance_loss: 60.1832 - val_out_fielding_position_loss: 1.7031
Epoch 69/1000

Epoch 00069: val_loss did not improve
 - 5s - loss: 9.6367 - out_stats_loss: 3.8906 - out_counts_loss: 1.4614 - out_mean_covariance_loss: 54.9415 - out_fielding_position_loss: 1.5377 - val_loss: 10.7461 - val_out_stats_loss: 4.2381 - val_out_counts_loss: 1.8040 - val_out_mean_covariance_loss: 60.0832 - val_out_fielding_position_loss: 1.6998
Epoch 70/1000

Epoch 00070: val_loss did not improve
 - 5s - loss: 9.5332 - out_stats_loss: 3.8522 - out_counts_loss: 1.4413 - out_mean_covariance_loss: 54.2059 - out_fielding_position_loss: 1.5294 - val_loss: 10.7433 - val_out_stats_loss: 4.2332 - val_out_counts_loss: 1.8051 - val_out_mean_covariance_loss: 60.1049 - val_out_fielding_position_loss: 1.6997
Epoch 71/1000

Epoch 00071: val_loss did not improve
 - 5s - loss: 9.6008 - out_stats_loss: 3.8856 - out_counts_loss: 1.4450 - out_mean_covariance_loss: 54.8249 - out_fielding_position_loss: 1.5290 - val_loss: 10.7773 - val_out_stats_loss: 4.2487 - val_out_counts_loss: 1.8193 - val_out_mean_covariance_loss: 60.1741 - val_out_fielding_position_loss: 1.7005
Epoch 72/1000

Epoch 00072: val_loss did not improve
 - 5s - loss: 9.4899 - out_stats_loss: 3.8466 - out_counts_loss: 1.4239 - out_mean_covariance_loss: 54.1292 - out_fielding_position_loss: 1.5128 - val_loss: 10.7937 - val_out_stats_loss: 4.2500 - val_out_counts_loss: 1.8334 - val_out_mean_covariance_loss: 60.1434 - val_out_fielding_position_loss: 1.7032
Epoch 73/1000

Epoch 00073: val_loss did not improve
 - 5s - loss: 9.5112 - out_stats_loss: 3.8537 - out_counts_loss: 1.4324 - out_mean_covariance_loss: 54.2210 - out_fielding_position_loss: 1.5141 - val_loss: 10.7796 - val_out_stats_loss: 4.2566 - val_out_counts_loss: 1.8189 - val_out_mean_covariance_loss: 60.1947 - val_out_fielding_position_loss: 1.6944
Epoch 74/1000

Epoch 00074: val_loss did not improve
 - 5s - loss: 9.4843 - out_stats_loss: 3.8532 - out_counts_loss: 1.4198 - out_mean_covariance_loss: 54.1078 - out_fielding_position_loss: 1.5058 - val_loss: 10.8013 - val_out_stats_loss: 4.2492 - val_out_counts_loss: 1.8490 - val_out_mean_covariance_loss: 60.1386 - val_out_fielding_position_loss: 1.6961
Epoch 75/1000

Epoch 00075: val_loss did not improve
 - 5s - loss: 9.4596 - out_stats_loss: 3.8491 - out_counts_loss: 1.4064 - out_mean_covariance_loss: 54.1232 - out_fielding_position_loss: 1.4979 - val_loss: 10.7819 - val_out_stats_loss: 4.2419 - val_out_counts_loss: 1.8350 - val_out_mean_covariance_loss: 60.1204 - val_out_fielding_position_loss: 1.6990
Epoch 76/1000

Epoch 00076: val_loss did not improve
 - 5s - loss: 9.4807 - out_stats_loss: 3.8626 - out_counts_loss: 1.4149 - out_mean_covariance_loss: 54.2619 - out_fielding_position_loss: 1.4900 - val_loss: 10.7895 - val_out_stats_loss: 4.2445 - val_out_counts_loss: 1.8403 - val_out_mean_covariance_loss: 60.2292 - val_out_fielding_position_loss: 1.6933
Epoch 77/1000

Epoch 00077: val_loss did not improve
 - 5s - loss: 9.3938 - out_stats_loss: 3.8248 - out_counts_loss: 1.3985 - out_mean_covariance_loss: 53.6348 - out_fielding_position_loss: 1.4888 - val_loss: 10.7823 - val_out_stats_loss: 4.2458 - val_out_counts_loss: 1.8407 - val_out_mean_covariance_loss: 60.1081 - val_out_fielding_position_loss: 1.6905
Epoch 78/1000

Epoch 00078: val_loss did not improve
 - 5s - loss: 9.4029 - out_stats_loss: 3.8349 - out_counts_loss: 1.3940 - out_mean_covariance_loss: 53.7779 - out_fielding_position_loss: 1.4851 - val_loss: 10.7984 - val_out_stats_loss: 4.2542 - val_out_counts_loss: 1.8435 - val_out_mean_covariance_loss: 60.1916 - val_out_fielding_position_loss: 1.6911
Epoch 79/1000

Epoch 00079: val_loss did not improve
 - 5s - loss: 9.3928 - out_stats_loss: 3.8373 - out_counts_loss: 1.3857 - out_mean_covariance_loss: 53.6630 - out_fielding_position_loss: 1.4866 - val_loss: 10.7840 - val_out_stats_loss: 4.2473 - val_out_counts_loss: 1.8353 - val_out_mean_covariance_loss: 60.2335 - val_out_fielding_position_loss: 1.6896
Epoch 80/1000

Epoch 00080: val_loss did not improve
 - 5s - loss: 9.3816 - out_stats_loss: 3.8266 - out_counts_loss: 1.3838 - out_mean_covariance_loss: 53.8064 - out_fielding_position_loss: 1.4808 - val_loss: 10.8110 - val_out_stats_loss: 4.2605 - val_out_counts_loss: 1.8564 - val_out_mean_covariance_loss: 60.0770 - val_out_fielding_position_loss: 1.6903
Epoch 81/1000

Epoch 00081: val_loss did not improve
 - 4s - loss: 9.4556 - out_stats_loss: 3.8568 - out_counts_loss: 1.3945 - out_mean_covariance_loss: 54.3378 - out_fielding_position_loss: 1.4874 - val_loss: 10.8082 - val_out_stats_loss: 4.2601 - val_out_counts_loss: 1.8542 - val_out_mean_covariance_loss: 60.1493 - val_out_fielding_position_loss: 1.6865
Epoch 82/1000

Epoch 00082: val_loss did not improve
 - 5s - loss: 9.2826 - out_stats_loss: 3.7920 - out_counts_loss: 1.3737 - out_mean_covariance_loss: 52.9571 - out_fielding_position_loss: 1.4691 - val_loss: 10.7937 - val_out_stats_loss: 4.2492 - val_out_counts_loss: 1.8590 - val_out_mean_covariance_loss: 60.0146 - val_out_fielding_position_loss: 1.6848
Epoch 83/1000

Epoch 00083: val_loss did not improve
 - 4s - loss: 9.3175 - out_stats_loss: 3.8073 - out_counts_loss: 1.3806 - out_mean_covariance_loss: 53.2160 - out_fielding_position_loss: 1.4688 - val_loss: 10.7899 - val_out_stats_loss: 4.2505 - val_out_counts_loss: 1.8592 - val_out_mean_covariance_loss: 59.9584 - val_out_fielding_position_loss: 1.6823
Epoch 84/1000

Epoch 00084: val_loss did not improve
 - 4s - loss: 9.2790 - out_stats_loss: 3.7935 - out_counts_loss: 1.3791 - out_mean_covariance_loss: 52.8076 - out_fielding_position_loss: 1.4660 - val_loss: 10.8332 - val_out_stats_loss: 4.2669 - val_out_counts_loss: 1.8781 - val_out_mean_covariance_loss: 60.0174 - val_out_fielding_position_loss: 1.6874
Epoch 85/1000

Epoch 00085: val_loss did not improve
 - 5s - loss: 9.2564 - out_stats_loss: 3.7957 - out_counts_loss: 1.3629 - out_mean_covariance_loss: 52.9299 - out_fielding_position_loss: 1.4514 - val_loss: 10.8302 - val_out_stats_loss: 4.2666 - val_out_counts_loss: 1.8766 - val_out_mean_covariance_loss: 60.0619 - val_out_fielding_position_loss: 1.6838
Epoch 86/1000

Epoch 00086: val_loss did not improve
 - 4s - loss: 9.2828 - out_stats_loss: 3.8055 - out_counts_loss: 1.3572 - out_mean_covariance_loss: 53.3118 - out_fielding_position_loss: 1.4545 - val_loss: 10.8641 - val_out_stats_loss: 4.2866 - val_out_counts_loss: 1.8797 - val_out_mean_covariance_loss: 60.3071 - val_out_fielding_position_loss: 1.6825
Epoch 87/1000

Epoch 00087: val_loss did not improve
 - 5s - loss: 9.2441 - out_stats_loss: 3.7955 - out_counts_loss: 1.3546 - out_mean_covariance_loss: 52.9859 - out_fielding_position_loss: 1.4447 - val_loss: 10.8494 - val_out_stats_loss: 4.2710 - val_out_counts_loss: 1.8880 - val_out_mean_covariance_loss: 60.1475 - val_out_fielding_position_loss: 1.6830
Epoch 88/1000

Epoch 00088: val_loss did not improve
 - 5s - loss: 9.1849 - out_stats_loss: 3.7707 - out_counts_loss: 1.3500 - out_mean_covariance_loss: 52.5176 - out_fielding_position_loss: 1.4383 - val_loss: 10.8935 - val_out_stats_loss: 4.2867 - val_out_counts_loss: 1.9094 - val_out_mean_covariance_loss: 60.2340 - val_out_fielding_position_loss: 1.6856
Epoch 89/1000

Epoch 00089: val_loss did not improve
 - 5s - loss: 9.2000 - out_stats_loss: 3.7866 - out_counts_loss: 1.3368 - out_mean_covariance_loss: 52.8390 - out_fielding_position_loss: 1.4347 - val_loss: 10.8528 - val_out_stats_loss: 4.2695 - val_out_counts_loss: 1.8936 - val_out_mean_covariance_loss: 60.1827 - val_out_fielding_position_loss: 1.6805
Epoch 90/1000

Epoch 00090: val_loss did not improve
 - 5s - loss: 9.1934 - out_stats_loss: 3.7873 - out_counts_loss: 1.3383 - out_mean_covariance_loss: 52.7030 - out_fielding_position_loss: 1.4327 - val_loss: 10.8999 - val_out_stats_loss: 4.2761 - val_out_counts_loss: 1.9307 - val_out_mean_covariance_loss: 60.1793 - val_out_fielding_position_loss: 1.6841
Epoch 91/1000

Epoch 00091: val_loss did not improve
 - 5s - loss: 9.1855 - out_stats_loss: 3.7820 - out_counts_loss: 1.3345 - out_mean_covariance_loss: 52.7221 - out_fielding_position_loss: 1.4330 - val_loss: 10.9403 - val_out_stats_loss: 4.3012 - val_out_counts_loss: 1.9430 - val_out_mean_covariance_loss: 60.2939 - val_out_fielding_position_loss: 1.6815
Epoch 92/1000

Epoch 00092: val_loss did not improve
 - 4s - loss: 9.1614 - out_stats_loss: 3.7725 - out_counts_loss: 1.3446 - out_mean_covariance_loss: 52.3905 - out_fielding_position_loss: 1.4248 - val_loss: 10.8833 - val_out_stats_loss: 4.2760 - val_out_counts_loss: 1.9184 - val_out_mean_covariance_loss: 60.1822 - val_out_fielding_position_loss: 1.6798
Epoch 93/1000

Epoch 00093: val_loss did not improve
 - 5s - loss: 9.1535 - out_stats_loss: 3.7729 - out_counts_loss: 1.3354 - out_mean_covariance_loss: 52.3877 - out_fielding_position_loss: 1.4259 - val_loss: 10.8925 - val_out_stats_loss: 4.2840 - val_out_counts_loss: 1.9163 - val_out_mean_covariance_loss: 60.2471 - val_out_fielding_position_loss: 1.6798
Epoch 94/1000

Epoch 00094: val_loss did not improve
 - 5s - loss: 9.0892 - out_stats_loss: 3.7503 - out_counts_loss: 1.3221 - out_mean_covariance_loss: 52.0929 - out_fielding_position_loss: 1.4122 - val_loss: 10.8500 - val_out_stats_loss: 4.2675 - val_out_counts_loss: 1.8982 - val_out_mean_covariance_loss: 60.2348 - val_out_fielding_position_loss: 1.6725
Epoch 95/1000

Epoch 00095: val_loss did not improve
 - 4s - loss: 9.1161 - out_stats_loss: 3.7613 - out_counts_loss: 1.3224 - out_mean_covariance_loss: 52.3480 - out_fielding_position_loss: 1.4150 - val_loss: 10.8831 - val_out_stats_loss: 4.2705 - val_out_counts_loss: 1.9258 - val_out_mean_covariance_loss: 60.1622 - val_out_fielding_position_loss: 1.6787
Epoch 96/1000

Epoch 00096: val_loss did not improve
 - 4s - loss: 9.0903 - out_stats_loss: 3.7535 - out_counts_loss: 1.3148 - out_mean_covariance_loss: 52.2633 - out_fielding_position_loss: 1.4088 - val_loss: 10.8876 - val_out_stats_loss: 4.2775 - val_out_counts_loss: 1.9252 - val_out_mean_covariance_loss: 60.1545 - val_out_fielding_position_loss: 1.6771
Epoch 97/1000

Epoch 00097: val_loss did not improve
 - 4s - loss: 9.0440 - out_stats_loss: 3.7389 - out_counts_loss: 1.3003 - out_mean_covariance_loss: 51.9159 - out_fielding_position_loss: 1.4090 - val_loss: 10.8900 - val_out_stats_loss: 4.2845 - val_out_counts_loss: 1.9224 - val_out_mean_covariance_loss: 60.1934 - val_out_fielding_position_loss: 1.6734
Epoch 98/1000

Epoch 00098: val_loss did not improve
 - 4s - loss: 9.0313 - out_stats_loss: 3.7440 - out_counts_loss: 1.2903 - out_mean_covariance_loss: 52.0915 - out_fielding_position_loss: 1.3924 - val_loss: 10.9128 - val_out_stats_loss: 4.2960 - val_out_counts_loss: 1.9357 - val_out_mean_covariance_loss: 60.2053 - val_out_fielding_position_loss: 1.6708
Epoch 99/1000

Epoch 00099: val_loss did not improve
 - 4s - loss: 9.0434 - out_stats_loss: 3.7466 - out_counts_loss: 1.3081 - out_mean_covariance_loss: 51.8371 - out_fielding_position_loss: 1.3969 - val_loss: 10.9385 - val_out_stats_loss: 4.3035 - val_out_counts_loss: 1.9364 - val_out_mean_covariance_loss: 60.4901 - val_out_fielding_position_loss: 1.6741
Epoch 100/1000

Epoch 00100: val_loss did not improve
 - 4s - loss: 9.0440 - out_stats_loss: 3.7557 - out_counts_loss: 1.2948 - out_mean_covariance_loss: 52.0283 - out_fielding_position_loss: 1.3920 - val_loss: 10.9257 - val_out_stats_loss: 4.2927 - val_out_counts_loss: 1.9477 - val_out_mean_covariance_loss: 60.2293 - val_out_fielding_position_loss: 1.6738
Epoch 101/1000

Epoch 00101: val_loss did not improve
 - 4s - loss: 9.0293 - out_stats_loss: 3.7433 - out_counts_loss: 1.2968 - out_mean_covariance_loss: 51.9341 - out_fielding_position_loss: 1.3925 - val_loss: 10.9278 - val_out_stats_loss: 4.2980 - val_out_counts_loss: 1.9534 - val_out_mean_covariance_loss: 60.1710 - val_out_fielding_position_loss: 1.6678
Epoch 102/1000

Epoch 00102: val_loss did not improve
 - 4s - loss: 8.9374 - out_stats_loss: 3.7133 - out_counts_loss: 1.2826 - out_mean_covariance_loss: 51.2210 - out_fielding_position_loss: 1.3804 - val_loss: 10.9956 - val_out_stats_loss: 4.3117 - val_out_counts_loss: 1.9937 - val_out_mean_covariance_loss: 60.3239 - val_out_fielding_position_loss: 1.6740
Epoch 103/1000

Epoch 00103: val_loss did not improve
 - 4s - loss: 9.0393 - out_stats_loss: 3.7556 - out_counts_loss: 1.2947 - out_mean_covariance_loss: 52.1186 - out_fielding_position_loss: 1.3831 - val_loss: 10.9151 - val_out_stats_loss: 4.2874 - val_out_counts_loss: 1.9529 - val_out_mean_covariance_loss: 60.0729 - val_out_fielding_position_loss: 1.6712
/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Years: [1958,2015]
Shift: 1
Fold: 4
Training into models/bc/shift1/max2015/simple-rnn/0.h5
/usr/local/lib/python3.5/dist-packages/keras/legacy/layers.py:533: UserWarning: The `MaxoutDense` layer is deprecated and will be removed after 06/2017.
  warnings.warn('The `MaxoutDense` layer is deprecated '
