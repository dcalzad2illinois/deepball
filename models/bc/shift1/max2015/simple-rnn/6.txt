__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
in_age (InputLayer)             (None, None, 2)      0                                            
__________________________________________________________________________________________________
in_bio (InputLayer)             (None, None, 7)      0                                            
__________________________________________________________________________________________________
in_fielding_position (InputLaye (None, None, 2)      0                                            
__________________________________________________________________________________________________
in_out_fielding_position (Input (None, None, 12)     0                                            
__________________________________________________________________________________________________
in_out_league_offense (InputLay (None, None, 9)      0                                            
__________________________________________________________________________________________________
in_out_park_factors (InputLayer (None, None, 8)      0                                            
__________________________________________________________________________________________________
in_out_plate_discipline (InputL (None, None, 8)      0                                            
__________________________________________________________________________________________________
in_out_running (InputLayer)     (None, None, 18)     0                                            
__________________________________________________________________________________________________
in_out_saber (InputLayer)       (None, None, 14)     0                                            
__________________________________________________________________________________________________
in_out_stats_extended (InputLay (None, None, 36)     0                                            
__________________________________________________________________________________________________
in_park_factors (InputLayer)    (None, None, 8)      0                                            
__________________________________________________________________________________________________
masked_in_age (Masking)         (None, None, 2)      0           in_age[0][0]                     
__________________________________________________________________________________________________
masked_in_bio (Masking)         (None, None, 7)      0           in_bio[0][0]                     
__________________________________________________________________________________________________
masked_in_fielding_position (Ma (None, None, 2)      0           in_fielding_position[0][0]       
__________________________________________________________________________________________________
masked_in_out_fielding_position (None, None, 12)     0           in_out_fielding_position[0][0]   
__________________________________________________________________________________________________
masked_in_out_league_offense (M (None, None, 9)      0           in_out_league_offense[0][0]      
__________________________________________________________________________________________________
masked_in_out_park_factors (Mas (None, None, 8)      0           in_out_park_factors[0][0]        
__________________________________________________________________________________________________
masked_in_out_plate_discipline  (None, None, 8)      0           in_out_plate_discipline[0][0]    
__________________________________________________________________________________________________
masked_in_out_running (Masking) (None, None, 18)     0           in_out_running[0][0]             
__________________________________________________________________________________________________
masked_in_out_saber (Masking)   (None, None, 14)     0           in_out_saber[0][0]               
__________________________________________________________________________________________________
masked_in_out_stats_extended (M (None, None, 36)     0           in_out_stats_extended[0][0]      
__________________________________________________________________________________________________
masked_in_park_factors (Masking (None, None, 8)      0           in_park_factors[0][0]            
__________________________________________________________________________________________________
time_distributed_3 (TimeDistrib (None, None, 1)      0           masked_in_age[0][0]              
__________________________________________________________________________________________________
time_distributed_5 (TimeDistrib (None, None, 6)      0           masked_in_bio[0][0]              
__________________________________________________________________________________________________
time_distributed_6 (TimeDistrib (None, None, 1)      0           masked_in_fielding_position[0][0]
__________________________________________________________________________________________________
time_distributed_1 (TimeDistrib (None, None, 11)     0           masked_in_out_fielding_position[0
__________________________________________________________________________________________________
time_distributed_10 (TimeDistri (None, None, 8)      0           masked_in_out_league_offense[0][0
__________________________________________________________________________________________________
time_distributed_8 (TimeDistrib (None, None, 7)      0           masked_in_out_park_factors[0][0] 
__________________________________________________________________________________________________
time_distributed_7 (TimeDistrib (None, None, 7)      0           masked_in_out_plate_discipline[0]
__________________________________________________________________________________________________
time_distributed_2 (TimeDistrib (None, None, 17)     0           masked_in_out_running[0][0]      
__________________________________________________________________________________________________
time_distributed_4 (TimeDistrib (None, None, 13)     0           masked_in_out_saber[0][0]        
__________________________________________________________________________________________________
time_distributed_9 (TimeDistrib (None, None, 35)     0           masked_in_out_stats_extended[0][0
__________________________________________________________________________________________________
time_distributed_11 (TimeDistri (None, None, 7)      0           masked_in_park_factors[0][0]     
__________________________________________________________________________________________________
norm_in_age (BatchNormalization (None, None, 1)      4           time_distributed_3[0][0]         
__________________________________________________________________________________________________
norm_in_bio (BatchNormalization (None, None, 6)      24          time_distributed_5[0][0]         
__________________________________________________________________________________________________
norm_in_fielding_position (Batc (None, None, 1)      4           time_distributed_6[0][0]         
__________________________________________________________________________________________________
norm_in_out_fielding_position ( (None, None, 11)     44          time_distributed_1[0][0]         
__________________________________________________________________________________________________
norm_in_out_league_offense (Bat (None, None, 8)      32          time_distributed_10[0][0]        
__________________________________________________________________________________________________
norm_in_out_park_factors (Batch (None, None, 7)      28          time_distributed_8[0][0]         
__________________________________________________________________________________________________
norm_in_out_plate_discipline (B (None, None, 7)      28          time_distributed_7[0][0]         
__________________________________________________________________________________________________2018-02-07 23:39:38.673811: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-02-07 23:39:45.691545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: eca0:00:00.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2018-02-07 23:39:45.691670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: eca0:00:00.0, compute capability: 3.7)

norm_in_out_running (BatchNorma (None, None, 17)     68          time_distributed_2[0][0]         
__________________________________________________________________________________________________
norm_in_out_saber (BatchNormali (None, None, 13)     52          time_distributed_4[0][0]         
__________________________________________________________________________________________________
norm_in_out_stats_extended (Bat (None, None, 35)     140         time_distributed_9[0][0]         
__________________________________________________________________________________________________
norm_in_park_factors (BatchNorm (None, None, 7)      28          time_distributed_11[0][0]        
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, None, 113)    0           norm_in_age[0][0]                
                                                                 norm_in_bio[0][0]                
                                                                 norm_in_fielding_position[0][0]  
                                                                 norm_in_out_fielding_position[0][
                                                                 norm_in_out_league_offense[0][0] 
                                                                 norm_in_out_park_factors[0][0]   
                                                                 norm_in_out_plate_discipline[0][0
                                                                 norm_in_out_running[0][0]        
                                                                 norm_in_out_saber[0][0]          
                                                                 norm_in_out_stats_extended[0][0] 
                                                                 norm_in_park_factors[0][0]       
__________________________________________________________________________________________________
gru_1 (GRU)                     (None, None, 113)    76953       concatenate_1[0][0]              
__________________________________________________________________________________________________
gru_2 (GRU)                     (None, None, 113)    76953       gru_1[0][0]                      
__________________________________________________________________________________________________
mv_out_stats (TimeDistributed)  (None, None, 5)      4560        gru_2[0][0]                      
__________________________________________________________________________________________________
mv_out_counts (TimeDistributed) (None, None, 3)      2736        gru_2[0][0]                      
__________________________________________________________________________________________________
mv_out_mean_covariance (TimeDis (None, None, 72)     65664       gru_2[0][0]                      
__________________________________________________________________________________________________
mv_out_fielding_position (TimeD (None, None, 11)     10032       gru_2[0][0]                      
__________________________________________________________________________________________________
out_stats (Activation)          (None, None, 5)      0           mv_out_stats[0][0]               
__________________________________________________________________________________________________
out_counts (Activation)         (None, None, 3)      0           mv_out_counts[0][0]              
__________________________________________________________________________________________________
out_mean_covariance (Activation (None, None, 72)     0           mv_out_mean_covariance[0][0]     
__________________________________________________________________________________________________
out_fielding_position (Activati (None, None, 11)     0           mv_out_fielding_position[0][0]   
==================================================================================================
Total params: 237,350
Trainable params: 237,124
Non-trainable params: 226
__________________________________________________________________________________________________
Train on 5748 samples, validate on 1385 samples
Epoch 1/1000

Epoch 00001: val_loss improved from inf to 19.78782, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 16s - loss: 21.6227 - out_stats_loss: 8.2800 - out_counts_loss: 3.6453 - out_mean_covariance_loss: 104.7811 - out_fielding_position_loss: 4.4584 - val_loss: 19.7878 - val_out_stats_loss: 7.7606 - val_out_counts_loss: 2.8331 - val_out_mean_covariance_loss: 99.5152 - val_out_fielding_position_loss: 4.2184
Epoch 2/1000

Epoch 00002: val_loss improved from 19.78782 to 16.89415, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 5s - loss: 17.9784 - out_stats_loss: 6.9850 - out_counts_loss: 2.4587 - out_mean_covariance_loss: 91.0584 - out_fielding_position_loss: 3.9818 - val_loss: 16.8942 - val_out_stats_loss: 6.5937 - val_out_counts_loss: 2.1662 - val_out_mean_covariance_loss: 86.5684 - val_out_fielding_position_loss: 3.8058
Epoch 3/1000

Epoch 00003: val_loss improved from 16.89415 to 15.26008, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 5s - loss: 15.8443 - out_stats_loss: 6.1061 - out_counts_loss: 2.1202 - out_mean_covariance_loss: 80.1010 - out_fielding_position_loss: 3.6129 - val_loss: 15.2601 - val_out_stats_loss: 6.0145 - val_out_counts_loss: 1.9652 - val_out_mean_covariance_loss: 77.9647 - val_out_fielding_position_loss: 3.3822
Epoch 4/1000

Epoch 00004: val_loss improved from 15.26008 to 14.27153, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 5s - loss: 14.5382 - out_stats_loss: 5.6763 - out_counts_loss: 1.9741 - out_mean_covariance_loss: 73.5165 - out_fielding_position_loss: 3.2120 - val_loss: 14.2715 - val_out_stats_loss: 5.7470 - val_out_counts_loss: 1.8712 - val_out_mean_covariance_loss: 73.1121 - val_out_fielding_position_loss: 2.9977
Epoch 5/1000

Epoch 00005: val_loss improved from 14.27153 to 13.63933, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 5s - loss: 13.8232 - out_stats_loss: 5.5201 - out_counts_loss: 1.9158 - out_mean_covariance_loss: 70.1769 - out_fielding_position_loss: 2.8784 - val_loss: 13.6393 - val_out_stats_loss: 5.6123 - val_out_counts_loss: 1.8100 - val_out_mean_covariance_loss: 70.5517 - val_out_fielding_position_loss: 2.6894
Epoch 6/1000

Epoch 00006: val_loss improved from 13.63933 to 13.20333, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 5s - loss: 13.2841 - out_stats_loss: 5.3870 - out_counts_loss: 1.8920 - out_mean_covariance_loss: 67.7704 - out_fielding_position_loss: 2.6166 - val_loss: 13.2033 - val_out_stats_loss: 5.5159 - val_out_counts_loss: 1.8031 - val_out_mean_covariance_loss: 68.8197 - val_out_fielding_position_loss: 2.4434
Epoch 7/1000

Epoch 00007: val_loss improved from 13.20333 to 12.90374, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 5s - loss: 12.9414 - out_stats_loss: 5.3325 - out_counts_loss: 1.8690 - out_mean_covariance_loss: 66.6167 - out_fielding_position_loss: 2.4091 - val_loss: 12.9037 - val_out_stats_loss: 5.4500 - val_out_counts_loss: 1.7967 - val_out_mean_covariance_loss: 67.6299 - val_out_fielding_position_loss: 2.2755
Epoch 8/1000

Epoch 00008: val_loss improved from 12.90374 to 12.68606, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 5s - loss: 12.6247 - out_stats_loss: 5.2450 - out_counts_loss: 1.8641 - out_mean_covariance_loss: 65.0714 - out_fielding_position_loss: 2.2620 - val_loss: 12.6861 - val_out_stats_loss: 5.4050 - val_out_counts_loss: 1.7855 - val_out_mean_covariance_loss: 66.8870 - val_out_fielding_position_loss: 2.1512
Epoch 9/1000

Epoch 00009: val_loss improved from 12.68606 to 12.49830, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 5s - loss: 12.4082 - out_stats_loss: 5.1882 - out_counts_loss: 1.8385 - out_mean_covariance_loss: 64.2808 - out_fielding_position_loss: 2.1675 - val_loss: 12.4983 - val_out_stats_loss: 5.3432 - val_out_counts_loss: 1.7807 - val_out_mean_covariance_loss: 66.2121 - val_out_fielding_position_loss: 2.0638
Epoch 10/1000

Epoch 00010: val_loss improved from 12.49830 to 12.35361, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 5s - loss: 12.3706 - out_stats_loss: 5.1895 - out_counts_loss: 1.8475 - out_mean_covariance_loss: 64.5698 - out_fielding_position_loss: 2.1051 - val_loss: 12.3536 - val_out_stats_loss: 5.2976 - val_out_counts_loss: 1.7718 - val_out_mean_covariance_loss: 65.5661 - val_out_fielding_position_loss: 2.0059
Epoch 11/1000

Epoch 00011: val_loss improved from 12.35361 to 12.28074, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 5s - loss: 12.1826 - out_stats_loss: 5.1215 - out_counts_loss: 1.8307 - out_mean_covariance_loss: 63.3437 - out_fielding_position_loss: 2.0632 - val_loss: 12.2807 - val_out_stats_loss: 5.2653 - val_out_counts_loss: 1.7843 - val_out_mean_covariance_loss: 65.2082 - val_out_fielding_position_loss: 1.9707
Epoch 12/1000

Epoch 00012: val_loss improved from 12.28074 to 12.18224, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 5s - loss: 12.0794 - out_stats_loss: 5.1011 - out_counts_loss: 1.8148 - out_mean_covariance_loss: 63.1218 - out_fielding_position_loss: 2.0074 - val_loss: 12.1822 - val_out_stats_loss: 5.2334 - val_out_counts_loss: 1.7678 - val_out_mean_covariance_loss: 64.8057 - val_out_fielding_position_loss: 1.9408
Epoch 13/1000

Epoch 00013: val_loss improved from 12.18224 to 12.09688, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 5s - loss: 11.9605 - out_stats_loss: 5.0588 - out_counts_loss: 1.8029 - out_mean_covariance_loss: 62.4283 - out_fielding_position_loss: 1.9774 - val_loss: 12.0969 - val_out_stats_loss: 5.2026 - val_out_counts_loss: 1.7594 - val_out_mean_covariance_loss: 64.2368 - val_out_fielding_position_loss: 1.9230
Epoch 14/1000

Epoch 00014: val_loss improved from 12.09688 to 12.07214, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 5s - loss: 11.9024 - out_stats_loss: 5.0423 - out_counts_loss: 1.7886 - out_mean_covariance_loss: 62.4246 - out_fielding_position_loss: 1.9503 - val_loss: 12.0721 - val_out_stats_loss: 5.2031 - val_out_counts_loss: 1.7562 - val_out_mean_covariance_loss: 64.1024 - val_out_fielding_position_loss: 1.9078
Epoch 15/1000

Epoch 00015: val_loss improved from 12.07214 to 11.99132, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 5s - loss: 11.8152 - out_stats_loss: 5.0003 - out_counts_loss: 1.7827 - out_mean_covariance_loss: 61.6369 - out_fielding_position_loss: 1.9503 - val_loss: 11.9913 - val_out_stats_loss: 5.1636 - val_out_counts_loss: 1.7553 - val_out_mean_covariance_loss: 63.6870 - val_out_fielding_position_loss: 1.8880
Epoch 16/1000

Epoch 00016: val_loss improved from 11.99132 to 11.96807, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 5s - loss: 11.7622 - out_stats_loss: 4.9845 - out_counts_loss: 1.7804 - out_mean_covariance_loss: 61.3035 - out_fielding_position_loss: 1.9321 - val_loss: 11.9681 - val_out_stats_loss: 5.1615 - val_out_counts_loss: 1.7503 - val_out_mean_covariance_loss: 63.4885 - val_out_fielding_position_loss: 1.8819
Epoch 17/1000

Epoch 00017: val_loss improved from 11.96807 to 11.91301, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 5s - loss: 11.7214 - out_stats_loss: 4.9834 - out_counts_loss: 1.7591 - out_mean_covariance_loss: 61.4157 - out_fielding_position_loss: 1.9081 - val_loss: 11.9130 - val_out_stats_loss: 5.1380 - val_out_counts_loss: 1.7451 - val_out_mean_covariance_loss: 63.1814 - val_out_fielding_position_loss: 1.8708
Epoch 18/1000

Epoch 00018: val_loss improved from 11.91301 to 11.89183, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 5s - loss: 11.6517 - out_stats_loss: 4.9416 - out_counts_loss: 1.7707 - out_mean_covariance_loss: 60.5369 - out_fielding_position_loss: 1.9126 - val_loss: 11.8918 - val_out_stats_loss: 5.1313 - val_out_counts_loss: 1.7466 - val_out_mean_covariance_loss: 62.9966 - val_out_fielding_position_loss: 1.8641
Epoch 19/1000

Epoch 00019: val_loss improved from 11.89183 to 11.85710, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 5s - loss: 11.5893 - out_stats_loss: 4.9125 - out_counts_loss: 1.7610 - out_mean_covariance_loss: 60.3052 - out_fielding_position_loss: 1.9006 - val_loss: 11.8571 - val_out_stats_loss: 5.1125 - val_out_counts_loss: 1.7449 - val_out_mean_covariance_loss: 62.8236 - val_out_fielding_position_loss: 1.8585
Epoch 20/1000

Epoch 00020: val_loss did not improve
 - 5s - loss: 11.5751 - out_stats_loss: 4.9208 - out_counts_loss: 1.7396 - out_mean_covariance_loss: 60.4053 - out_fielding_position_loss: 1.8944 - val_loss: 11.8669 - val_out_stats_loss: 5.1076 - val_out_counts_loss: 1.7668 - val_out_mean_covariance_loss: 62.8241 - val_out_fielding_position_loss: 1.8513
Epoch 21/1000

Epoch 00021: val_loss did not improve
 - 5s - loss: 11.4898 - out_stats_loss: 4.8782 - out_counts_loss: 1.7476 - out_mean_covariance_loss: 59.8781 - out_fielding_position_loss: 1.8701 - val_loss: 11.8711 - val_out_stats_loss: 5.1241 - val_out_counts_loss: 1.7674 - val_out_mean_covariance_loss: 62.6789 - val_out_fielding_position_loss: 1.8456
Epoch 22/1000

Epoch 00022: val_loss improved from 11.85710 to 11.78773, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 5s - loss: 11.4642 - out_stats_loss: 4.8861 - out_counts_loss: 1.7347 - out_mean_covariance_loss: 59.7651 - out_fielding_position_loss: 1.8551 - val_loss: 11.7877 - val_out_stats_loss: 5.0940 - val_out_counts_loss: 1.7400 - val_out_mean_covariance_loss: 62.3618 - val_out_fielding_position_loss: 1.8356
Epoch 23/1000

Epoch 00023: val_loss improved from 11.78773 to 11.75937, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 5s - loss: 11.4115 - out_stats_loss: 4.8626 - out_counts_loss: 1.7252 - out_mean_covariance_loss: 59.4816 - out_fielding_position_loss: 1.8496 - val_loss: 11.7594 - val_out_stats_loss: 5.0786 - val_out_counts_loss: 1.7408 - val_out_mean_covariance_loss: 62.1675 - val_out_fielding_position_loss: 1.8316
Epoch 24/1000

Epoch 00024: val_loss did not improve
 - 5s - loss: 11.3739 - out_stats_loss: 4.8418 - out_counts_loss: 1.7245 - out_mean_covariance_loss: 59.2743 - out_fielding_position_loss: 1.8439 - val_loss: 11.7729 - val_out_stats_loss: 5.0726 - val_out_counts_loss: 1.7637 - val_out_mean_covariance_loss: 62.1754 - val_out_fielding_position_loss: 1.8278
Epoch 25/1000

Epoch 00025: val_loss improved from 11.75937 to 11.73471, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 5s - loss: 11.3492 - out_stats_loss: 4.8371 - out_counts_loss: 1.7133 - out_mean_covariance_loss: 59.2264 - out_fielding_position_loss: 1.8375 - val_loss: 11.7347 - val_out_stats_loss: 5.0659 - val_out_counts_loss: 1.7453 - val_out_mean_covariance_loss: 61.9802 - val_out_fielding_position_loss: 1.8245
Epoch 26/1000

Epoch 00026: val_loss improved from 11.73471 to 11.70607, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 5s - loss: 11.2818 - out_stats_loss: 4.8238 - out_counts_loss: 1.7063 - out_mean_covariance_loss: 58.7831 - out_fielding_position_loss: 1.8126 - val_loss: 11.7061 - val_out_stats_loss: 5.0622 - val_out_counts_loss: 1.7334 - val_out_mean_covariance_loss: 61.8743 - val_out_fielding_position_loss: 1.8167
Epoch 27/1000

Epoch 00027: val_loss did not improve
 - 5s - loss: 11.2414 - out_stats_loss: 4.8049 - out_counts_loss: 1.7004 - out_mean_covariance_loss: 58.7371 - out_fielding_position_loss: 1.7993 - val_loss: 11.7219 - val_out_stats_loss: 5.0571 - val_out_counts_loss: 1.7544 - val_out_mean_covariance_loss: 61.8412 - val_out_fielding_position_loss: 1.8184
Epoch 28/1000

Epoch 00028: val_loss improved from 11.70607 to 11.67989, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 5s - loss: 11.2495 - out_stats_loss: 4.8064 - out_counts_loss: 1.6974 - out_mean_covariance_loss: 58.6684 - out_fielding_position_loss: 1.8123 - val_loss: 11.6799 - val_out_stats_loss: 5.0441 - val_out_counts_loss: 1.7368 - val_out_mean_covariance_loss: 61.7924 - val_out_fielding_position_loss: 1.8093
Epoch 29/1000

Epoch 00029: val_loss did not improve
 - 5s - loss: 11.2069 - out_stats_loss: 4.7981 - out_counts_loss: 1.6919 - out_mean_covariance_loss: 58.3106 - out_fielding_position_loss: 1.8014 - val_loss: 11.7161 - val_out_stats_loss: 5.0633 - val_out_counts_loss: 1.7574 - val_out_mean_covariance_loss: 61.7571 - val_out_fielding_position_loss: 1.8075
Epoch 30/1000

Epoch 00030: val_loss improved from 11.67989 to 11.66942, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 5s - loss: 11.2412 - out_stats_loss: 4.8151 - out_counts_loss: 1.6895 - out_mean_covariance_loss: 58.8286 - out_fielding_position_loss: 1.7952 - val_loss: 11.6694 - val_out_stats_loss: 5.0514 - val_out_counts_loss: 1.7334 - val_out_mean_covariance_loss: 61.6560 - val_out_fielding_position_loss: 1.8019
Epoch 31/1000

Epoch 00031: val_loss improved from 11.66942 to 11.66504, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 5s - loss: 11.1894 - out_stats_loss: 4.7947 - out_counts_loss: 1.6879 - out_mean_covariance_loss: 58.4860 - out_fielding_position_loss: 1.7825 - val_loss: 11.6650 - val_out_stats_loss: 5.0467 - val_out_counts_loss: 1.7411 - val_out_mean_covariance_loss: 61.5949 - val_out_fielding_position_loss: 1.7974
Epoch 32/1000

Epoch 00032: val_loss improved from 11.66504 to 11.64144, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 5s - loss: 11.1634 - out_stats_loss: 4.7864 - out_counts_loss: 1.6689 - out_mean_covariance_loss: 58.4327 - out_fielding_position_loss: 1.7865 - val_loss: 11.6414 - val_out_stats_loss: 5.0317 - val_out_counts_loss: 1.7401 - val_out_mean_covariance_loss: 61.4311 - val_out_fielding_position_loss: 1.7980
Epoch 33/1000

Epoch 00033: val_loss did not improve
 - 4s - loss: 11.0926 - out_stats_loss: 4.7614 - out_counts_loss: 1.6649 - out_mean_covariance_loss: 58.0331 - out_fielding_position_loss: 1.7647 - val_loss: 11.6770 - val_out_stats_loss: 5.0657 - val_out_counts_loss: 1.7377 - val_out_mean_covariance_loss: 61.6080 - val_out_fielding_position_loss: 1.7932
Epoch 34/1000

Epoch 00034: val_loss did not improve
 - 5s - loss: 11.0768 - out_stats_loss: 4.7757 - out_counts_loss: 1.6559 - out_mean_covariance_loss: 57.9237 - out_fielding_position_loss: 1.7491 - val_loss: 11.6672 - val_out_stats_loss: 5.0507 - val_out_counts_loss: 1.7510 - val_out_mean_covariance_loss: 61.4369 - val_out_fielding_position_loss: 1.7937
Epoch 35/1000

Epoch 00035: val_loss improved from 11.64144 to 11.61816, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 5s - loss: 11.0292 - out_stats_loss: 4.7389 - out_counts_loss: 1.6581 - out_mean_covariance_loss: 57.6376 - out_fielding_position_loss: 1.7503 - val_loss: 11.6182 - val_out_stats_loss: 5.0340 - val_out_counts_loss: 1.7371 - val_out_mean_covariance_loss: 61.1852 - val_out_fielding_position_loss: 1.7878
Epoch 36/1000

Epoch 00036: val_loss did not improve
 - 5s - loss: 11.0275 - out_stats_loss: 4.7449 - out_counts_loss: 1.6444 - out_mean_covariance_loss: 57.7349 - out_fielding_position_loss: 1.7515 - val_loss: 11.6572 - val_out_stats_loss: 5.0647 - val_out_counts_loss: 1.7419 - val_out_mean_covariance_loss: 61.3177 - val_out_fielding_position_loss: 1.7847
Epoch 37/1000

Epoch 00037: val_loss did not improve
 - 5s - loss: 10.9643 - out_stats_loss: 4.7195 - out_counts_loss: 1.6491 - out_mean_covariance_loss: 57.2529 - out_fielding_position_loss: 1.7331 - val_loss: 11.6786 - val_out_stats_loss: 5.0787 - val_out_counts_loss: 1.7476 - val_out_mean_covariance_loss: 61.4213 - val_out_fielding_position_loss: 1.7812
Epoch 38/1000

Epoch 00038: val_loss did not improve
 - 4s - loss: 10.9983 - out_stats_loss: 4.7508 - out_counts_loss: 1.6252 - out_mean_covariance_loss: 57.8784 - out_fielding_position_loss: 1.7284 - val_loss: 11.6337 - val_out_stats_loss: 5.0470 - val_out_counts_loss: 1.7491 - val_out_mean_covariance_loss: 61.2003 - val_out_fielding_position_loss: 1.7776
Epoch 39/1000

Epoch 00039: val_loss improved from 11.61816 to 11.60161, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 5s - loss: 10.9489 - out_stats_loss: 4.7322 - out_counts_loss: 1.6234 - out_mean_covariance_loss: 57.4106 - out_fielding_position_loss: 1.7228 - val_loss: 11.6016 - val_out_stats_loss: 5.0267 - val_out_counts_loss: 1.7488 - val_out_mean_covariance_loss: 61.0445 - val_out_fielding_position_loss: 1.7739
Epoch 40/1000

Epoch 00040: val_loss improved from 11.60161 to 11.58621, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 5s - loss: 10.9212 - out_stats_loss: 4.7188 - out_counts_loss: 1.6148 - out_mean_covariance_loss: 57.3810 - out_fielding_position_loss: 1.7186 - val_loss: 11.5862 - val_out_stats_loss: 5.0247 - val_out_counts_loss: 1.7405 - val_out_mean_covariance_loss: 60.9441 - val_out_fielding_position_loss: 1.7738
Epoch 41/1000

Epoch 00041: val_loss improved from 11.58621 to 11.58274, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 5s - loss: 10.8900 - out_stats_loss: 4.7071 - out_counts_loss: 1.6215 - out_mean_covariance_loss: 57.0838 - out_fielding_position_loss: 1.7072 - val_loss: 11.5827 - val_out_stats_loss: 5.0137 - val_out_counts_loss: 1.7516 - val_out_mean_covariance_loss: 60.9305 - val_out_fielding_position_loss: 1.7708
Epoch 42/1000

Epoch 00042: val_loss improved from 11.58274 to 11.57987, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 5s - loss: 10.8318 - out_stats_loss: 4.6944 - out_counts_loss: 1.5999 - out_mean_covariance_loss: 56.8749 - out_fielding_position_loss: 1.6938 - val_loss: 11.5799 - val_out_stats_loss: 5.0135 - val_out_counts_loss: 1.7531 - val_out_mean_covariance_loss: 60.9286 - val_out_fielding_position_loss: 1.7668
Epoch 43/1000

Epoch 00043: val_loss did not improve
 - 5s - loss: 10.9026 - out_stats_loss: 4.7135 - out_counts_loss: 1.6188 - out_mean_covariance_loss: 57.3740 - out_fielding_position_loss: 1.7016 - val_loss: 11.6053 - val_out_stats_loss: 5.0170 - val_out_counts_loss: 1.7742 - val_out_mean_covariance_loss: 60.9193 - val_out_fielding_position_loss: 1.7682
Epoch 44/1000

Epoch 00044: val_loss did not improve
 - 5s - loss: 10.7935 - out_stats_loss: 4.6695 - out_counts_loss: 1.5993 - out_mean_covariance_loss: 56.6762 - out_fielding_position_loss: 1.6909 - val_loss: 11.6161 - val_out_stats_loss: 5.0344 - val_out_counts_loss: 1.7686 - val_out_mean_covariance_loss: 60.9776 - val_out_fielding_position_loss: 1.7642
Epoch 45/1000

Epoch 00045: val_loss improved from 11.57987 to 11.56759, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 5s - loss: 10.7764 - out_stats_loss: 4.6624 - out_counts_loss: 1.5859 - out_mean_covariance_loss: 56.7048 - out_fielding_position_loss: 1.6930 - val_loss: 11.5676 - val_out_stats_loss: 5.0176 - val_out_counts_loss: 1.7517 - val_out_mean_covariance_loss: 60.8015 - val_out_fielding_position_loss: 1.7582
Epoch 46/1000

Epoch 00046: val_loss did not improve
 - 5s - loss: 10.8037 - out_stats_loss: 4.6788 - out_counts_loss: 1.5979 - out_mean_covariance_loss: 56.9143 - out_fielding_position_loss: 1.6813 - val_loss: 11.6936 - val_out_stats_loss: 5.0603 - val_out_counts_loss: 1.8133 - val_out_mean_covariance_loss: 61.0892 - val_out_fielding_position_loss: 1.7655
Epoch 47/1000

Epoch 00047: val_loss did not improve
 - 5s - loss: 10.7268 - out_stats_loss: 4.6457 - out_counts_loss: 1.5902 - out_mean_covariance_loss: 56.3346 - out_fielding_position_loss: 1.6741 - val_loss: 11.5861 - val_out_stats_loss: 5.0200 - val_out_counts_loss: 1.7772 - val_out_mean_covariance_loss: 60.6478 - val_out_fielding_position_loss: 1.7565
Epoch 48/1000

Epoch 00048: val_loss improved from 11.56759 to 11.55510, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 5s - loss: 10.7258 - out_stats_loss: 4.6598 - out_counts_loss: 1.5738 - out_mean_covariance_loss: 56.3898 - out_fielding_position_loss: 1.6727 - val_loss: 11.5551 - val_out_stats_loss: 5.0117 - val_out_counts_loss: 1.7545 - val_out_mean_covariance_loss: 60.6752 - val_out_fielding_position_loss: 1.7552
Epoch 49/1000

Epoch 00049: val_loss did not improve
 - 5s - loss: 10.7198 - out_stats_loss: 4.6649 - out_counts_loss: 1.5782 - out_mean_covariance_loss: 56.3191 - out_fielding_position_loss: 1.6608 - val_loss: 11.5931 - val_out_stats_loss: 5.0341 - val_out_counts_loss: 1.7650 - val_out_mean_covariance_loss: 60.8825 - val_out_fielding_position_loss: 1.7498
Epoch 50/1000

Epoch 00050: val_loss did not improve
 - 5s - loss: 10.6967 - out_stats_loss: 4.6654 - out_counts_loss: 1.5555 - out_mean_covariance_loss: 56.5688 - out_fielding_position_loss: 1.6473 - val_loss: 11.5785 - val_out_stats_loss: 5.0380 - val_out_counts_loss: 1.7580 - val_out_mean_covariance_loss: 60.7433 - val_out_fielding_position_loss: 1.7453
Epoch 51/1000

Epoch 00051: val_loss improved from 11.55510 to 11.55024, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 5s - loss: 10.6110 - out_stats_loss: 4.6118 - out_counts_loss: 1.5576 - out_mean_covariance_loss: 55.9246 - out_fielding_position_loss: 1.6454 - val_loss: 11.5502 - val_out_stats_loss: 5.0123 - val_out_counts_loss: 1.7645 - val_out_mean_covariance_loss: 60.5679 - val_out_fielding_position_loss: 1.7451
Epoch 52/1000

Epoch 00052: val_loss did not improve
 - 5s - loss: 10.5708 - out_stats_loss: 4.6076 - out_counts_loss: 1.5420 - out_mean_covariance_loss: 55.6576 - out_fielding_position_loss: 1.6384 - val_loss: 11.5567 - val_out_stats_loss: 5.0224 - val_out_counts_loss: 1.7686 - val_out_mean_covariance_loss: 60.4251 - val_out_fielding_position_loss: 1.7445
Epoch 53/1000

Epoch 00053: val_loss did not improve
 - 5s - loss: 10.5544 - out_stats_loss: 4.6015 - out_counts_loss: 1.5399 - out_mean_covariance_loss: 55.6097 - out_fielding_position_loss: 1.6325 - val_loss: 11.5717 - val_out_stats_loss: 5.0296 - val_out_counts_loss: 1.7693 - val_out_mean_covariance_loss: 60.6257 - val_out_fielding_position_loss: 1.7415
Epoch 54/1000

Epoch 00054: val_loss did not improve
 - 5s - loss: 10.5578 - out_stats_loss: 4.6075 - out_counts_loss: 1.5459 - out_mean_covariance_loss: 55.5487 - out_fielding_position_loss: 1.6270 - val_loss: 11.5597 - val_out_stats_loss: 5.0309 - val_out_counts_loss: 1.7696 - val_out_mean_covariance_loss: 60.4726 - val_out_fielding_position_loss: 1.7357
Epoch 55/1000

Epoch 00055: val_loss improved from 11.55024 to 11.52981, saving model to models/bc/shift1/max2015/simple-rnn/6.h5
 - 5s - loss: 10.5068 - out_stats_loss: 4.5869 - out_counts_loss: 1.5235 - out_mean_covariance_loss: 55.4714 - out_fielding_position_loss: 1.6229 - val_loss: 11.5298 - val_out_stats_loss: 5.0087 - val_out_counts_loss: 1.7681 - val_out_mean_covariance_loss: 60.3364 - val_out_fielding_position_loss: 1.7363
Epoch 56/1000

Epoch 00056: val_loss did not improve
 - 4s - loss: 10.4902 - out_stats_loss: 4.5819 - out_counts_loss: 1.5266 - out_mean_covariance_loss: 55.2842 - out_fielding_position_loss: 1.6175 - val_loss: 11.5677 - val_out_stats_loss: 5.0209 - val_out_counts_loss: 1.7865 - val_out_mean_covariance_loss: 60.4227 - val_out_fielding_position_loss: 1.7391
Epoch 57/1000

Epoch 00057: val_loss did not improve
 - 5s - loss: 10.5032 - out_stats_loss: 4.5993 - out_counts_loss: 1.5121 - out_mean_covariance_loss: 55.5844 - out_fielding_position_loss: 1.6126 - val_loss: 11.6123 - val_out_stats_loss: 5.0504 - val_out_counts_loss: 1.8012 - val_out_mean_covariance_loss: 60.5094 - val_out_fielding_position_loss: 1.7352
Epoch 58/1000

Epoch 00058: val_loss did not improve
 - 4s - loss: 10.4211 - out_stats_loss: 4.5591 - out_counts_loss: 1.5089 - out_mean_covariance_loss: 54.9225 - out_fielding_position_loss: 1.6070 - val_loss: 11.5736 - val_out_stats_loss: 5.0303 - val_out_counts_loss: 1.7923 - val_out_mean_covariance_loss: 60.3243 - val_out_fielding_position_loss: 1.7349
Epoch 59/1000

Epoch 00059: val_loss did not improve
 - 5s - loss: 10.4149 - out_stats_loss: 4.5631 - out_counts_loss: 1.5009 - out_mean_covariance_loss: 55.0509 - out_fielding_position_loss: 1.5983 - val_loss: 11.5640 - val_out_stats_loss: 5.0273 - val_out_counts_loss: 1.7895 - val_out_mean_covariance_loss: 60.3759 - val_out_fielding_position_loss: 1.7283
Epoch 60/1000

Epoch 00060: val_loss did not improve
 - 5s - loss: 10.3937 - out_stats_loss: 4.5688 - out_counts_loss: 1.4910 - out_mean_covariance_loss: 54.8746 - out_fielding_position_loss: 1.5902 - val_loss: 11.5652 - val_out_stats_loss: 5.0229 - val_out_counts_loss: 1.7927 - val_out_mean_covariance_loss: 60.4223 - val_out_fielding_position_loss: 1.7284
Epoch 61/1000

Epoch 00061: val_loss did not improve
 - 4s - loss: 10.3771 - out_stats_loss: 4.5596 - out_counts_loss: 1.4843 - out_mean_covariance_loss: 54.9159 - out_fielding_position_loss: 1.5874 - val_loss: 11.5956 - val_out_stats_loss: 5.0448 - val_out_counts_loss: 1.8015 - val_out_mean_covariance_loss: 60.4867 - val_out_fielding_position_loss: 1.7250
Epoch 62/1000

Epoch 00062: val_loss did not improve
 - 4s - loss: 10.3814 - out_stats_loss: 4.5544 - out_counts_loss: 1.4882 - out_mean_covariance_loss: 54.9556 - out_fielding_position_loss: 1.5910 - val_loss: 11.5964 - val_out_stats_loss: 5.0268 - val_out_counts_loss: 1.8236 - val_out_mean_covariance_loss: 60.3703 - val_out_fielding_position_loss: 1.7275
Epoch 63/1000

Epoch 00063: val_loss did not improve
 - 4s - loss: 10.3315 - out_stats_loss: 4.5393 - out_counts_loss: 1.4861 - out_mean_covariance_loss: 54.4964 - out_fielding_position_loss: 1.5813 - val_loss: 11.5798 - val_out_stats_loss: 5.0229 - val_out_counts_loss: 1.8176 - val_out_mean_covariance_loss: 60.2758 - val_out_fielding_position_loss: 1.7255
Epoch 64/1000

Epoch 00064: val_loss did not improve
 - 5s - loss: 10.3120 - out_stats_loss: 4.5452 - out_counts_loss: 1.4667 - out_mean_covariance_loss: 54.8228 - out_fielding_position_loss: 1.5590 - val_loss: 11.6448 - val_out_stats_loss: 5.0678 - val_out_counts_loss: 1.8300 - val_out_mean_covariance_loss: 60.3713 - val_out_fielding_position_loss: 1.7284
Epoch 65/1000

Epoch 00065: val_loss did not improve
 - 5s - loss: 10.3654 - out_stats_loss: 4.5737 - out_counts_loss: 1.4718 - out_mean_covariance_loss: 55.0980 - out_fielding_position_loss: 1.5650 - val_loss: 11.6084 - val_out_stats_loss: 5.0390 - val_out_counts_loss: 1.8278 - val_out_mean_covariance_loss: 60.3173 - val_out_fielding_position_loss: 1.7257
Epoch 66/1000

Epoch 00066: val_loss did not improve
 - 4s - loss: 10.2704 - out_stats_loss: 4.5303 - out_counts_loss: 1.4612 - out_mean_covariance_loss: 54.3138 - out_fielding_position_loss: 1.5632 - val_loss: 11.5731 - val_out_stats_loss: 5.0260 - val_out_counts_loss: 1.8204 - val_out_mean_covariance_loss: 60.2324 - val_out_fielding_position_loss: 1.7151
Epoch 67/1000

Epoch 00067: val_loss did not improve
 - 5s - loss: 10.2936 - out_stats_loss: 4.5325 - out_counts_loss: 1.4684 - out_mean_covariance_loss: 54.5363 - out_fielding_position_loss: 1.5659 - val_loss: 11.6650 - val_out_stats_loss: 5.0616 - val_out_counts_loss: 1.8591 - val_out_mean_covariance_loss: 60.3985 - val_out_fielding_position_loss: 1.7244
Epoch 68/1000

Epoch 00068: val_loss did not improve
 - 5s - loss: 10.3051 - out_stats_loss: 4.5550 - out_counts_loss: 1.4587 - out_mean_covariance_loss: 54.8002 - out_fielding_position_loss: 1.5514 - val_loss: 11.5791 - val_out_stats_loss: 5.0320 - val_out_counts_loss: 1.8184 - val_out_mean_covariance_loss: 60.2079 - val_out_fielding_position_loss: 1.7183
Epoch 69/1000

Epoch 00069: val_loss did not improve
 - 4s - loss: 10.1932 - out_stats_loss: 4.5071 - out_counts_loss: 1.4517 - out_mean_covariance_loss: 53.8212 - out_fielding_position_loss: 1.5433 - val_loss: 11.6706 - val_out_stats_loss: 5.0796 - val_out_counts_loss: 1.8460 - val_out_mean_covariance_loss: 60.4884 - val_out_fielding_position_loss: 1.7206
Epoch 70/1000

Epoch 00070: val_loss did not improve
 - 4s - loss: 10.2094 - out_stats_loss: 4.5129 - out_counts_loss: 1.4468 - out_mean_covariance_loss: 53.9589 - out_fielding_position_loss: 1.5517 - val_loss: 11.6850 - val_out_stats_loss: 5.0794 - val_out_counts_loss: 1.8672 - val_out_mean_covariance_loss: 60.3127 - val_out_fielding_position_loss: 1.7227
Epoch 71/1000

Epoch 00071: val_loss did not improve
 - 4s - loss: 10.2432 - out_stats_loss: 4.5343 - out_counts_loss: 1.4432 - out_mean_covariance_loss: 54.4771 - out_fielding_position_loss: 1.5419 - val_loss: 11.6011 - val_out_stats_loss: 5.0474 - val_out_counts_loss: 1.8362 - val_out_mean_covariance_loss: 60.0915 - val_out_fielding_position_loss: 1.7129
Epoch 72/1000

Epoch 00072: val_loss did not improve
 - 5s - loss: 10.2100 - out_stats_loss: 4.5193 - out_counts_loss: 1.4467 - out_mean_covariance_loss: 53.9412 - out_fielding_position_loss: 1.5469 - val_loss: 11.6615 - val_out_stats_loss: 5.0655 - val_out_counts_loss: 1.8611 - val_out_mean_covariance_loss: 60.3872 - val_out_fielding_position_loss: 1.7154
Epoch 73/1000

Epoch 00073: val_loss did not improve
 - 5s - loss: 10.2233 - out_stats_loss: 4.5149 - out_counts_loss: 1.4523 - out_mean_covariance_loss: 54.0398 - out_fielding_position_loss: 1.5542 - val_loss: 11.6062 - val_out_stats_loss: 5.0473 - val_out_counts_loss: 1.8420 - val_out_mean_covariance_loss: 60.1070 - val_out_fielding_position_loss: 1.7116
Epoch 74/1000

Epoch 00074: val_loss did not improve
 - 5s - loss: 10.1597 - out_stats_loss: 4.5158 - out_counts_loss: 1.4369 - out_mean_covariance_loss: 53.6820 - out_fielding_position_loss: 1.5229 - val_loss: 11.6226 - val_out_stats_loss: 5.0552 - val_out_counts_loss: 1.8503 - val_out_mean_covariance_loss: 60.0497 - val_out_fielding_position_loss: 1.7147
Epoch 75/1000

Epoch 00075: val_loss did not improve
 - 5s - loss: 10.1837 - out_stats_loss: 4.5343 - out_counts_loss: 1.4291 - out_mean_covariance_loss: 53.9532 - out_fielding_position_loss: 1.5227 - val_loss: 11.7539 - val_out_stats_loss: 5.0839 - val_out_counts_loss: 1.9231 - val_out_mean_covariance_loss: 60.2765 - val_out_fielding_position_loss: 1.7330
Epoch 76/1000

Epoch 00076: val_loss did not improve
 - 4s - loss: 10.1344 - out_stats_loss: 4.4949 - out_counts_loss: 1.4348 - out_mean_covariance_loss: 53.6018 - out_fielding_position_loss: 1.5246 - val_loss: 11.6276 - val_out_stats_loss: 5.0641 - val_out_counts_loss: 1.8378 - val_out_mean_covariance_loss: 60.3191 - val_out_fielding_position_loss: 1.7098
Epoch 77/1000

Epoch 00077: val_loss did not improve
 - 4s - loss: 9.9977 - out_stats_loss: 4.4354 - out_counts_loss: 1.4093 - out_mean_covariance_loss: 52.7788 - out_fielding_position_loss: 1.5140 - val_loss: 11.6516 - val_out_stats_loss: 5.0601 - val_out_counts_loss: 1.8701 - val_out_mean_covariance_loss: 60.1202 - val_out_fielding_position_loss: 1.7154
Epoch 78/1000

Epoch 00078: val_loss did not improve
 - 5s - loss: 10.0355 - out_stats_loss: 4.4564 - out_counts_loss: 1.4147 - out_mean_covariance_loss: 53.0221 - out_fielding_position_loss: 1.5134 - val_loss: 11.5965 - val_out_stats_loss: 5.0393 - val_out_counts_loss: 1.8521 - val_out_mean_covariance_loss: 59.8896 - val_out_fielding_position_loss: 1.7107
Epoch 79/1000

Epoch 00079: val_loss did not improve
 - 5s - loss: 10.0300 - out_stats_loss: 4.4565 - out_counts_loss: 1.4177 - out_mean_covariance_loss: 53.0190 - out_fielding_position_loss: 1.5049 - val_loss: 11.7852 - val_out_stats_loss: 5.1124 - val_out_counts_loss: 1.9255 - val_out_mean_covariance_loss: 60.3997 - val_out_fielding_position_loss: 1.7273
Epoch 80/1000

Epoch 00080: val_loss did not improve
 - 5s - loss: 10.0022 - out_stats_loss: 4.4403 - out_counts_loss: 1.4073 - out_mean_covariance_loss: 53.0239 - out_fielding_position_loss: 1.5034 - val_loss: 11.6504 - val_out_stats_loss: 5.0613 - val_out_counts_loss: 1.8774 - val_out_mean_covariance_loss: 60.0089 - val_out_fielding_position_loss: 1.7113
Epoch 81/1000

Epoch 00081: val_loss did not improve
 - 5s - loss: 10.0480 - out_stats_loss: 4.4850 - out_counts_loss: 1.4038 - out_mean_covariance_loss: 53.3394 - out_fielding_position_loss: 1.4923 - val_loss: 11.7053 - val_out_stats_loss: 5.0789 - val_out_counts_loss: 1.8979 - val_out_mean_covariance_loss: 60.1616 - val_out_fielding_position_loss: 1.7203
Epoch 82/1000

Epoch 00082: val_loss did not improve
 - 5s - loss: 9.9808 - out_stats_loss: 4.4351 - out_counts_loss: 1.4019 - out_mean_covariance_loss: 52.9045 - out_fielding_position_loss: 1.4987 - val_loss: 11.6318 - val_out_stats_loss: 5.0522 - val_out_counts_loss: 1.8725 - val_out_mean_covariance_loss: 60.0653 - val_out_fielding_position_loss: 1.7038
Epoch 83/1000

Epoch 00083: val_loss did not improve
 - 5s - loss: 9.9241 - out_stats_loss: 4.4367 - out_counts_loss: 1.3743 - out_mean_covariance_loss: 52.5399 - out_fielding_position_loss: 1.4861 - val_loss: 11.6401 - val_out_stats_loss: 5.0554 - val_out_counts_loss: 1.8780 - val_out_mean_covariance_loss: 60.0828 - val_out_fielding_position_loss: 1.7026
Epoch 84/1000

Epoch 00084: val_loss did not improve
 - 4s - loss: 9.9773 - out_stats_loss: 4.4574 - out_counts_loss: 1.3784 - out_mean_covariance_loss: 53.0290 - out_fielding_position_loss: 1.4901 - val_loss: 11.6443 - val_out_stats_loss: 5.0512 - val_out_counts_loss: 1.8823 - val_out_mean_covariance_loss: 60.1207 - val_out_fielding_position_loss: 1.7048
Epoch 85/1000

Epoch 00085: val_loss did not improve
 - 4s - loss: 9.9025 - out_stats_loss: 4.4246 - out_counts_loss: 1.3686 - out_mean_covariance_loss: 52.5409 - out_fielding_position_loss: 1.4823 - val_loss: 11.7403 - val_out_stats_loss: 5.1138 - val_out_counts_loss: 1.9145 - val_out_mean_covariance_loss: 60.0447 - val_out_fielding_position_loss: 1.7098
Epoch 86/1000

Epoch 00086: val_loss did not improve
 - 4s - loss: 9.9317 - out_stats_loss: 4.4402 - out_counts_loss: 1.3714 - out_mean_covariance_loss: 52.6285 - out_fielding_position_loss: 1.4887 - val_loss: 11.6790 - val_out_stats_loss: 5.0722 - val_out_counts_loss: 1.8943 - val_out_mean_covariance_loss: 60.1456 - val_out_fielding_position_loss: 1.7052
Epoch 87/1000

Epoch 00087: val_loss did not improve
 - 5s - loss: 9.9049 - out_stats_loss: 4.4244 - out_counts_loss: 1.3690 - out_mean_covariance_loss: 52.6975 - out_fielding_position_loss: 1.4767 - val_loss: 11.7827 - val_out_stats_loss: 5.1047 - val_out_counts_loss: 1.9373 - val_out_mean_covariance_loss: 60.4126 - val_out_fielding_position_loss: 1.7202
Epoch 88/1000

Epoch 00088: val_loss did not improve
 - 4s - loss: 9.9264 - out_stats_loss: 4.4521 - out_counts_loss: 1.3561 - out_mean_covariance_loss: 52.9915 - out_fielding_position_loss: 1.4686 - val_loss: 11.6991 - val_out_stats_loss: 5.0636 - val_out_counts_loss: 1.9212 - val_out_mean_covariance_loss: 60.1918 - val_out_fielding_position_loss: 1.7048
Epoch 89/1000

Epoch 00089: val_loss did not improve
 - 5s - loss: 9.8348 - out_stats_loss: 4.4093 - out_counts_loss: 1.3546 - out_mean_covariance_loss: 52.1330 - out_fielding_position_loss: 1.4642 - val_loss: 11.6921 - val_out_stats_loss: 5.0786 - val_out_counts_loss: 1.9088 - val_out_mean_covariance_loss: 59.9623 - val_out_fielding_position_loss: 1.7066
Epoch 90/1000

Epoch 00090: val_loss did not improve
 - 4s - loss: 9.8490 - out_stats_loss: 4.4155 - out_counts_loss: 1.3522 - out_mean_covariance_loss: 52.4073 - out_fielding_position_loss: 1.4609 - val_loss: 11.6705 - val_out_stats_loss: 5.0686 - val_out_counts_loss: 1.9008 - val_out_mean_covariance_loss: 60.0484 - val_out_fielding_position_loss: 1.6987
Epoch 91/1000

Epoch 00091: val_loss did not improve
 - 4s - loss: 9.8199 - out_stats_loss: 4.4072 - out_counts_loss: 1.3533 - out_mean_covariance_loss: 52.0485 - out_fielding_position_loss: 1.4569 - val_loss: 11.6920 - val_out_stats_loss: 5.0756 - val_out_counts_loss: 1.9135 - val_out_mean_covariance_loss: 60.0529 - val_out_fielding_position_loss: 1.7003
Epoch 92/1000

Epoch 00092: val_loss did not improve
 - 4s - loss: 9.7462 - out_stats_loss: 4.3677 - out_counts_loss: 1.3420 - out_mean_covariance_loss: 51.5994 - out_fielding_position_loss: 1.4565 - val_loss: 11.7359 - val_out_stats_loss: 5.0759 - val_out_counts_loss: 1.9375 - val_out_mean_covariance_loss: 60.1605 - val_out_fielding_position_loss: 1.7146
Epoch 93/1000

Epoch 00093: val_loss did not improve
 - 5s - loss: 9.7469 - out_stats_loss: 4.3757 - out_counts_loss: 1.3314 - out_mean_covariance_loss: 51.7774 - out_fielding_position_loss: 1.4509 - val_loss: 11.7114 - val_out_stats_loss: 5.0767 - val_out_counts_loss: 1.9283 - val_out_mean_covariance_loss: 60.0291 - val_out_fielding_position_loss: 1.7049
Epoch 94/1000

Epoch 00094: val_loss did not improve
 - 5s - loss: 9.7869 - out_stats_loss: 4.3987 - out_counts_loss: 1.3334 - out_mean_covariance_loss: 52.0944 - out_fielding_position_loss: 1.4501 - val_loss: 11.7756 - val_out_stats_loss: 5.1071 - val_out_counts_loss: 1.9484 - val_out_mean_covariance_loss: 60.2127 - val_out_fielding_position_loss: 1.7094
Epoch 95/1000

Epoch 00095: val_loss did not improve
 - 5s - loss: 9.7136 - out_stats_loss: 4.3650 - out_counts_loss: 1.3278 - out_mean_covariance_loss: 51.5394 - out_fielding_position_loss: 1.4438 - val_loss: 11.7548 - val_out_stats_loss: 5.1002 - val_out_counts_loss: 1.9384 - val_out_mean_covariance_loss: 60.1796 - val_out_fielding_position_loss: 1.7072
Epoch 96/1000

Epoch 00096: val_loss did not improve
 - 5s - loss: 9.6923 - out_stats_loss: 4.3547 - out_counts_loss: 1.3309 - out_mean_covariance_loss: 51.3659 - out_fielding_position_loss: 1.4384 - val_loss: 11.7224 - val_out_stats_loss: 5.0889 - val_out_counts_loss: 1.9233 - val_out_mean_covariance_loss: 60.2143 - val_out_fielding_position_loss: 1.6994
Epoch 97/1000

Epoch 00097: val_loss did not improve
 - 5s - loss: 9.6965 - out_stats_loss: 4.3612 - out_counts_loss: 1.3264 - out_mean_covariance_loss: 51.4431 - out_fielding_position_loss: 1.4368 - val_loss: 11.7101 - val_out_stats_loss: 5.0819 - val_out_counts_loss: 1.9289 - val_out_mean_covariance_loss: 60.1545 - val_out_fielding_position_loss: 1.6916
Epoch 98/1000

Epoch 00098: val_loss did not improve
 - 4s - loss: 9.7640 - out_stats_loss: 4.3968 - out_counts_loss: 1.3279 - out_mean_covariance_loss: 52.0919 - out_fielding_position_loss: 1.4347 - val_loss: 11.6909 - val_out_stats_loss: 5.0749 - val_out_counts_loss: 1.9160 - val_out_mean_covariance_loss: 59.9532 - val_out_fielding_position_loss: 1.7024
Epoch 99/1000

Epoch 00099: val_loss did not improve
 - 4s - loss: 9.6801 - out_stats_loss: 4.3683 - out_counts_loss: 1.3154 - out_mean_covariance_loss: 51.3485 - out_fielding_position_loss: 1.4290 - val_loss: 11.7494 - val_out_stats_loss: 5.1043 - val_out_counts_loss: 1.9341 - val_out_mean_covariance_loss: 60.2704 - val_out_fielding_position_loss: 1.6974
Epoch 100/1000

Epoch 00100: val_loss did not improve
 - 5s - loss: 9.7197 - out_stats_loss: 4.3807 - out_counts_loss: 1.3262 - out_mean_covariance_loss: 51.5693 - out_fielding_position_loss: 1.4343 - val_loss: 11.7387 - val_out_stats_loss: 5.0950 - val_out_counts_loss: 1.9333 - val_out_mean_covariance_loss: 60.2399 - val_out_fielding_position_loss: 1.6984
Epoch 101/1000

Epoch 00101: val_loss did not improve
 - 4s - loss: 9.6176 - out_stats_loss: 4.3403 - out_counts_loss: 1.2992 - out_mean_covariance_loss: 50.9917 - out_fielding_position_loss: 1.4285 - val_loss: 11.7756 - val_out_stats_loss: 5.1027 - val_out_counts_loss: 1.9560 - val_out_mean_covariance_loss: 60.2700 - val_out_fielding_position_loss: 1.7034
Epoch 102/1000

Epoch 00102: val_loss did not improve
 - 4s - loss: 9.6577 - out_stats_loss: 4.3635 - out_counts_loss: 1.3027 - out_mean_covariance_loss: 51.5199 - out_fielding_position_loss: 1.4156 - val_loss: 11.7489 - val_out_stats_loss: 5.0936 - val_out_counts_loss: 1.9481 - val_out_mean_covariance_loss: 60.1246 - val_out_fielding_position_loss: 1.7010
Epoch 103/1000

Epoch 00103: val_loss did not improve
 - 4s - loss: 9.6359 - out_stats_loss: 4.3553 - out_counts_loss: 1.2946 - out_mean_covariance_loss: 51.3502 - out_fielding_position_loss: 1.4185 - val_loss: 11.8119 - val_out_stats_loss: 5.1204 - val_out_counts_loss: 1.9778 - val_out_mean_covariance_loss: 60.2126 - val_out_fielding_position_loss: 1.7031
Epoch 104/1000

Epoch 00104: val_loss did not improve
 - 4s - loss: 9.6227 - out_stats_loss: 4.3520 - out_counts_loss: 1.2924 - out_mean_covariance_loss: 51.2089 - out_fielding_position_loss: 1.4178 - val_loss: 11.8130 - val_out_stats_loss: 5.1235 - val_out_counts_loss: 1.9657 - val_out_mean_covariance_loss: 60.3246 - val_out_fielding_position_loss: 1.7075
Epoch 105/1000

Epoch 00105: val_loss did not improve
 - 4s - loss: 9.5677 - out_stats_loss: 4.3316 - out_counts_loss: 1.2839 - out_mean_covariance_loss: 50.8943 - out_fielding_position_loss: 1.4074 - val_loss: 11.7872 - val_out_stats_loss: 5.1107 - val_out_counts_loss: 1.9637 - val_out_mean_covariance_loss: 60.2745 - val_out_fielding_position_loss: 1.6992
/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Years: [1958,2015]
Shift: 1
Fold: 4
Training into models/bc/shift1/max2015/simple-rnn/6.h5
/usr/local/lib/python3.5/dist-packages/keras/legacy/layers.py:533: UserWarning: The `MaxoutDense` layer is deprecated and will be removed after 06/2017.
  warnings.warn('The `MaxoutDense` layer is deprecated '
