__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
in_age (InputLayer)             (None, None, 2)      0                                            
__________________________________________________________________________________________________
in_bio (InputLayer)             (None, None, 7)      0                                            
__________________________________________________________________________________________________
in_fielding_position (InputLaye (None, None, 2)      0                                            
__________________________________________________________________________________________________
in_out_fielding_position (Input (None, None, 12)     0                                            
__________________________________________________________________________________________________
in_out_league_offense (InputLay (None, None, 9)      0                                            
__________________________________________________________________________________________________
in_out_park_factors (InputLayer (None, None, 8)      0                                            
__________________________________________________________________________________________________
in_out_plate_discipline (InputL (None, None, 8)      0                                            
__________________________________________________________________________________________________
in_out_running (InputLayer)     (None, None, 18)     0                                            
__________________________________________________________________________________________________
in_out_saber (InputLayer)       (None, None, 14)     0                                            
__________________________________________________________________________________________________
in_out_stats_extended (InputLay (None, None, 36)     0                                            
__________________________________________________________________________________________________
in_park_factors (InputLayer)    (None, None, 8)      0                                            
__________________________________________________________________________________________________
masked_in_age (Masking)         (None, None, 2)      0           in_age[0][0]                     
__________________________________________________________________________________________________
masked_in_bio (Masking)         (None, None, 7)      0           in_bio[0][0]                     
__________________________________________________________________________________________________
masked_in_fielding_position (Ma (None, None, 2)      0           in_fielding_position[0][0]       
__________________________________________________________________________________________________
masked_in_out_fielding_position (None, None, 12)     0           in_out_fielding_position[0][0]   
__________________________________________________________________________________________________
masked_in_out_league_offense (M (None, None, 9)      0           in_out_league_offense[0][0]      
__________________________________________________________________________________________________
masked_in_out_park_factors (Mas (None, None, 8)      0           in_out_park_factors[0][0]        
__________________________________________________________________________________________________
masked_in_out_plate_discipline  (None, None, 8)      0           in_out_plate_discipline[0][0]    
__________________________________________________________________________________________________
masked_in_out_running (Masking) (None, None, 18)     0           in_out_running[0][0]             
__________________________________________________________________________________________________
masked_in_out_saber (Masking)   (None, None, 14)     0           in_out_saber[0][0]               
__________________________________________________________________________________________________
masked_in_out_stats_extended (M (None, None, 36)     0           in_out_stats_extended[0][0]      
__________________________________________________________________________________________________
masked_in_park_factors (Masking (None, None, 8)      0           in_park_factors[0][0]            
__________________________________________________________________________________________________
time_distributed_6 (TimeDistrib (None, None, 1)      0           masked_in_age[0][0]              
__________________________________________________________________________________________________
time_distributed_3 (TimeDistrib (None, None, 6)      0           masked_in_bio[0][0]              
__________________________________________________________________________________________________
time_distributed_7 (TimeDistrib (None, None, 1)      0           masked_in_fielding_position[0][0]
__________________________________________________________________________________________________
time_distributed_11 (TimeDistri (None, None, 11)     0           masked_in_out_fielding_position[0
__________________________________________________________________________________________________
time_distributed_1 (TimeDistrib (None, None, 8)      0           masked_in_out_league_offense[0][0
__________________________________________________________________________________________________
time_distributed_2 (TimeDistrib (None, None, 7)      0           masked_in_out_park_factors[0][0] 
__________________________________________________________________________________________________
time_distributed_4 (TimeDistrib (None, None, 7)      0           masked_in_out_plate_discipline[0]
__________________________________________________________________________________________________
time_distributed_8 (TimeDistrib (None, None, 17)     0           masked_in_out_running[0][0]      
__________________________________________________________________________________________________
time_distributed_9 (TimeDistrib (None, None, 13)     0           masked_in_out_saber[0][0]        
__________________________________________________________________________________________________
time_distributed_10 (TimeDistri (None, None, 35)     0           masked_in_out_stats_extended[0][0
__________________________________________________________________________________________________
time_distributed_5 (TimeDistrib (None, None, 7)      0           masked_in_park_factors[0][0]     
__________________________________________________________________________________________________
norm_in_age (BatchNormalization (None, None, 1)      4           time_distributed_6[0][0]         
__________________________________________________________________________________________________
norm_in_bio (BatchNormalization (None, None, 6)      24          time_distributed_3[0][0]         
__________________________________________________________________________________________________
norm_in_fielding_position (Batc (None, None, 1)      4           time_distributed_7[0][0]         
__________________________________________________________________________________________________
norm_in_out_fielding_position ( (None, None, 11)     44          time_distributed_11[0][0]        
__________________________________________________________________________________________________
norm_in_out_league_offense (Bat (None, None, 8)      32          time_distributed_1[0][0]         
__________________________________________________________________________________________________
norm_in_out_park_factors (Batch (None, None, 7)      28          time_distributed_2[0][0]         
__________________________________________________________________________________________________
norm_in_out_plate_discipline (B (None, None, 7)      28          time_distributed_4[0][0]         
__________________________________________________________________________________________________2018-02-08 06:47:04.643008: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-02-08 06:47:11.390031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: eca0:00:00.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2018-02-08 06:47:11.390073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: eca0:00:00.0, compute capability: 3.7)

norm_in_out_running (BatchNorma (None, None, 17)     68          time_distributed_8[0][0]         
__________________________________________________________________________________________________
norm_in_out_saber (BatchNormali (None, None, 13)     52          time_distributed_9[0][0]         
__________________________________________________________________________________________________
norm_in_out_stats_extended (Bat (None, None, 35)     140         time_distributed_10[0][0]        
__________________________________________________________________________________________________
norm_in_park_factors (BatchNorm (None, None, 7)      28          time_distributed_5[0][0]         
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, None, 113)    0           norm_in_age[0][0]                
                                                                 norm_in_bio[0][0]                
                                                                 norm_in_fielding_position[0][0]  
                                                                 norm_in_out_fielding_position[0][
                                                                 norm_in_out_league_offense[0][0] 
                                                                 norm_in_out_park_factors[0][0]   
                                                                 norm_in_out_plate_discipline[0][0
                                                                 norm_in_out_running[0][0]        
                                                                 norm_in_out_saber[0][0]          
                                                                 norm_in_out_stats_extended[0][0] 
                                                                 norm_in_park_factors[0][0]       
__________________________________________________________________________________________________
gru_1 (GRU)                     (None, None, 113)    76953       concatenate_1[0][0]              
__________________________________________________________________________________________________
gru_2 (GRU)                     (None, None, 113)    76953       gru_1[0][0]                      
__________________________________________________________________________________________________
mv_out_stats (TimeDistributed)  (None, None, 5)      4560        gru_2[0][0]                      
__________________________________________________________________________________________________
mv_out_counts (TimeDistributed) (None, None, 3)      2736        gru_2[0][0]                      
__________________________________________________________________________________________________
mv_out_mean_covariance (TimeDis (None, None, 72)     65664       gru_2[0][0]                      
__________________________________________________________________________________________________
mv_out_fielding_position (TimeD (None, None, 11)     10032       gru_2[0][0]                      
__________________________________________________________________________________________________
out_stats (Activation)          (None, None, 5)      0           mv_out_stats[0][0]               
__________________________________________________________________________________________________
out_counts (Activation)         (None, None, 3)      0           mv_out_counts[0][0]              
__________________________________________________________________________________________________
out_mean_covariance (Activation (None, None, 72)     0           mv_out_mean_covariance[0][0]     
__________________________________________________________________________________________________
out_fielding_position (Activati (None, None, 11)     0           mv_out_fielding_position[0][0]   
==================================================================================================
Total params: 237,350
Trainable params: 237,124
Non-trainable params: 226
__________________________________________________________________________________________________
Train on 5748 samples, validate on 1385 samples
Epoch 1/1000

Epoch 00001: val_loss improved from inf to 19.76239, saving model to models/bc/shift1/max2015/simple-rnn/7.h5
 - 16s - loss: 21.5351 - out_stats_loss: 8.2748 - out_counts_loss: 3.5959 - out_mean_covariance_loss: 104.1673 - out_fielding_position_loss: 4.4560 - val_loss: 19.7624 - val_out_stats_loss: 7.7729 - val_out_counts_loss: 2.8062 - val_out_mean_covariance_loss: 99.5074 - val_out_fielding_position_loss: 4.2078
Epoch 2/1000

Epoch 00002: val_loss improved from 19.76239 to 16.82373, saving model to models/bc/shift1/max2015/simple-rnn/7.h5
 - 5s - loss: 17.9529 - out_stats_loss: 6.9760 - out_counts_loss: 2.4551 - out_mean_covariance_loss: 90.8546 - out_fielding_position_loss: 3.9790 - val_loss: 16.8237 - val_out_stats_loss: 6.5929 - val_out_counts_loss: 2.1644 - val_out_mean_covariance_loss: 85.8860 - val_out_fielding_position_loss: 3.7721
Epoch 3/1000

Epoch 00003: val_loss improved from 16.82373 to 15.23325, saving model to models/bc/shift1/max2015/simple-rnn/7.h5
 - 5s - loss: 15.8063 - out_stats_loss: 6.1119 - out_counts_loss: 2.1474 - out_mean_covariance_loss: 79.5054 - out_fielding_position_loss: 3.5717 - val_loss: 15.2332 - val_out_stats_loss: 6.0123 - val_out_counts_loss: 1.9922 - val_out_mean_covariance_loss: 78.0044 - val_out_fielding_position_loss: 3.3285
Epoch 4/1000

Epoch 00004: val_loss improved from 15.23325 to 14.25936, saving model to models/bc/shift1/max2015/simple-rnn/7.h5
 - 5s - loss: 14.5653 - out_stats_loss: 5.7116 - out_counts_loss: 2.0049 - out_mean_covariance_loss: 73.9771 - out_fielding_position_loss: 3.1499 - val_loss: 14.2594 - val_out_stats_loss: 5.7399 - val_out_counts_loss: 1.8771 - val_out_mean_covariance_loss: 73.5496 - val_out_fielding_position_loss: 2.9649
Epoch 5/1000

Epoch 00005: val_loss improved from 14.25936 to 13.63398, saving model to models/bc/shift1/max2015/simple-rnn/7.h5
 - 5s - loss: 13.7973 - out_stats_loss: 5.5171 - out_counts_loss: 1.9339 - out_mean_covariance_loss: 70.3152 - out_fielding_position_loss: 2.8305 - val_loss: 13.6340 - val_out_stats_loss: 5.6007 - val_out_counts_loss: 1.8381 - val_out_mean_covariance_loss: 70.5070 - val_out_fielding_position_loss: 2.6698
Epoch 6/1000

Epoch 00006: val_loss improved from 13.63398 to 13.30234, saving model to models/bc/shift1/max2015/simple-rnn/7.h5
 - 5s - loss: 13.3144 - out_stats_loss: 5.4119 - out_counts_loss: 1.9066 - out_mean_covariance_loss: 68.1618 - out_fielding_position_loss: 2.5878 - val_loss: 13.3023 - val_out_stats_loss: 5.5684 - val_out_counts_loss: 1.8344 - val_out_mean_covariance_loss: 69.0917 - val_out_fielding_position_loss: 2.4450
Epoch 7/1000

Epoch 00007: val_loss improved from 13.30234 to 12.90278, saving model to models/bc/shift1/max2015/simple-rnn/7.h5
 - 5s - loss: 12.9273 - out_stats_loss: 5.3210 - out_counts_loss: 1.8749 - out_mean_covariance_loss: 66.6397 - out_fielding_position_loss: 2.3994 - val_loss: 12.9028 - val_out_stats_loss: 5.4540 - val_out_counts_loss: 1.8010 - val_out_mean_covariance_loss: 67.7568 - val_out_fielding_position_loss: 2.2600
Epoch 8/1000

Epoch 00008: val_loss improved from 12.90278 to 12.68898, saving model to models/bc/shift1/max2015/simple-rnn/7.h5
 - 5s - loss: 12.6799 - out_stats_loss: 5.2749 - out_counts_loss: 1.8619 - out_mean_covariance_loss: 65.6733 - out_fielding_position_loss: 2.2594 - val_loss: 12.6890 - val_out_stats_loss: 5.3939 - val_out_counts_loss: 1.8048 - val_out_mean_covariance_loss: 66.8576 - val_out_fielding_position_loss: 2.1474
Epoch 9/1000

Epoch 00009: val_loss improved from 12.68898 to 12.49623, saving model to models/bc/shift1/max2015/simple-rnn/7.h5
 - 5s - loss: 12.4581 - out_stats_loss: 5.2061 - out_counts_loss: 1.8476 - out_mean_covariance_loss: 64.6164 - out_fielding_position_loss: 2.1737 - val_loss: 12.4962 - val_out_stats_loss: 5.3393 - val_out_counts_loss: 1.7866 - val_out_mean_covariance_loss: 66.1821 - val_out_fielding_position_loss: 2.0613
Epoch 10/1000

Epoch 00010: val_loss improved from 12.49623 to 12.36944, saving model to models/bc/shift1/max2015/simple-rnn/7.h5
 - 5s - loss: 12.2964 - out_stats_loss: 5.1672 - out_counts_loss: 1.8374 - out_mean_covariance_loss: 64.0855 - out_fielding_position_loss: 2.0876 - val_loss: 12.3694 - val_out_stats_loss: 5.2948 - val_out_counts_loss: 1.7841 - val_out_mean_covariance_loss: 65.5513 - val_out_fielding_position_loss: 2.0130
Epoch 11/1000

Epoch 00011: val_loss improved from 12.36944 to 12.29526, saving model to models/bc/shift1/max2015/simple-rnn/7.h5
 - 5s - loss: 12.2038 - out_stats_loss: 5.1174 - out_counts_loss: 1.8444 - out_mean_covariance_loss: 63.4880 - out_fielding_position_loss: 2.0676 - val_loss: 12.2953 - val_out_stats_loss: 5.2836 - val_out_counts_loss: 1.7785 - val_out_mean_covariance_loss: 65.1501 - val_out_fielding_position_loss: 1.9756
Epoch 12/1000

Epoch 00012: val_loss improved from 12.29526 to 12.24098, saving model to models/bc/shift1/max2015/simple-rnn/7.h5
 - 5s - loss: 12.0328 - out_stats_loss: 5.0660 - out_counts_loss: 1.8197 - out_mean_covariance_loss: 62.4543 - out_fielding_position_loss: 2.0243 - val_loss: 12.2410 - val_out_stats_loss: 5.2422 - val_out_counts_loss: 1.8017 - val_out_mean_covariance_loss: 64.8725 - val_out_fielding_position_loss: 1.9535
Epoch 13/1000

Epoch 00013: val_loss improved from 12.24098 to 12.13464, saving model to models/bc/shift1/max2015/simple-rnn/7.h5
 - 5s - loss: 11.9987 - out_stats_loss: 5.0653 - out_counts_loss: 1.8112 - out_mean_covariance_loss: 62.7852 - out_fielding_position_loss: 1.9829 - val_loss: 12.1346 - val_out_stats_loss: 5.2151 - val_out_counts_loss: 1.7764 - val_out_mean_covariance_loss: 64.2506 - val_out_fielding_position_loss: 1.9307
Epoch 14/1000

Epoch 00014: val_loss improved from 12.13464 to 12.06926, saving model to models/bc/shift1/max2015/simple-rnn/7.h5
 - 5s - loss: 11.9136 - out_stats_loss: 5.0259 - out_counts_loss: 1.7988 - out_mean_covariance_loss: 62.2361 - out_fielding_position_loss: 1.9771 - val_loss: 12.0693 - val_out_stats_loss: 5.1882 - val_out_counts_loss: 1.7672 - val_out_mean_covariance_loss: 63.9465 - val_out_fielding_position_loss: 1.9165
Epoch 15/1000

Epoch 00015: val_loss improved from 12.06926 to 12.00613, saving model to models/bc/shift1/max2015/simple-rnn/7.h5
 - 5s - loss: 11.8380 - out_stats_loss: 5.0031 - out_counts_loss: 1.7985 - out_mean_covariance_loss: 61.5891 - out_fielding_position_loss: 1.9569 - val_loss: 12.0061 - val_out_stats_loss: 5.1589 - val_out_counts_loss: 1.7636 - val_out_mean_covariance_loss: 63.5874 - val_out_fielding_position_loss: 1.9042
Epoch 16/1000

Epoch 00016: val_loss improved from 12.00613 to 11.95942, saving model to models/bc/shift1/max2015/simple-rnn/7.h5
 - 5s - loss: 11.7421 - out_stats_loss: 4.9647 - out_counts_loss: 1.7819 - out_mean_covariance_loss: 61.1556 - out_fielding_position_loss: 1.9377 - val_loss: 11.9594 - val_out_stats_loss: 5.1444 - val_out_counts_loss: 1.7575 - val_out_mean_covariance_loss: 63.3194 - val_out_fielding_position_loss: 1.8915
Epoch 17/1000

Epoch 00017: val_loss improved from 11.95942 to 11.92093, saving model to models/bc/shift1/max2015/simple-rnn/7.h5
 - 5s - loss: 11.7112 - out_stats_loss: 4.9556 - out_counts_loss: 1.7757 - out_mean_covariance_loss: 61.2490 - out_fielding_position_loss: 1.9175 - val_loss: 11.9209 - val_out_stats_loss: 5.1235 - val_out_counts_loss: 1.7589 - val_out_mean_covariance_loss: 63.1469 - val_out_fielding_position_loss: 1.8812
Epoch 18/1000

Epoch 00018: val_loss did not improve
 - 5s - loss: 11.6446 - out_stats_loss: 4.9284 - out_counts_loss: 1.7646 - out_mean_covariance_loss: 60.7828 - out_fielding_position_loss: 1.9125 - val_loss: 11.9676 - val_out_stats_loss: 5.1248 - val_out_counts_loss: 1.8098 - val_out_mean_covariance_loss: 63.1884 - val_out_fielding_position_loss: 1.8735
Epoch 19/1000

Epoch 00019: val_loss improved from 11.92093 to 11.90771, saving model to models/bc/shift1/max2015/simple-rnn/7.h5
 - 5s - loss: 11.6053 - out_stats_loss: 4.9112 - out_counts_loss: 1.7723 - out_mean_covariance_loss: 60.2514 - out_fielding_position_loss: 1.9092 - val_loss: 11.9077 - val_out_stats_loss: 5.1289 - val_out_counts_loss: 1.7668 - val_out_mean_covariance_loss: 62.9389 - val_out_fielding_position_loss: 1.8650
Epoch 20/1000

Epoch 00020: val_loss improved from 11.90771 to 11.82867, saving model to models/bc/shift1/max2015/simple-rnn/7.h5
 - 5s - loss: 11.5717 - out_stats_loss: 4.9085 - out_counts_loss: 1.7586 - out_mean_covariance_loss: 60.3538 - out_fielding_position_loss: 1.8870 - val_loss: 11.8287 - val_out_stats_loss: 5.0908 - val_out_counts_loss: 1.7497 - val_out_mean_covariance_loss: 62.5607 - val_out_fielding_position_loss: 1.8601
Epoch 21/1000

Epoch 00021: val_loss improved from 11.82867 to 11.79842, saving model to models/bc/shift1/max2015/simple-rnn/7.h5
 - 5s - loss: 11.4560 - out_stats_loss: 4.8563 - out_counts_loss: 1.7425 - out_mean_covariance_loss: 59.5386 - out_fielding_position_loss: 1.8803 - val_loss: 11.7984 - val_out_stats_loss: 5.0776 - val_out_counts_loss: 1.7507 - val_out_mean_covariance_loss: 62.3745 - val_out_fielding_position_loss: 1.8515
Epoch 22/1000

Epoch 00022: val_loss improved from 11.79842 to 11.77488, saving model to models/bc/shift1/max2015/simple-rnn/7.h5
 - 5s - loss: 11.4561 - out_stats_loss: 4.8562 - out_counts_loss: 1.7505 - out_mean_covariance_loss: 59.6132 - out_fielding_position_loss: 1.8688 - val_loss: 11.7749 - val_out_stats_loss: 5.0678 - val_out_counts_loss: 1.7491 - val_out_mean_covariance_loss: 62.2424 - val_out_fielding_position_loss: 1.8459
Epoch 23/1000

Epoch 00023: val_loss did not improve
 - 5s - loss: 11.4778 - out_stats_loss: 4.8896 - out_counts_loss: 1.7467 - out_mean_covariance_loss: 59.7178 - out_fielding_position_loss: 1.8556 - val_loss: 11.7812 - val_out_stats_loss: 5.0768 - val_out_counts_loss: 1.7556 - val_out_mean_covariance_loss: 62.1273 - val_out_fielding_position_loss: 1.8424
Epoch 24/1000

Epoch 00024: val_loss improved from 11.77488 to 11.72745, saving model to models/bc/shift1/max2015/simple-rnn/7.h5
 - 5s - loss: 11.4555 - out_stats_loss: 4.8711 - out_counts_loss: 1.7431 - out_mean_covariance_loss: 59.7111 - out_fielding_position_loss: 1.8557 - val_loss: 11.7275 - val_out_stats_loss: 5.0488 - val_out_counts_loss: 1.7499 - val_out_mean_covariance_loss: 61.8829 - val_out_fielding_position_loss: 1.8346
Epoch 25/1000

Epoch 00025: val_loss improved from 11.72745 to 11.72570, saving model to models/bc/shift1/max2015/simple-rnn/7.h5
 - 5s - loss: 11.3728 - out_stats_loss: 4.8420 - out_counts_loss: 1.7303 - out_mean_covariance_loss: 59.1500 - out_fielding_position_loss: 1.8430 - val_loss: 11.7257 - val_out_stats_loss: 5.0556 - val_out_counts_loss: 1.7500 - val_out_mean_covariance_loss: 61.8353 - val_out_fielding_position_loss: 1.8284
Epoch 26/1000

Epoch 00026: val_loss did not improve
 - 5s - loss: 11.2949 - out_stats_loss: 4.8086 - out_counts_loss: 1.7123 - out_mean_covariance_loss: 58.8917 - out_fielding_position_loss: 1.8293 - val_loss: 11.7459 - val_out_stats_loss: 5.0681 - val_out_counts_loss: 1.7509 - val_out_mean_covariance_loss: 62.0078 - val_out_fielding_position_loss: 1.8265
Epoch 27/1000

Epoch 00027: val_loss improved from 11.72570 to 11.69894, saving model to models/bc/shift1/max2015/simple-rnn/7.h5
 - 5s - loss: 11.2931 - out_stats_loss: 4.8208 - out_counts_loss: 1.7093 - out_mean_covariance_loss: 59.0915 - out_fielding_position_loss: 1.8084 - val_loss: 11.6989 - val_out_stats_loss: 5.0466 - val_out_counts_loss: 1.7483 - val_out_mean_covariance_loss: 61.6638 - val_out_fielding_position_loss: 1.8209
Epoch 28/1000

Epoch 00028: val_loss improved from 11.69894 to 11.68360, saving model to models/bc/shift1/max2015/simple-rnn/7.h5
 - 5s - loss: 11.3136 - out_stats_loss: 4.8443 - out_counts_loss: 1.6922 - out_mean_covariance_loss: 59.4050 - out_fielding_position_loss: 1.8070 - val_loss: 11.6836 - val_out_stats_loss: 5.0424 - val_out_counts_loss: 1.7472 - val_out_mean_covariance_loss: 61.5767 - val_out_fielding_position_loss: 1.8152
Epoch 29/1000

Epoch 00029: val_loss improved from 11.68360 to 11.66025, saving model to models/bc/shift1/max2015/simple-rnn/7.h5
 - 5s - loss: 11.2103 - out_stats_loss: 4.7912 - out_counts_loss: 1.6925 - out_mean_covariance_loss: 58.4982 - out_fielding_position_loss: 1.8018 - val_loss: 11.6602 - val_out_stats_loss: 5.0306 - val_out_counts_loss: 1.7493 - val_out_mean_covariance_loss: 61.4123 - val_out_fielding_position_loss: 1.8097
Epoch 30/1000

Epoch 00030: val_loss did not improve
 - 5s - loss: 11.1759 - out_stats_loss: 4.7835 - out_counts_loss: 1.6936 - out_mean_covariance_loss: 58.2306 - out_fielding_position_loss: 1.7872 - val_loss: 11.6630 - val_out_stats_loss: 5.0395 - val_out_counts_loss: 1.7479 - val_out_mean_covariance_loss: 61.3903 - val_out_fielding_position_loss: 1.8060
Epoch 31/1000

Epoch 00031: val_loss improved from 11.66025 to 11.63794, saving model to models/bc/shift1/max2015/simple-rnn/7.h5
 - 5s - loss: 11.1900 - out_stats_loss: 4.7773 - out_counts_loss: 1.6995 - out_mean_covariance_loss: 58.3655 - out_fielding_position_loss: 1.7949 - val_loss: 11.6379 - val_out_stats_loss: 5.0195 - val_out_counts_loss: 1.7538 - val_out_mean_covariance_loss: 61.2588 - val_out_fielding_position_loss: 1.8017
Epoch 32/1000

Epoch 00032: val_loss did not improve
 - 5s - loss: 11.0600 - out_stats_loss: 4.7322 - out_counts_loss: 1.6691 - out_mean_covariance_loss: 57.6002 - out_fielding_position_loss: 1.7787 - val_loss: 11.6525 - val_out_stats_loss: 5.0299 - val_out_counts_loss: 1.7560 - val_out_mean_covariance_loss: 61.3293 - val_out_fielding_position_loss: 1.8002
Epoch 33/1000

Epoch 00033: val_loss did not improve
 - 5s - loss: 11.0726 - out_stats_loss: 4.7429 - out_counts_loss: 1.6754 - out_mean_covariance_loss: 57.7946 - out_fielding_position_loss: 1.7646 - val_loss: 11.6547 - val_out_stats_loss: 5.0401 - val_out_counts_loss: 1.7550 - val_out_mean_covariance_loss: 61.3384 - val_out_fielding_position_loss: 1.7927
Epoch 34/1000

Epoch 00034: val_loss improved from 11.63794 to 11.61186, saving model to models/bc/shift1/max2015/simple-rnn/7.h5
 - 5s - loss: 11.0131 - out_stats_loss: 4.7242 - out_counts_loss: 1.6638 - out_mean_covariance_loss: 57.3053 - out_fielding_position_loss: 1.7599 - val_loss: 11.6119 - val_out_stats_loss: 5.0157 - val_out_counts_loss: 1.7505 - val_out_mean_covariance_loss: 61.1446 - val_out_fielding_position_loss: 1.7884
Epoch 35/1000

Epoch 00035: val_loss did not improve
 - 5s - loss: 11.0851 - out_stats_loss: 4.7709 - out_counts_loss: 1.6552 - out_mean_covariance_loss: 57.9614 - out_fielding_position_loss: 1.7609 - val_loss: 11.6200 - val_out_stats_loss: 5.0263 - val_out_counts_loss: 1.7557 - val_out_mean_covariance_loss: 61.1037 - val_out_fielding_position_loss: 1.7828
Epoch 36/1000

Epoch 00036: val_loss did not improve
 - 4s - loss: 11.0408 - out_stats_loss: 4.7473 - out_counts_loss: 1.6437 - out_mean_covariance_loss: 58.0173 - out_fielding_position_loss: 1.7489 - val_loss: 11.6155 - val_out_stats_loss: 5.0176 - val_out_counts_loss: 1.7651 - val_out_mean_covariance_loss: 61.1038 - val_out_fielding_position_loss: 1.7775
Epoch 37/1000

Epoch 00037: val_loss did not improve
 - 5s - loss: 11.0061 - out_stats_loss: 4.7379 - out_counts_loss: 1.6494 - out_mean_covariance_loss: 57.4549 - out_fielding_position_loss: 1.7460 - val_loss: 11.6479 - val_out_stats_loss: 5.0459 - val_out_counts_loss: 1.7637 - val_out_mean_covariance_loss: 61.1370 - val_out_fielding_position_loss: 1.7815
Epoch 38/1000

Epoch 00038: val_loss improved from 11.61186 to 11.58955, saving model to models/bc/shift1/max2015/simple-rnn/7.h5
 - 5s - loss: 11.0038 - out_stats_loss: 4.7492 - out_counts_loss: 1.6451 - out_mean_covariance_loss: 57.6775 - out_fielding_position_loss: 1.7257 - val_loss: 11.5895 - val_out_stats_loss: 5.0147 - val_out_counts_loss: 1.7567 - val_out_mean_covariance_loss: 60.8565 - val_out_fielding_position_loss: 1.7754
Epoch 39/1000

Epoch 00039: val_loss improved from 11.58955 to 11.56141, saving model to models/bc/shift1/max2015/simple-rnn/7.h5
 - 5s - loss: 10.8558 - out_stats_loss: 4.6836 - out_counts_loss: 1.6214 - out_mean_covariance_loss: 56.5649 - out_fielding_position_loss: 1.7225 - val_loss: 11.5614 - val_out_stats_loss: 5.0041 - val_out_counts_loss: 1.7502 - val_out_mean_covariance_loss: 60.7563 - val_out_fielding_position_loss: 1.7693
Epoch 40/1000

Epoch 00040: val_loss did not improve
 - 5s - loss: 10.9223 - out_stats_loss: 4.7088 - out_counts_loss: 1.6198 - out_mean_covariance_loss: 57.3094 - out_fielding_position_loss: 1.7282 - val_loss: 11.5664 - val_out_stats_loss: 5.0070 - val_out_counts_loss: 1.7552 - val_out_mean_covariance_loss: 60.7148 - val_out_fielding_position_loss: 1.7684
Epoch 41/1000

Epoch 00041: val_loss did not improve
 - 5s - loss: 10.8911 - out_stats_loss: 4.7114 - out_counts_loss: 1.6195 - out_mean_covariance_loss: 57.0968 - out_fielding_position_loss: 1.7055 - val_loss: 11.6320 - val_out_stats_loss: 5.0384 - val_out_counts_loss: 1.7867 - val_out_mean_covariance_loss: 60.8672 - val_out_fielding_position_loss: 1.7636
Epoch 42/1000

Epoch 00042: val_loss did not improve
 - 5s - loss: 10.8220 - out_stats_loss: 4.6739 - out_counts_loss: 1.6043 - out_mean_covariance_loss: 56.8853 - out_fielding_position_loss: 1.6995 - val_loss: 11.5633 - val_out_stats_loss: 5.0047 - val_out_counts_loss: 1.7600 - val_out_mean_covariance_loss: 60.7125 - val_out_fielding_position_loss: 1.7629
Epoch 43/1000

Epoch 00043: val_loss did not improve
 - 5s - loss: 10.8051 - out_stats_loss: 4.6808 - out_counts_loss: 1.6024 - out_mean_covariance_loss: 56.6072 - out_fielding_position_loss: 1.6915 - val_loss: 11.6698 - val_out_stats_loss: 5.0517 - val_out_counts_loss: 1.8082 - val_out_mean_covariance_loss: 60.9534 - val_out_fielding_position_loss: 1.7622
Epoch 44/1000

Epoch 00044: val_loss improved from 11.56141 to 11.54472, saving model to models/bc/shift1/max2015/simple-rnn/7.h5
 - 5s - loss: 10.8338 - out_stats_loss: 4.6980 - out_counts_loss: 1.6047 - out_mean_covariance_loss: 56.9610 - out_fielding_position_loss: 1.6831 - val_loss: 11.5447 - val_out_stats_loss: 5.0041 - val_out_counts_loss: 1.7584 - val_out_mean_covariance_loss: 60.5871 - val_out_fielding_position_loss: 1.7529
Epoch 45/1000

Epoch 00045: val_loss did not improve
 - 5s - loss: 10.7447 - out_stats_loss: 4.6597 - out_counts_loss: 1.5910 - out_mean_covariance_loss: 56.3276 - out_fielding_position_loss: 1.6777 - val_loss: 11.5625 - val_out_stats_loss: 5.0138 - val_out_counts_loss: 1.7686 - val_out_mean_covariance_loss: 60.5398 - val_out_fielding_position_loss: 1.7531
Epoch 46/1000

Epoch 00046: val_loss did not improve
 - 5s - loss: 10.7378 - out_stats_loss: 4.6537 - out_counts_loss: 1.5919 - out_mean_covariance_loss: 56.1193 - out_fielding_position_loss: 1.6863 - val_loss: 11.6240 - val_out_stats_loss: 5.0234 - val_out_counts_loss: 1.8051 - val_out_mean_covariance_loss: 60.7301 - val_out_fielding_position_loss: 1.7590
Epoch 47/1000

Epoch 00047: val_loss did not improve
 - 5s - loss: 10.7439 - out_stats_loss: 4.6656 - out_counts_loss: 1.5742 - out_mean_covariance_loss: 56.4984 - out_fielding_position_loss: 1.6790 - val_loss: 11.6006 - val_out_stats_loss: 5.0260 - val_out_counts_loss: 1.7940 - val_out_mean_covariance_loss: 60.5524 - val_out_fielding_position_loss: 1.7531
Epoch 48/1000

Epoch 00048: val_loss did not improve
 - 5s - loss: 10.6831 - out_stats_loss: 4.6439 - out_counts_loss: 1.5735 - out_mean_covariance_loss: 56.0532 - out_fielding_position_loss: 1.6630 - val_loss: 11.6154 - val_out_stats_loss: 5.0277 - val_out_counts_loss: 1.8093 - val_out_mean_covariance_loss: 60.5609 - val_out_fielding_position_loss: 1.7503
Epoch 49/1000

Epoch 00049: val_loss did not improve
 - 5s - loss: 10.6796 - out_stats_loss: 4.6399 - out_counts_loss: 1.5724 - out_mean_covariance_loss: 56.1623 - out_fielding_position_loss: 1.6591 - val_loss: 11.5563 - val_out_stats_loss: 4.9993 - val_out_counts_loss: 1.7875 - val_out_mean_covariance_loss: 60.4864 - val_out_fielding_position_loss: 1.7451
Epoch 50/1000

Epoch 00050: val_loss improved from 11.54472 to 11.54272, saving model to models/bc/shift1/max2015/simple-rnn/7.h5
 - 5s - loss: 10.6653 - out_stats_loss: 4.6531 - out_counts_loss: 1.5525 - out_mean_covariance_loss: 56.2530 - out_fielding_position_loss: 1.6470 - val_loss: 11.5427 - val_out_stats_loss: 5.0072 - val_out_counts_loss: 1.7762 - val_out_mean_covariance_loss: 60.4216 - val_out_fielding_position_loss: 1.7383
Epoch 51/1000

Epoch 00051: val_loss did not improve
 - 5s - loss: 10.6041 - out_stats_loss: 4.6274 - out_counts_loss: 1.5401 - out_mean_covariance_loss: 55.8569 - out_fielding_position_loss: 1.6437 - val_loss: 11.5449 - val_out_stats_loss: 5.0042 - val_out_counts_loss: 1.7856 - val_out_mean_covariance_loss: 60.3755 - val_out_fielding_position_loss: 1.7364
Epoch 52/1000

Epoch 00052: val_loss did not improve
 - 4s - loss: 10.6206 - out_stats_loss: 4.6387 - out_counts_loss: 1.5413 - out_mean_covariance_loss: 56.0843 - out_fielding_position_loss: 1.6365 - val_loss: 11.5506 - val_out_stats_loss: 5.0081 - val_out_counts_loss: 1.7892 - val_out_mean_covariance_loss: 60.4023 - val_out_fielding_position_loss: 1.7331
Epoch 53/1000

Epoch 00053: val_loss did not improve
 - 4s - loss: 10.5816 - out_stats_loss: 4.6352 - out_counts_loss: 1.5342 - out_mean_covariance_loss: 55.7075 - out_fielding_position_loss: 1.6268 - val_loss: 11.7093 - val_out_stats_loss: 5.0767 - val_out_counts_loss: 1.8566 - val_out_mean_covariance_loss: 60.7053 - val_out_fielding_position_loss: 1.7409
Epoch 54/1000

Epoch 00054: val_loss did not improve
 - 5s - loss: 10.5316 - out_stats_loss: 4.5979 - out_counts_loss: 1.5280 - out_mean_covariance_loss: 55.4449 - out_fielding_position_loss: 1.6335 - val_loss: 11.6153 - val_out_stats_loss: 5.0320 - val_out_counts_loss: 1.8268 - val_out_mean_covariance_loss: 60.5121 - val_out_fielding_position_loss: 1.7308
Epoch 55/1000

Epoch 00055: val_loss did not improve
 - 5s - loss: 10.5105 - out_stats_loss: 4.6037 - out_counts_loss: 1.5179 - out_mean_covariance_loss: 55.4753 - out_fielding_position_loss: 1.6152 - val_loss: 11.5601 - val_out_stats_loss: 5.0167 - val_out_counts_loss: 1.8034 - val_out_mean_covariance_loss: 60.2757 - val_out_fielding_position_loss: 1.7262
Epoch 56/1000

Epoch 00056: val_loss did not improve
 - 5s - loss: 10.5362 - out_stats_loss: 4.6177 - out_counts_loss: 1.5196 - out_mean_covariance_loss: 55.6882 - out_fielding_position_loss: 1.6145 - val_loss: 11.5482 - val_out_stats_loss: 5.0070 - val_out_counts_loss: 1.8036 - val_out_mean_covariance_loss: 60.2670 - val_out_fielding_position_loss: 1.7242
Epoch 57/1000

Epoch 00057: val_loss did not improve
 - 5s - loss: 10.4415 - out_stats_loss: 4.5867 - out_counts_loss: 1.5004 - out_mean_covariance_loss: 55.0557 - out_fielding_position_loss: 1.6016 - val_loss: 11.5678 - val_out_stats_loss: 5.0269 - val_out_counts_loss: 1.8096 - val_out_mean_covariance_loss: 60.1817 - val_out_fielding_position_loss: 1.7222
Epoch 58/1000

Epoch 00058: val_loss did not improve
 - 5s - loss: 10.3945 - out_stats_loss: 4.5631 - out_counts_loss: 1.4972 - out_mean_covariance_loss: 54.7143 - out_fielding_position_loss: 1.5984 - val_loss: 11.5429 - val_out_stats_loss: 5.0168 - val_out_counts_loss: 1.7997 - val_out_mean_covariance_loss: 60.2216 - val_out_fielding_position_loss: 1.7153
Epoch 59/1000

Epoch 00059: val_loss did not improve
 - 5s - loss: 10.4173 - out_stats_loss: 4.5730 - out_counts_loss: 1.4961 - out_mean_covariance_loss: 55.0640 - out_fielding_position_loss: 1.5950 - val_loss: 11.5541 - val_out_stats_loss: 5.0129 - val_out_counts_loss: 1.8137 - val_out_mean_covariance_loss: 60.2482 - val_out_fielding_position_loss: 1.7150
Epoch 60/1000

Epoch 00060: val_loss improved from 11.54272 to 11.53727, saving model to models/bc/shift1/max2015/simple-rnn/7.h5
 - 5s - loss: 10.3363 - out_stats_loss: 4.5434 - out_counts_loss: 1.4874 - out_mean_covariance_loss: 54.4909 - out_fielding_position_loss: 1.5810 - val_loss: 11.5373 - val_out_stats_loss: 5.0106 - val_out_counts_loss: 1.8082 - val_out_mean_covariance_loss: 60.1435 - val_out_fielding_position_loss: 1.7113
Epoch 61/1000

Epoch 00061: val_loss did not improve
 - 5s - loss: 10.4229 - out_stats_loss: 4.5897 - out_counts_loss: 1.4935 - out_mean_covariance_loss: 55.2074 - out_fielding_position_loss: 1.5792 - val_loss: 11.5677 - val_out_stats_loss: 5.0189 - val_out_counts_loss: 1.8277 - val_out_mean_covariance_loss: 60.1713 - val_out_fielding_position_loss: 1.7125
Epoch 62/1000

Epoch 00062: val_loss did not improve
 - 5s - loss: 10.4328 - out_stats_loss: 4.5907 - out_counts_loss: 1.5018 - out_mean_covariance_loss: 55.0981 - out_fielding_position_loss: 1.5853 - val_loss: 11.5835 - val_out_stats_loss: 5.0277 - val_out_counts_loss: 1.8335 - val_out_mean_covariance_loss: 60.2130 - val_out_fielding_position_loss: 1.7117
Epoch 63/1000

Epoch 00063: val_loss did not improve
 - 5s - loss: 10.2943 - out_stats_loss: 4.5332 - out_counts_loss: 1.4729 - out_mean_covariance_loss: 54.2611 - out_fielding_position_loss: 1.5751 - val_loss: 11.5983 - val_out_stats_loss: 5.0266 - val_out_counts_loss: 1.8469 - val_out_mean_covariance_loss: 60.1830 - val_out_fielding_position_loss: 1.7156
Epoch 64/1000

Epoch 00064: val_loss did not improve
 - 5s - loss: 10.3301 - out_stats_loss: 4.5514 - out_counts_loss: 1.4800 - out_mean_covariance_loss: 54.4691 - out_fielding_position_loss: 1.5752 - val_loss: 11.5523 - val_out_stats_loss: 5.0191 - val_out_counts_loss: 1.8181 - val_out_mean_covariance_loss: 60.1428 - val_out_fielding_position_loss: 1.7080
Epoch 65/1000

Epoch 00065: val_loss did not improve
 - 5s - loss: 10.3283 - out_stats_loss: 4.5520 - out_counts_loss: 1.4684 - out_mean_covariance_loss: 54.7096 - out_fielding_position_loss: 1.5725 - val_loss: 11.5968 - val_out_stats_loss: 5.0282 - val_out_counts_loss: 1.8443 - val_out_mean_covariance_loss: 60.2303 - val_out_fielding_position_loss: 1.7128
Epoch 66/1000

Epoch 00066: val_loss did not improve
 - 5s - loss: 10.3114 - out_stats_loss: 4.5481 - out_counts_loss: 1.4855 - out_mean_covariance_loss: 54.4060 - out_fielding_position_loss: 1.5575 - val_loss: 11.5835 - val_out_stats_loss: 5.0350 - val_out_counts_loss: 1.8369 - val_out_mean_covariance_loss: 60.1680 - val_out_fielding_position_loss: 1.7032
Epoch 67/1000

Epoch 00067: val_loss did not improve
 - 5s - loss: 10.2875 - out_stats_loss: 4.5510 - out_counts_loss: 1.4464 - out_mean_covariance_loss: 54.8882 - out_fielding_position_loss: 1.5457 - val_loss: 11.5680 - val_out_stats_loss: 5.0236 - val_out_counts_loss: 1.8336 - val_out_mean_covariance_loss: 60.1108 - val_out_fielding_position_loss: 1.7053
Epoch 68/1000

Epoch 00068: val_loss did not improve
 - 5s - loss: 10.2065 - out_stats_loss: 4.5140 - out_counts_loss: 1.4530 - out_mean_covariance_loss: 53.9479 - out_fielding_position_loss: 1.5421 - val_loss: 11.6296 - val_out_stats_loss: 5.0377 - val_out_counts_loss: 1.8764 - val_out_mean_covariance_loss: 60.1576 - val_out_fielding_position_loss: 1.7077
Epoch 69/1000

Epoch 00069: val_loss did not improve
 - 5s - loss: 10.2488 - out_stats_loss: 4.5349 - out_counts_loss: 1.4442 - out_mean_covariance_loss: 54.3253 - out_fielding_position_loss: 1.5534 - val_loss: 11.5680 - val_out_stats_loss: 5.0210 - val_out_counts_loss: 1.8493 - val_out_mean_covariance_loss: 59.9854 - val_out_fielding_position_loss: 1.6984
Epoch 70/1000

Epoch 00070: val_loss did not improve
 - 5s - loss: 10.2102 - out_stats_loss: 4.5310 - out_counts_loss: 1.4342 - out_mean_covariance_loss: 54.1372 - out_fielding_position_loss: 1.5381 - val_loss: 11.6081 - val_out_stats_loss: 5.0399 - val_out_counts_loss: 1.8694 - val_out_mean_covariance_loss: 59.9931 - val_out_fielding_position_loss: 1.6991
Epoch 71/1000

Epoch 00071: val_loss did not improve
 - 5s - loss: 10.1731 - out_stats_loss: 4.5155 - out_counts_loss: 1.4309 - out_mean_covariance_loss: 54.0377 - out_fielding_position_loss: 1.5248 - val_loss: 11.6184 - val_out_stats_loss: 5.0385 - val_out_counts_loss: 1.8718 - val_out_mean_covariance_loss: 60.0775 - val_out_fielding_position_loss: 1.7042
Epoch 72/1000

Epoch 00072: val_loss did not improve
 - 5s - loss: 10.2254 - out_stats_loss: 4.5517 - out_counts_loss: 1.4315 - out_mean_covariance_loss: 54.2151 - out_fielding_position_loss: 1.5314 - val_loss: 11.6620 - val_out_stats_loss: 5.0655 - val_out_counts_loss: 1.8884 - val_out_mean_covariance_loss: 60.2031 - val_out_fielding_position_loss: 1.6980
Epoch 73/1000

Epoch 00073: val_loss did not improve
 - 5s - loss: 10.1770 - out_stats_loss: 4.5293 - out_counts_loss: 1.4286 - out_mean_covariance_loss: 53.9609 - out_fielding_position_loss: 1.5211 - val_loss: 11.6080 - val_out_stats_loss: 5.0354 - val_out_counts_loss: 1.8733 - val_out_mean_covariance_loss: 60.0513 - val_out_fielding_position_loss: 1.6967
Epoch 74/1000

Epoch 00074: val_loss did not improve
 - 5s - loss: 10.1502 - out_stats_loss: 4.5187 - out_counts_loss: 1.4217 - out_mean_covariance_loss: 53.7841 - out_fielding_position_loss: 1.5205 - val_loss: 11.6699 - val_out_stats_loss: 5.0580 - val_out_counts_loss: 1.9038 - val_out_mean_covariance_loss: 60.1962 - val_out_fielding_position_loss: 1.6983
Epoch 75/1000

Epoch 00075: val_loss did not improve
 - 5s - loss: 10.0846 - out_stats_loss: 4.4809 - out_counts_loss: 1.4185 - out_mean_covariance_loss: 53.3975 - out_fielding_position_loss: 1.5153 - val_loss: 11.6758 - val_out_stats_loss: 5.0489 - val_out_counts_loss: 1.9198 - val_out_mean_covariance_loss: 60.1621 - val_out_fielding_position_loss: 1.6990
Epoch 76/1000

Epoch 00076: val_loss did not improve
 - 5s - loss: 10.0526 - out_stats_loss: 4.4635 - out_counts_loss: 1.4177 - out_mean_covariance_loss: 53.2095 - out_fielding_position_loss: 1.5109 - val_loss: 11.6701 - val_out_stats_loss: 5.0608 - val_out_counts_loss: 1.9066 - val_out_mean_covariance_loss: 60.0709 - val_out_fielding_position_loss: 1.6992
Epoch 77/1000

Epoch 00077: val_loss did not improve
 - 4s - loss: 10.0231 - out_stats_loss: 4.4629 - out_counts_loss: 1.3980 - out_mean_covariance_loss: 53.2597 - out_fielding_position_loss: 1.4993 - val_loss: 11.8472 - val_out_stats_loss: 5.0963 - val_out_counts_loss: 2.0117 - val_out_mean_covariance_loss: 60.5218 - val_out_fielding_position_loss: 1.7131
Epoch 78/1000

Epoch 00078: val_loss did not improve
 - 5s - loss: 10.0102 - out_stats_loss: 4.4517 - out_counts_loss: 1.4109 - out_mean_covariance_loss: 52.7860 - out_fielding_position_loss: 1.5083 - val_loss: 11.6552 - val_out_stats_loss: 5.0665 - val_out_counts_loss: 1.8881 - val_out_mean_covariance_loss: 60.1522 - val_out_fielding_position_loss: 1.6929
Epoch 79/1000

Epoch 00079: val_loss did not improve
 - 4s - loss: 10.0274 - out_stats_loss: 4.4835 - out_counts_loss: 1.3983 - out_mean_covariance_loss: 53.0841 - out_fielding_position_loss: 1.4915 - val_loss: 11.7135 - val_out_stats_loss: 5.0619 - val_out_counts_loss: 1.9335 - val_out_mean_covariance_loss: 60.2317 - val_out_fielding_position_loss: 1.7064
Epoch 80/1000

Epoch 00080: val_loss did not improve
 - 5s - loss: 10.0537 - out_stats_loss: 4.4996 - out_counts_loss: 1.3875 - out_mean_covariance_loss: 53.5149 - out_fielding_position_loss: 1.4908 - val_loss: 11.7547 - val_out_stats_loss: 5.0927 - val_out_counts_loss: 1.9501 - val_out_mean_covariance_loss: 60.3184 - val_out_fielding_position_loss: 1.6959
Epoch 81/1000

Epoch 00081: val_loss did not improve
 - 5s - loss: 9.9625 - out_stats_loss: 4.4521 - out_counts_loss: 1.3795 - out_mean_covariance_loss: 52.8405 - out_fielding_position_loss: 1.4887 - val_loss: 11.6029 - val_out_stats_loss: 5.0375 - val_out_counts_loss: 1.8805 - val_out_mean_covariance_loss: 59.9617 - val_out_fielding_position_loss: 1.6868
Epoch 82/1000

Epoch 00082: val_loss did not improve
 - 4s - loss: 9.9647 - out_stats_loss: 4.4547 - out_counts_loss: 1.3742 - out_mean_covariance_loss: 53.0253 - out_fielding_position_loss: 1.4845 - val_loss: 11.7018 - val_out_stats_loss: 5.0680 - val_out_counts_loss: 1.9349 - val_out_mean_covariance_loss: 60.1136 - val_out_fielding_position_loss: 1.6933
Epoch 83/1000

Epoch 00083: val_loss did not improve
 - 5s - loss: 9.9810 - out_stats_loss: 4.4604 - out_counts_loss: 1.3844 - out_mean_covariance_loss: 53.0071 - out_fielding_position_loss: 1.4858 - val_loss: 11.6572 - val_out_stats_loss: 5.0518 - val_out_counts_loss: 1.9044 - val_out_mean_covariance_loss: 60.2193 - val_out_fielding_position_loss: 1.6901
Epoch 84/1000

Epoch 00084: val_loss did not improve
 - 4s - loss: 9.9218 - out_stats_loss: 4.4473 - out_counts_loss: 1.3616 - out_mean_covariance_loss: 52.7302 - out_fielding_position_loss: 1.4765 - val_loss: 11.6781 - val_out_stats_loss: 5.0596 - val_out_counts_loss: 1.9236 - val_out_mean_covariance_loss: 60.1201 - val_out_fielding_position_loss: 1.6888
Epoch 85/1000

Epoch 00085: val_loss did not improve
 - 4s - loss: 9.8804 - out_stats_loss: 4.4320 - out_counts_loss: 1.3509 - out_mean_covariance_loss: 52.5579 - out_fielding_position_loss: 1.4697 - val_loss: 11.6893 - val_out_stats_loss: 5.0592 - val_out_counts_loss: 1.9334 - val_out_mean_covariance_loss: 60.1418 - val_out_fielding_position_loss: 1.6896
Epoch 86/1000

Epoch 00086: val_loss did not improve
 - 4s - loss: 9.8924 - out_stats_loss: 4.4336 - out_counts_loss: 1.3517 - out_mean_covariance_loss: 52.6934 - out_fielding_position_loss: 1.4724 - val_loss: 11.7134 - val_out_stats_loss: 5.0739 - val_out_counts_loss: 1.9411 - val_out_mean_covariance_loss: 60.2041 - val_out_fielding_position_loss: 1.6881
Epoch 87/1000

Epoch 00087: val_loss did not improve
 - 5s - loss: 9.8240 - out_stats_loss: 4.4165 - out_counts_loss: 1.3447 - out_mean_covariance_loss: 52.0529 - out_fielding_position_loss: 1.4602 - val_loss: 11.8330 - val_out_stats_loss: 5.1168 - val_out_counts_loss: 2.0044 - val_out_mean_covariance_loss: 60.3507 - val_out_fielding_position_loss: 1.6943
Epoch 88/1000

Epoch 00088: val_loss did not improve
 - 4s - loss: 9.8625 - out_stats_loss: 4.4246 - out_counts_loss: 1.3493 - out_mean_covariance_loss: 52.5449 - out_fielding_position_loss: 1.4614 - val_loss: 11.7008 - val_out_stats_loss: 5.0814 - val_out_counts_loss: 1.9267 - val_out_mean_covariance_loss: 60.1022 - val_out_fielding_position_loss: 1.6876
Epoch 89/1000

Epoch 00089: val_loss did not improve
 - 4s - loss: 9.8344 - out_stats_loss: 4.4150 - out_counts_loss: 1.3460 - out_mean_covariance_loss: 52.3114 - out_fielding_position_loss: 1.4578 - val_loss: 11.6734 - val_out_stats_loss: 5.0599 - val_out_counts_loss: 1.9276 - val_out_mean_covariance_loss: 59.9794 - val_out_fielding_position_loss: 1.6869
Epoch 90/1000

Epoch 00090: val_loss did not improve
 - 4s - loss: 9.8509 - out_stats_loss: 4.4313 - out_counts_loss: 1.3448 - out_mean_covariance_loss: 52.3800 - out_fielding_position_loss: 1.4558 - val_loss: 11.6983 - val_out_stats_loss: 5.0618 - val_out_counts_loss: 1.9426 - val_out_mean_covariance_loss: 60.2095 - val_out_fielding_position_loss: 1.6835
Epoch 91/1000

Epoch 00091: val_loss did not improve
 - 4s - loss: 9.8448 - out_stats_loss: 4.4268 - out_counts_loss: 1.3406 - out_mean_covariance_loss: 52.5582 - out_fielding_position_loss: 1.4495 - val_loss: 11.7306 - val_out_stats_loss: 5.0803 - val_out_counts_loss: 1.9584 - val_out_mean_covariance_loss: 60.1802 - val_out_fielding_position_loss: 1.6829
Epoch 92/1000

Epoch 00092: val_loss did not improve
 - 5s - loss: 9.8386 - out_stats_loss: 4.4313 - out_counts_loss: 1.3280 - out_mean_covariance_loss: 52.6737 - out_fielding_position_loss: 1.4457 - val_loss: 11.7433 - val_out_stats_loss: 5.0763 - val_out_counts_loss: 1.9645 - val_out_mean_covariance_loss: 60.3511 - val_out_fielding_position_loss: 1.6850
Epoch 93/1000

Epoch 00093: val_loss did not improve
 - 4s - loss: 9.7730 - out_stats_loss: 4.4024 - out_counts_loss: 1.3228 - out_mean_covariance_loss: 52.0493 - out_fielding_position_loss: 1.4453 - val_loss: 11.7365 - val_out_stats_loss: 5.0769 - val_out_counts_loss: 1.9662 - val_out_mean_covariance_loss: 60.2313 - val_out_fielding_position_loss: 1.6818
Epoch 94/1000

Epoch 00094: val_loss did not improve
 - 5s - loss: 9.7813 - out_stats_loss: 4.4035 - out_counts_loss: 1.3324 - out_mean_covariance_loss: 52.0021 - out_fielding_position_loss: 1.4452 - val_loss: 11.7222 - val_out_stats_loss: 5.0682 - val_out_counts_loss: 1.9498 - val_out_mean_covariance_loss: 60.3265 - val_out_fielding_position_loss: 1.6879
Epoch 95/1000

Epoch 00095: val_loss did not improve
 - 4s - loss: 9.7865 - out_stats_loss: 4.4093 - out_counts_loss: 1.3220 - out_mean_covariance_loss: 52.2627 - out_fielding_position_loss: 1.4421 - val_loss: 11.7433 - val_out_stats_loss: 5.0760 - val_out_counts_loss: 1.9695 - val_out_mean_covariance_loss: 60.1822 - val_out_fielding_position_loss: 1.6887
Epoch 96/1000

Epoch 00096: val_loss did not improve
 - 5s - loss: 9.7019 - out_stats_loss: 4.3815 - out_counts_loss: 1.3130 - out_mean_covariance_loss: 51.7235 - out_fielding_position_loss: 1.4212 - val_loss: 11.7195 - val_out_stats_loss: 5.0690 - val_out_counts_loss: 1.9538 - val_out_mean_covariance_loss: 60.2176 - val_out_fielding_position_loss: 1.6858
Epoch 97/1000

Epoch 00097: val_loss did not improve
 - 5s - loss: 9.7064 - out_stats_loss: 4.3798 - out_counts_loss: 1.3138 - out_mean_covariance_loss: 51.6760 - out_fielding_position_loss: 1.4289 - val_loss: 11.7727 - val_out_stats_loss: 5.0998 - val_out_counts_loss: 1.9669 - val_out_mean_covariance_loss: 60.3768 - val_out_fielding_position_loss: 1.6871
Epoch 98/1000

Epoch 00098: val_loss did not improve
 - 5s - loss: 9.7436 - out_stats_loss: 4.4008 - out_counts_loss: 1.3189 - out_mean_covariance_loss: 51.9183 - out_fielding_position_loss: 1.4280 - val_loss: 11.8189 - val_out_stats_loss: 5.1070 - val_out_counts_loss: 2.0024 - val_out_mean_covariance_loss: 60.3574 - val_out_fielding_position_loss: 1.6916
Epoch 99/1000

Epoch 00099: val_loss did not improve
 - 4s - loss: 9.6615 - out_stats_loss: 4.3720 - out_counts_loss: 1.2989 - out_mean_covariance_loss: 51.5658 - out_fielding_position_loss: 1.4124 - val_loss: 11.7233 - val_out_stats_loss: 5.0694 - val_out_counts_loss: 1.9628 - val_out_mean_covariance_loss: 60.2518 - val_out_fielding_position_loss: 1.6785
Epoch 100/1000

Epoch 00100: val_loss did not improve
 - 5s - loss: 9.6918 - out_stats_loss: 4.3792 - out_counts_loss: 1.3091 - out_mean_covariance_loss: 51.7110 - out_fielding_position_loss: 1.4179 - val_loss: 11.7451 - val_out_stats_loss: 5.0773 - val_out_counts_loss: 1.9725 - val_out_mean_covariance_loss: 60.2081 - val_out_fielding_position_loss: 1.6849
Epoch 101/1000

Epoch 00101: val_loss did not improve
 - 5s - loss: 9.6045 - out_stats_loss: 4.3461 - out_counts_loss: 1.2907 - out_mean_covariance_loss: 51.0957 - out_fielding_position_loss: 1.4129 - val_loss: 11.7841 - val_out_stats_loss: 5.0895 - val_out_counts_loss: 1.9874 - val_out_mean_covariance_loss: 60.3952 - val_out_fielding_position_loss: 1.6873
Epoch 102/1000

Epoch 00102: val_loss did not improve
 - 4s - loss: 9.6269 - out_stats_loss: 4.3610 - out_counts_loss: 1.2917 - out_mean_covariance_loss: 51.2708 - out_fielding_position_loss: 1.4107 - val_loss: 11.8031 - val_out_stats_loss: 5.0998 - val_out_counts_loss: 1.9972 - val_out_mean_covariance_loss: 60.5473 - val_out_fielding_position_loss: 1.6787
Epoch 103/1000

Epoch 00103: val_loss did not improve
 - 4s - loss: 9.6457 - out_stats_loss: 4.3675 - out_counts_loss: 1.2885 - out_mean_covariance_loss: 51.5611 - out_fielding_position_loss: 1.4116 - val_loss: 11.7998 - val_out_stats_loss: 5.0899 - val_out_counts_loss: 2.0022 - val_out_mean_covariance_loss: 60.4433 - val_out_fielding_position_loss: 1.6855
Epoch 104/1000

Epoch 00104: val_loss did not improve
 - 4s - loss: 9.5964 - out_stats_loss: 4.3539 - out_counts_loss: 1.2809 - out_mean_covariance_loss: 51.1318 - out_fielding_position_loss: 1.4050 - val_loss: 11.7880 - val_out_stats_loss: 5.0912 - val_out_counts_loss: 1.9937 - val_out_mean_covariance_loss: 60.3813 - val_out_fielding_position_loss: 1.6841
Epoch 105/1000

Epoch 00105: val_loss did not improve
 - 4s - loss: 9.5579 - out_stats_loss: 4.3349 - out_counts_loss: 1.2695 - out_mean_covariance_loss: 51.1469 - out_fielding_position_loss: 1.3962 - val_loss: 11.8280 - val_out_stats_loss: 5.1115 - val_out_counts_loss: 2.0035 - val_out_mean_covariance_loss: 60.5346 - val_out_fielding_position_loss: 1.6863
Epoch 106/1000

Epoch 00106: val_loss did not improve
 - 4s - loss: 9.5968 - out_stats_loss: 4.3561 - out_counts_loss: 1.2762 - out_mean_covariance_loss: 51.2928 - out_fielding_position_loss: 1.3999 - val_loss: 11.7885 - val_out_stats_loss: 5.0920 - val_out_counts_loss: 1.9851 - val_out_mean_covariance_loss: 60.6208 - val_out_fielding_position_loss: 1.6803
Epoch 107/1000

Epoch 00107: val_loss did not improve
 - 4s - loss: 9.5993 - out_stats_loss: 4.3566 - out_counts_loss: 1.2733 - out_mean_covariance_loss: 51.4597 - out_fielding_position_loss: 1.3964 - val_loss: 11.8473 - val_out_stats_loss: 5.1154 - val_out_counts_loss: 2.0161 - val_out_mean_covariance_loss: 60.6386 - val_out_fielding_position_loss: 1.6838
Epoch 108/1000

Epoch 00108: val_loss did not improve
 - 5s - loss: 9.6088 - out_stats_loss: 4.3593 - out_counts_loss: 1.2859 - out_mean_covariance_loss: 51.2990 - out_fielding_position_loss: 1.3987 - val_loss: 11.8613 - val_out_stats_loss: 5.1218 - val_out_counts_loss: 2.0217 - val_out_mean_covariance_loss: 60.7224 - val_out_fielding_position_loss: 1.6817
Epoch 109/1000

Epoch 00109: val_loss did not improve
 - 4s - loss: 9.5731 - out_stats_loss: 4.3522 - out_counts_loss: 1.2729 - out_mean_covariance_loss: 51.1773 - out_fielding_position_loss: 1.3891 - val_loss: 11.8348 - val_out_stats_loss: 5.1104 - val_out_counts_loss: 2.0112 - val_out_mean_covariance_loss: 60.5596 - val_out_fielding_position_loss: 1.6853
Epoch 110/1000

Epoch 00110: val_loss did not improve
 - 4s - loss: 9.5413 - out_stats_loss: 4.3349 - out_counts_loss: 1.2634 - out_mean_covariance_loss: 51.0325 - out_fielding_position_loss: 1.3914 - val_loss: 11.9355 - val_out_stats_loss: 5.1490 - val_out_counts_loss: 2.0634 - val_out_mean_covariance_loss: 60.7222 - val_out_fielding_position_loss: 1.6870
/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Years: [1958,2015]
Shift: 1
Fold: 4
Training into models/bc/shift1/max2015/simple-rnn/7.h5
/usr/local/lib/python3.5/dist-packages/keras/legacy/layers.py:533: UserWarning: The `MaxoutDense` layer is deprecated and will be removed after 06/2017.
  warnings.warn('The `MaxoutDense` layer is deprecated '
