__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
in_age (InputLayer)             (None, None, 2)      0                                            
__________________________________________________________________________________________________
in_bio (InputLayer)             (None, None, 7)      0                                            
__________________________________________________________________________________________________
in_fielding_position (InputLaye (None, None, 2)      0                                            
__________________________________________________________________________________________________
in_out_fielding_position (Input (None, None, 12)     0                                            
__________________________________________________________________________________________________
in_out_league_offense (InputLay (None, None, 9)      0                                            
__________________________________________________________________________________________________
in_out_park_factors (InputLayer (None, None, 8)      0                                            
__________________________________________________________________________________________________
in_out_plate_discipline (InputL (None, None, 8)      0                                            
__________________________________________________________________________________________________
in_out_running (InputLayer)     (None, None, 18)     0                                            
__________________________________________________________________________________________________
in_out_saber (InputLayer)       (None, None, 14)     0                                            
__________________________________________________________________________________________________
in_out_stats_extended (InputLay (None, None, 36)     0                                            
__________________________________________________________________________________________________
in_park_factors (InputLayer)    (None, None, 8)      0                                            
__________________________________________________________________________________________________
masked_in_age (Masking)         (None, None, 2)      0           in_age[0][0]                     
__________________________________________________________________________________________________
masked_in_bio (Masking)         (None, None, 7)      0           in_bio[0][0]                     
__________________________________________________________________________________________________
masked_in_fielding_position (Ma (None, None, 2)      0           in_fielding_position[0][0]       
__________________________________________________________________________________________________
masked_in_out_fielding_position (None, None, 12)     0           in_out_fielding_position[0][0]   
__________________________________________________________________________________________________
masked_in_out_league_offense (M (None, None, 9)      0           in_out_league_offense[0][0]      
__________________________________________________________________________________________________
masked_in_out_park_factors (Mas (None, None, 8)      0           in_out_park_factors[0][0]        
__________________________________________________________________________________________________
masked_in_out_plate_discipline  (None, None, 8)      0           in_out_plate_discipline[0][0]    
__________________________________________________________________________________________________
masked_in_out_running (Masking) (None, None, 18)     0           in_out_running[0][0]             
__________________________________________________________________________________________________
masked_in_out_saber (Masking)   (None, None, 14)     0           in_out_saber[0][0]               
__________________________________________________________________________________________________
masked_in_out_stats_extended (M (None, None, 36)     0           in_out_stats_extended[0][0]      
__________________________________________________________________________________________________
masked_in_park_factors (Masking (None, None, 8)      0           in_park_factors[0][0]            
__________________________________________________________________________________________________
time_distributed_5 (TimeDistrib (None, None, 1)      0           masked_in_age[0][0]              
__________________________________________________________________________________________________
time_distributed_4 (TimeDistrib (None, None, 6)      0           masked_in_bio[0][0]              
__________________________________________________________________________________________________
time_distributed_1 (TimeDistrib (None, None, 1)      0           masked_in_fielding_position[0][0]
__________________________________________________________________________________________________
time_distributed_7 (TimeDistrib (None, None, 11)     0           masked_in_out_fielding_position[0
__________________________________________________________________________________________________
time_distributed_10 (TimeDistri (None, None, 8)      0           masked_in_out_league_offense[0][0
__________________________________________________________________________________________________
time_distributed_3 (TimeDistrib (None, None, 7)      0           masked_in_out_park_factors[0][0] 
__________________________________________________________________________________________________
time_distributed_6 (TimeDistrib (None, None, 7)      0           masked_in_out_plate_discipline[0]
__________________________________________________________________________________________________
time_distributed_11 (TimeDistri (None, None, 17)     0           masked_in_out_running[0][0]      
__________________________________________________________________________________________________
time_distributed_2 (TimeDistrib (None, None, 13)     0           masked_in_out_saber[0][0]        
__________________________________________________________________________________________________
time_distributed_8 (TimeDistrib (None, None, 35)     0           masked_in_out_stats_extended[0][0
__________________________________________________________________________________________________
time_distributed_9 (TimeDistrib (None, None, 7)      0           masked_in_park_factors[0][0]     
__________________________________________________________________________________________________
norm_in_age (BatchNormalization (None, None, 1)      4           time_distributed_5[0][0]         
__________________________________________________________________________________________________
norm_in_bio (BatchNormalization (None, None, 6)      24          time_distributed_4[0][0]         
__________________________________________________________________________________________________
norm_in_fielding_position (Batc (None, None, 1)      4           time_distributed_1[0][0]         
__________________________________________________________________________________________________
norm_in_out_fielding_position ( (None, None, 11)     44          time_distributed_7[0][0]         
__________________________________________________________________________________________________
norm_in_out_league_offense (Bat (None, None, 8)      32          time_distributed_10[0][0]        
__________________________________________________________________________________________________
norm_in_out_park_factors (Batch (None, None, 7)      28          time_distributed_3[0][0]         
__________________________________________________________________________________________________
norm_in_out_plate_discipline (B (None, None, 7)      28          time_distributed_6[0][0]         
__________________________________________________________________________________________________2018-02-08 02:18:15.095126: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-02-08 02:18:21.714345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: eca0:00:00.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2018-02-08 02:18:21.714392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: eca0:00:00.0, compute capability: 3.7)

norm_in_out_running (BatchNorma (None, None, 17)     68          time_distributed_11[0][0]        
__________________________________________________________________________________________________
norm_in_out_saber (BatchNormali (None, None, 13)     52          time_distributed_2[0][0]         
__________________________________________________________________________________________________
norm_in_out_stats_extended (Bat (None, None, 35)     140         time_distributed_8[0][0]         
__________________________________________________________________________________________________
norm_in_park_factors (BatchNorm (None, None, 7)      28          time_distributed_9[0][0]         
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, None, 113)    0           norm_in_age[0][0]                
                                                                 norm_in_bio[0][0]                
                                                                 norm_in_fielding_position[0][0]  
                                                                 norm_in_out_fielding_position[0][
                                                                 norm_in_out_league_offense[0][0] 
                                                                 norm_in_out_park_factors[0][0]   
                                                                 norm_in_out_plate_discipline[0][0
                                                                 norm_in_out_running[0][0]        
                                                                 norm_in_out_saber[0][0]          
                                                                 norm_in_out_stats_extended[0][0] 
                                                                 norm_in_park_factors[0][0]       
__________________________________________________________________________________________________
gru_1 (GRU)                     (None, None, 113)    76953       concatenate_1[0][0]              
__________________________________________________________________________________________________
gru_2 (GRU)                     (None, None, 113)    76953       gru_1[0][0]                      
__________________________________________________________________________________________________
mv_out_stats (TimeDistributed)  (None, None, 5)      4560        gru_2[0][0]                      
__________________________________________________________________________________________________
mv_out_counts (TimeDistributed) (None, None, 3)      2736        gru_2[0][0]                      
__________________________________________________________________________________________________
mv_out_mean_covariance (TimeDis (None, None, 72)     65664       gru_2[0][0]                      
__________________________________________________________________________________________________
mv_out_fielding_position (TimeD (None, None, 11)     10032       gru_2[0][0]                      
__________________________________________________________________________________________________
out_stats (Activation)          (None, None, 5)      0           mv_out_stats[0][0]               
__________________________________________________________________________________________________
out_counts (Activation)         (None, None, 3)      0           mv_out_counts[0][0]              
__________________________________________________________________________________________________
out_mean_covariance (Activation (None, None, 72)     0           mv_out_mean_covariance[0][0]     
__________________________________________________________________________________________________
out_fielding_position (Activati (None, None, 11)     0           mv_out_fielding_position[0][0]   
==================================================================================================
Total params: 237,350
Trainable params: 237,124
Non-trainable params: 226
__________________________________________________________________________________________________
Train on 5879 samples, validate on 1409 samples
Epoch 1/1000

Epoch 00001: val_loss improved from inf to 20.24990, saving model to models/bc/shift2/max2016/simple-rnn/6.h5
 - 16s - loss: 21.8212 - out_stats_loss: 8.3126 - out_counts_loss: 3.7360 - out_mean_covariance_loss: 105.0997 - out_fielding_position_loss: 4.5176 - val_loss: 20.2499 - val_out_stats_loss: 7.8035 - val_out_counts_loss: 3.1385 - val_out_mean_covariance_loss: 99.9233 - val_out_fielding_position_loss: 4.3118
Epoch 2/1000

Epoch 00002: val_loss improved from 20.24990 to 17.59609, saving model to models/bc/shift2/max2016/simple-rnn/6.h5
 - 5s - loss: 18.7145 - out_stats_loss: 7.0636 - out_counts_loss: 2.8939 - out_mean_covariance_loss: 92.3800 - out_fielding_position_loss: 4.1380 - val_loss: 17.5961 - val_out_stats_loss: 6.6434 - val_out_counts_loss: 2.6218 - val_out_mean_covariance_loss: 87.3976 - val_out_fielding_position_loss: 3.9610
Epoch 3/1000

Epoch 00003: val_loss improved from 17.59609 to 16.03928, saving model to models/bc/shift2/max2016/simple-rnn/6.h5
 - 5s - loss: 16.7013 - out_stats_loss: 6.1931 - out_counts_loss: 2.6084 - out_mean_covariance_loss: 81.7195 - out_fielding_position_loss: 3.8138 - val_loss: 16.0393 - val_out_stats_loss: 6.0323 - val_out_counts_loss: 2.4124 - val_out_mean_covariance_loss: 79.0612 - val_out_fielding_position_loss: 3.6415
Epoch 4/1000

Epoch 00004: val_loss improved from 16.03928 to 15.28322, saving model to models/bc/shift2/max2016/simple-rnn/6.h5
 - 5s - loss: 15.6328 - out_stats_loss: 5.8215 - out_counts_loss: 2.4619 - out_mean_covariance_loss: 76.2488 - out_fielding_position_loss: 3.5369 - val_loss: 15.2832 - val_out_stats_loss: 5.8216 - val_out_counts_loss: 2.3326 - val_out_mean_covariance_loss: 74.7891 - val_out_fielding_position_loss: 3.3895
Epoch 5/1000

Epoch 00005: val_loss improved from 15.28322 to 14.77723, saving model to models/bc/shift2/max2016/simple-rnn/6.h5
 - 5s - loss: 15.0033 - out_stats_loss: 5.6649 - out_counts_loss: 2.3962 - out_mean_covariance_loss: 72.9866 - out_fielding_position_loss: 3.2929 - val_loss: 14.7772 - val_out_stats_loss: 5.7003 - val_out_counts_loss: 2.2823 - val_out_mean_covariance_loss: 72.1419 - val_out_fielding_position_loss: 3.1876
Epoch 6/1000

Epoch 00006: val_loss improved from 14.77723 to 14.42991, saving model to models/bc/shift2/max2016/simple-rnn/6.h5
 - 5s - loss: 14.5894 - out_stats_loss: 5.5503 - out_counts_loss: 2.3739 - out_mean_covariance_loss: 70.5189 - out_fielding_position_loss: 3.1392 - val_loss: 14.4299 - val_out_stats_loss: 5.6197 - val_out_counts_loss: 2.2739 - val_out_mean_covariance_loss: 70.4514 - val_out_fielding_position_loss: 3.0137
Epoch 7/1000

Epoch 00007: val_loss improved from 14.42991 to 14.14731, saving model to models/bc/shift2/max2016/simple-rnn/6.h5
 - 5s - loss: 14.2521 - out_stats_loss: 5.4821 - out_counts_loss: 2.3401 - out_mean_covariance_loss: 68.9842 - out_fielding_position_loss: 2.9806 - val_loss: 14.1473 - val_out_stats_loss: 5.5577 - val_out_counts_loss: 2.2396 - val_out_mean_covariance_loss: 69.0601 - val_out_fielding_position_loss: 2.8970
Epoch 8/1000

Epoch 00008: val_loss improved from 14.14731 to 14.00535, saving model to models/bc/shift2/max2016/simple-rnn/6.h5
 - 5s - loss: 14.1314 - out_stats_loss: 5.4835 - out_counts_loss: 2.3261 - out_mean_covariance_loss: 68.4935 - out_fielding_position_loss: 2.8971 - val_loss: 14.0053 - val_out_stats_loss: 5.5247 - val_out_counts_loss: 2.2447 - val_out_mean_covariance_loss: 68.5672 - val_out_fielding_position_loss: 2.8076
Epoch 9/1000

Epoch 00009: val_loss improved from 14.00535 to 13.84498, saving model to models/bc/shift2/max2016/simple-rnn/6.h5
 - 5s - loss: 13.8667 - out_stats_loss: 5.4042 - out_counts_loss: 2.2982 - out_mean_covariance_loss: 67.2829 - out_fielding_position_loss: 2.8001 - val_loss: 13.8450 - val_out_stats_loss: 5.4922 - val_out_counts_loss: 2.2276 - val_out_mean_covariance_loss: 67.8755 - val_out_fielding_position_loss: 2.7314
Epoch 10/1000

Epoch 00010: val_loss improved from 13.84498 to 13.72504, saving model to models/bc/shift2/max2016/simple-rnn/6.h5
 - 5s - loss: 13.6939 - out_stats_loss: 5.3506 - out_counts_loss: 2.2819 - out_mean_covariance_loss: 66.5097 - out_fielding_position_loss: 2.7360 - val_loss: 13.7250 - val_out_stats_loss: 5.4608 - val_out_counts_loss: 2.2192 - val_out_mean_covariance_loss: 67.3448 - val_out_fielding_position_loss: 2.6779
Epoch 11/1000

Epoch 00011: val_loss improved from 13.72504 to 13.65076, saving model to models/bc/shift2/max2016/simple-rnn/6.h5
 - 5s - loss: 13.5893 - out_stats_loss: 5.3256 - out_counts_loss: 2.2697 - out_mean_covariance_loss: 66.0851 - out_fielding_position_loss: 2.6897 - val_loss: 13.6508 - val_out_stats_loss: 5.4505 - val_out_counts_loss: 2.2094 - val_out_mean_covariance_loss: 67.0683 - val_out_fielding_position_loss: 2.6374
Epoch 12/1000

Epoch 00012: val_loss improved from 13.65076 to 13.58008, saving model to models/bc/shift2/max2016/simple-rnn/6.h5
 - 5s - loss: 13.4380 - out_stats_loss: 5.2754 - out_counts_loss: 2.2505 - out_mean_covariance_loss: 65.2767 - out_fielding_position_loss: 2.6484 - val_loss: 13.5801 - val_out_stats_loss: 5.4225 - val_out_counts_loss: 2.2123 - val_out_mean_covariance_loss: 66.7432 - val_out_fielding_position_loss: 2.6082
Epoch 13/1000

Epoch 00013: val_loss improved from 13.58008 to 13.54249, saving model to models/bc/shift2/max2016/simple-rnn/6.h5
 - 5s - loss: 13.4498 - out_stats_loss: 5.3103 - out_counts_loss: 2.2304 - out_mean_covariance_loss: 65.9636 - out_fielding_position_loss: 2.6108 - val_loss: 13.5425 - val_out_stats_loss: 5.4173 - val_out_counts_loss: 2.2123 - val_out_mean_covariance_loss: 66.5632 - val_out_fielding_position_loss: 2.5847
Epoch 14/1000

Epoch 00014: val_loss improved from 13.54249 to 13.47980, saving model to models/bc/shift2/max2016/simple-rnn/6.h5
 - 5s - loss: 13.3830 - out_stats_loss: 5.2800 - out_counts_loss: 2.2291 - out_mean_covariance_loss: 65.4281 - out_fielding_position_loss: 2.6024 - val_loss: 13.4798 - val_out_stats_loss: 5.3857 - val_out_counts_loss: 2.2180 - val_out_mean_covariance_loss: 66.3548 - val_out_fielding_position_loss: 2.5584
Epoch 15/1000

Epoch 00015: val_loss improved from 13.47980 to 13.42809, saving model to models/bc/shift2/max2016/simple-rnn/6.h5
 - 5s - loss: 13.3109 - out_stats_loss: 5.2522 - out_counts_loss: 2.2186 - out_mean_covariance_loss: 65.2950 - out_fielding_position_loss: 2.5753 - val_loss: 13.4281 - val_out_stats_loss: 5.3713 - val_out_counts_loss: 2.2054 - val_out_mean_covariance_loss: 66.2299 - val_out_fielding_position_loss: 2.5399
Epoch 16/1000

Epoch 00016: val_loss improved from 13.42809 to 13.36529, saving model to models/bc/shift2/max2016/simple-rnn/6.h5
 - 5s - loss: 13.2089 - out_stats_loss: 5.2182 - out_counts_loss: 2.2079 - out_mean_covariance_loss: 64.4285 - out_fielding_position_loss: 2.5614 - val_loss: 13.3653 - val_out_stats_loss: 5.3424 - val_out_counts_loss: 2.2045 - val_out_mean_covariance_loss: 65.8486 - val_out_fielding_position_loss: 2.5260
Epoch 17/1000

Epoch 00017: val_loss improved from 13.36529 to 13.32546, saving model to models/bc/shift2/max2016/simple-rnn/6.h5
 - 5s - loss: 13.1448 - out_stats_loss: 5.2030 - out_counts_loss: 2.1987 - out_mean_covariance_loss: 64.2298 - out_fielding_position_loss: 2.5316 - val_loss: 13.3255 - val_out_stats_loss: 5.3238 - val_out_counts_loss: 2.2004 - val_out_mean_covariance_loss: 65.8161 - val_out_fielding_position_loss: 2.5104
Epoch 18/1000

Epoch 00018: val_loss improved from 13.32546 to 13.27084, saving model to models/bc/shift2/max2016/simple-rnn/6.h5
 - 5s - loss: 13.0688 - out_stats_loss: 5.1699 - out_counts_loss: 2.1946 - out_mean_covariance_loss: 63.7808 - out_fielding_position_loss: 2.5153 - val_loss: 13.2708 - val_out_stats_loss: 5.3064 - val_out_counts_loss: 2.1877 - val_out_mean_covariance_loss: 65.5740 - val_out_fielding_position_loss: 2.4981
Epoch 19/1000

Epoch 00019: val_loss improved from 13.27084 to 13.23113, saving model to models/bc/shift2/max2016/simple-rnn/6.h5
 - 5s - loss: 12.9584 - out_stats_loss: 5.1403 - out_counts_loss: 2.1517 - out_mean_covariance_loss: 63.4179 - out_fielding_position_loss: 2.4955 - val_loss: 13.2311 - val_out_stats_loss: 5.2969 - val_out_counts_loss: 2.1709 - val_out_mean_covariance_loss: 65.3839 - val_out_fielding_position_loss: 2.4942
Epoch 20/1000

Epoch 00020: val_loss did not improve
 - 5s - loss: 12.9324 - out_stats_loss: 5.1275 - out_counts_loss: 2.1427 - out_mean_covariance_loss: 63.3461 - out_fielding_position_loss: 2.4949 - val_loss: 13.2614 - val_out_stats_loss: 5.3075 - val_out_counts_loss: 2.2038 - val_out_mean_covariance_loss: 65.2477 - val_out_fielding_position_loss: 2.4877
Epoch 21/1000

Epoch 00021: val_loss improved from 13.23113 to 13.15332, saving model to models/bc/shift2/max2016/simple-rnn/6.h5
 - 5s - loss: 12.8549 - out_stats_loss: 5.1126 - out_counts_loss: 2.1372 - out_mean_covariance_loss: 62.9477 - out_fielding_position_loss: 2.4577 - val_loss: 13.1533 - val_out_stats_loss: 5.2781 - val_out_counts_loss: 2.1553 - val_out_mean_covariance_loss: 64.9256 - val_out_fielding_position_loss: 2.4737
Epoch 22/1000

Epoch 00022: val_loss did not improve
 - 5s - loss: 12.7995 - out_stats_loss: 5.0956 - out_counts_loss: 2.1222 - out_mean_covariance_loss: 62.7209 - out_fielding_position_loss: 2.4456 - val_loss: 13.2016 - val_out_stats_loss: 5.3003 - val_out_counts_loss: 2.1813 - val_out_mean_covariance_loss: 65.0493 - val_out_fielding_position_loss: 2.4676
Epoch 23/1000

Epoch 00023: val_loss improved from 13.15332 to 13.14242, saving model to models/bc/shift2/max2016/simple-rnn/6.h5
 - 5s - loss: 12.7388 - out_stats_loss: 5.0936 - out_counts_loss: 2.0918 - out_mean_covariance_loss: 62.8539 - out_fielding_position_loss: 2.4107 - val_loss: 13.1424 - val_out_stats_loss: 5.2752 - val_out_counts_loss: 2.1651 - val_out_mean_covariance_loss: 64.8088 - val_out_fielding_position_loss: 2.4617
Epoch 24/1000

Epoch 00024: val_loss improved from 13.14242 to 13.13324, saving model to models/bc/shift2/max2016/simple-rnn/6.h5
 - 5s - loss: 12.7112 - out_stats_loss: 5.0726 - out_counts_loss: 2.0909 - out_mean_covariance_loss: 62.4269 - out_fielding_position_loss: 2.4263 - val_loss: 13.1332 - val_out_stats_loss: 5.2757 - val_out_counts_loss: 2.1657 - val_out_mean_covariance_loss: 64.7176 - val_out_fielding_position_loss: 2.4560
Epoch 25/1000

Epoch 00025: val_loss improved from 13.13324 to 13.11867, saving model to models/bc/shift2/max2016/simple-rnn/6.h5
 - 5s - loss: 12.7318 - out_stats_loss: 5.0913 - out_counts_loss: 2.0798 - out_mean_covariance_loss: 63.0763 - out_fielding_position_loss: 2.4069 - val_loss: 13.1187 - val_out_stats_loss: 5.2728 - val_out_counts_loss: 2.1658 - val_out_mean_covariance_loss: 64.6310 - val_out_fielding_position_loss: 2.4485
Epoch 26/1000

Epoch 00026: val_loss did not improve
 - 5s - loss: 12.6778 - out_stats_loss: 5.0820 - out_counts_loss: 2.0596 - out_mean_covariance_loss: 62.8582 - out_fielding_position_loss: 2.3932 - val_loss: 13.1801 - val_out_stats_loss: 5.2860 - val_out_counts_loss: 2.2052 - val_out_mean_covariance_loss: 64.8062 - val_out_fielding_position_loss: 2.4486
Epoch 27/1000

Epoch 00027: val_loss improved from 13.11867 to 13.08337, saving model to models/bc/shift2/max2016/simple-rnn/6.h5
 - 5s - loss: 12.5462 - out_stats_loss: 5.0277 - out_counts_loss: 2.0528 - out_mean_covariance_loss: 61.6953 - out_fielding_position_loss: 2.3809 - val_loss: 13.0834 - val_out_stats_loss: 5.2608 - val_out_counts_loss: 2.1648 - val_out_mean_covariance_loss: 64.3628 - val_out_fielding_position_loss: 2.4396
Epoch 28/1000

Epoch 00028: val_loss did not improve
 - 5s - loss: 12.5346 - out_stats_loss: 5.0359 - out_counts_loss: 2.0325 - out_mean_covariance_loss: 62.0238 - out_fielding_position_loss: 2.3650 - val_loss: 13.1098 - val_out_stats_loss: 5.2762 - val_out_counts_loss: 2.1796 - val_out_mean_covariance_loss: 64.3575 - val_out_fielding_position_loss: 2.4361
Epoch 29/1000

Epoch 00029: val_loss improved from 13.08337 to 13.06777, saving model to models/bc/shift2/max2016/simple-rnn/6.h5
 - 5s - loss: 12.5768 - out_stats_loss: 5.0572 - out_counts_loss: 2.0302 - out_mean_covariance_loss: 62.5107 - out_fielding_position_loss: 2.3639 - val_loss: 13.0678 - val_out_stats_loss: 5.2607 - val_out_counts_loss: 2.1646 - val_out_mean_covariance_loss: 64.2801 - val_out_fielding_position_loss: 2.4285
Epoch 30/1000

Epoch 00030: val_loss did not improve
 - 5s - loss: 12.4436 - out_stats_loss: 5.0059 - out_counts_loss: 2.0201 - out_mean_covariance_loss: 61.2658 - out_fielding_position_loss: 2.3543 - val_loss: 13.0811 - val_out_stats_loss: 5.2629 - val_out_counts_loss: 2.1732 - val_out_mean_covariance_loss: 64.3158 - val_out_fielding_position_loss: 2.4292
Epoch 31/1000

Epoch 00031: val_loss improved from 13.06777 to 13.05880, saving model to models/bc/shift2/max2016/simple-rnn/6.h5
 - 5s - loss: 12.4567 - out_stats_loss: 5.0238 - out_counts_loss: 2.0136 - out_mean_covariance_loss: 61.5962 - out_fielding_position_loss: 2.3395 - val_loss: 13.0588 - val_out_stats_loss: 5.2564 - val_out_counts_loss: 2.1712 - val_out_mean_covariance_loss: 64.1585 - val_out_fielding_position_loss: 2.4233
Epoch 32/1000

Epoch 00032: val_loss did not improve
 - 5s - loss: 12.3914 - out_stats_loss: 5.0107 - out_counts_loss: 1.9842 - out_mean_covariance_loss: 61.5715 - out_fielding_position_loss: 2.3179 - val_loss: 13.1168 - val_out_stats_loss: 5.2647 - val_out_counts_loss: 2.2128 - val_out_mean_covariance_loss: 64.2769 - val_out_fielding_position_loss: 2.4255
Epoch 33/1000

Epoch 00033: val_loss did not improve
 - 5s - loss: 12.3018 - out_stats_loss: 4.9667 - out_counts_loss: 1.9917 - out_mean_covariance_loss: 60.6641 - out_fielding_position_loss: 2.3102 - val_loss: 13.0759 - val_out_stats_loss: 5.2650 - val_out_counts_loss: 2.1811 - val_out_mean_covariance_loss: 64.2248 - val_out_fielding_position_loss: 2.4186
Epoch 34/1000

Epoch 00034: val_loss did not improve
 - 5s - loss: 12.2844 - out_stats_loss: 4.9710 - out_counts_loss: 1.9679 - out_mean_covariance_loss: 60.7981 - out_fielding_position_loss: 2.3056 - val_loss: 13.0808 - val_out_stats_loss: 5.2744 - val_out_counts_loss: 2.1880 - val_out_mean_covariance_loss: 64.1587 - val_out_fielding_position_loss: 2.4105
Epoch 35/1000

Epoch 00035: val_loss improved from 13.05880 to 13.03042, saving model to models/bc/shift2/max2016/simple-rnn/6.h5
 - 5s - loss: 12.2695 - out_stats_loss: 4.9800 - out_counts_loss: 1.9559 - out_mean_covariance_loss: 60.7941 - out_fielding_position_loss: 2.2939 - val_loss: 13.0304 - val_out_stats_loss: 5.2492 - val_out_counts_loss: 2.1768 - val_out_mean_covariance_loss: 63.9919 - val_out_fielding_position_loss: 2.4048
Epoch 36/1000

Epoch 00036: val_loss did not improve
 - 5s - loss: 12.2109 - out_stats_loss: 4.9571 - out_counts_loss: 1.9462 - out_mean_covariance_loss: 60.6404 - out_fielding_position_loss: 2.2755 - val_loss: 13.0659 - val_out_stats_loss: 5.2681 - val_out_counts_loss: 2.1906 - val_out_mean_covariance_loss: 63.9651 - val_out_fielding_position_loss: 2.4090
Epoch 37/1000

Epoch 00037: val_loss did not improve
 - 5s - loss: 12.2252 - out_stats_loss: 4.9680 - out_counts_loss: 1.9433 - out_mean_covariance_loss: 60.8908 - out_fielding_position_loss: 2.2694 - val_loss: 13.0992 - val_out_stats_loss: 5.2965 - val_out_counts_loss: 2.2067 - val_out_mean_covariance_loss: 63.9126 - val_out_fielding_position_loss: 2.4004
Epoch 38/1000

Epoch 00038: val_loss did not improve
 - 5s - loss: 12.1581 - out_stats_loss: 4.9500 - out_counts_loss: 1.9135 - out_mean_covariance_loss: 60.5445 - out_fielding_position_loss: 2.2674 - val_loss: 13.0473 - val_out_stats_loss: 5.2656 - val_out_counts_loss: 2.1943 - val_out_mean_covariance_loss: 63.8893 - val_out_fielding_position_loss: 2.3930
Epoch 39/1000

Epoch 00039: val_loss did not improve
 - 5s - loss: 12.0849 - out_stats_loss: 4.9279 - out_counts_loss: 1.9041 - out_mean_covariance_loss: 60.1770 - out_fielding_position_loss: 2.2441 - val_loss: 13.0625 - val_out_stats_loss: 5.2667 - val_out_counts_loss: 2.2115 - val_out_mean_covariance_loss: 63.8460 - val_out_fielding_position_loss: 2.3920
Epoch 40/1000

Epoch 00040: val_loss improved from 13.03042 to 13.02297, saving model to models/bc/shift2/max2016/simple-rnn/6.h5
 - 5s - loss: 12.0901 - out_stats_loss: 4.9327 - out_counts_loss: 1.9030 - out_mean_covariance_loss: 60.2958 - out_fielding_position_loss: 2.2397 - val_loss: 13.0230 - val_out_stats_loss: 5.2581 - val_out_counts_loss: 2.1906 - val_out_mean_covariance_loss: 63.7663 - val_out_fielding_position_loss: 2.3859
Epoch 41/1000

Epoch 00041: val_loss did not improve
 - 5s - loss: 12.0059 - out_stats_loss: 4.9094 - out_counts_loss: 1.8739 - out_mean_covariance_loss: 60.0894 - out_fielding_position_loss: 2.2181 - val_loss: 13.0539 - val_out_stats_loss: 5.2653 - val_out_counts_loss: 2.2081 - val_out_mean_covariance_loss: 63.9619 - val_out_fielding_position_loss: 2.3823
Epoch 42/1000

Epoch 00042: val_loss did not improve
 - 5s - loss: 11.9914 - out_stats_loss: 4.9044 - out_counts_loss: 1.8785 - out_mean_covariance_loss: 59.8578 - out_fielding_position_loss: 2.2156 - val_loss: 13.0886 - val_out_stats_loss: 5.2762 - val_out_counts_loss: 2.2353 - val_out_mean_covariance_loss: 63.8040 - val_out_fielding_position_loss: 2.3869
Epoch 43/1000

Epoch 00043: val_loss did not improve
 - 5s - loss: 11.9487 - out_stats_loss: 4.8905 - out_counts_loss: 1.8730 - out_mean_covariance_loss: 59.5666 - out_fielding_position_loss: 2.2068 - val_loss: 13.0892 - val_out_stats_loss: 5.2770 - val_out_counts_loss: 2.2488 - val_out_mean_covariance_loss: 63.7140 - val_out_fielding_position_loss: 2.3777
Epoch 44/1000

Epoch 00044: val_loss did not improve
 - 5s - loss: 11.9213 - out_stats_loss: 4.8869 - out_counts_loss: 1.8569 - out_mean_covariance_loss: 59.5536 - out_fielding_position_loss: 2.1999 - val_loss: 13.0434 - val_out_stats_loss: 5.2696 - val_out_counts_loss: 2.2224 - val_out_mean_covariance_loss: 63.6403 - val_out_fielding_position_loss: 2.3694
Epoch 45/1000

Epoch 00045: val_loss did not improve
 - 5s - loss: 11.9158 - out_stats_loss: 4.9064 - out_counts_loss: 1.8457 - out_mean_covariance_loss: 59.6992 - out_fielding_position_loss: 2.1788 - val_loss: 13.1177 - val_out_stats_loss: 5.2912 - val_out_counts_loss: 2.2513 - val_out_mean_covariance_loss: 63.7503 - val_out_fielding_position_loss: 2.3876
Epoch 46/1000

Epoch 00046: val_loss did not improve
 - 5s - loss: 11.8958 - out_stats_loss: 4.8963 - out_counts_loss: 1.8480 - out_mean_covariance_loss: 59.5446 - out_fielding_position_loss: 2.1743 - val_loss: 13.0478 - val_out_stats_loss: 5.2675 - val_out_counts_loss: 2.2312 - val_out_mean_covariance_loss: 63.6138 - val_out_fielding_position_loss: 2.3684
Epoch 47/1000

Epoch 00047: val_loss did not improve
 - 5s - loss: 11.8959 - out_stats_loss: 4.9053 - out_counts_loss: 1.8370 - out_mean_covariance_loss: 59.7322 - out_fielding_position_loss: 2.1670 - val_loss: 13.0732 - val_out_stats_loss: 5.2764 - val_out_counts_loss: 2.2540 - val_out_mean_covariance_loss: 63.5403 - val_out_fielding_position_loss: 2.3658
Epoch 48/1000

Epoch 00048: val_loss did not improve
 - 5s - loss: 11.8045 - out_stats_loss: 4.8719 - out_counts_loss: 1.8174 - out_mean_covariance_loss: 59.2804 - out_fielding_position_loss: 2.1512 - val_loss: 13.0483 - val_out_stats_loss: 5.2833 - val_out_counts_loss: 2.2307 - val_out_mean_covariance_loss: 63.6630 - val_out_fielding_position_loss: 2.3512
Epoch 49/1000

Epoch 00049: val_loss did not improve
 - 5s - loss: 11.7816 - out_stats_loss: 4.8530 - out_counts_loss: 1.8197 - out_mean_covariance_loss: 59.0653 - out_fielding_position_loss: 2.1557 - val_loss: 13.2211 - val_out_stats_loss: 5.3192 - val_out_counts_loss: 2.3447 - val_out_mean_covariance_loss: 63.8226 - val_out_fielding_position_loss: 2.3661
Epoch 50/1000

Epoch 00050: val_loss did not improve
 - 5s - loss: 11.7882 - out_stats_loss: 4.8787 - out_counts_loss: 1.8097 - out_mean_covariance_loss: 59.2655 - out_fielding_position_loss: 2.1365 - val_loss: 13.2152 - val_out_stats_loss: 5.3494 - val_out_counts_loss: 2.3147 - val_out_mean_covariance_loss: 63.7701 - val_out_fielding_position_loss: 2.3626
Epoch 51/1000

Epoch 00051: val_loss did not improve
 - 5s - loss: 11.7030 - out_stats_loss: 4.8526 - out_counts_loss: 1.7874 - out_mean_covariance_loss: 58.8556 - out_fielding_position_loss: 2.1202 - val_loss: 13.0378 - val_out_stats_loss: 5.2701 - val_out_counts_loss: 2.2545 - val_out_mean_covariance_loss: 63.4018 - val_out_fielding_position_loss: 2.3432
Epoch 52/1000

Epoch 00052: val_loss did not improve
 - 5s - loss: 11.6480 - out_stats_loss: 4.8312 - out_counts_loss: 1.7790 - out_mean_covariance_loss: 58.5152 - out_fielding_position_loss: 2.1121 - val_loss: 13.1883 - val_out_stats_loss: 5.3344 - val_out_counts_loss: 2.3208 - val_out_mean_covariance_loss: 63.6062 - val_out_fielding_position_loss: 2.3527
Epoch 53/1000

Epoch 00053: val_loss did not improve
 - 5s - loss: 11.6078 - out_stats_loss: 4.8089 - out_counts_loss: 1.7842 - out_mean_covariance_loss: 58.0830 - out_fielding_position_loss: 2.1106 - val_loss: 13.0454 - val_out_stats_loss: 5.2784 - val_out_counts_loss: 2.2556 - val_out_mean_covariance_loss: 63.3576 - val_out_fielding_position_loss: 2.3435
Epoch 54/1000

Epoch 00054: val_loss did not improve
 - 5s - loss: 11.6687 - out_stats_loss: 4.8578 - out_counts_loss: 1.7687 - out_mean_covariance_loss: 59.0186 - out_fielding_position_loss: 2.0913 - val_loss: 13.0562 - val_out_stats_loss: 5.2821 - val_out_counts_loss: 2.2648 - val_out_mean_covariance_loss: 63.5003 - val_out_fielding_position_loss: 2.3343
Epoch 55/1000

Epoch 00055: val_loss did not improve
 - 5s - loss: 11.6078 - out_stats_loss: 4.8229 - out_counts_loss: 1.7758 - out_mean_covariance_loss: 58.2219 - out_fielding_position_loss: 2.0979 - val_loss: 13.0547 - val_out_stats_loss: 5.2690 - val_out_counts_loss: 2.2743 - val_out_mean_covariance_loss: 63.4036 - val_out_fielding_position_loss: 2.3412
Epoch 56/1000

Epoch 00056: val_loss did not improve
 - 5s - loss: 11.6170 - out_stats_loss: 4.8396 - out_counts_loss: 1.7671 - out_mean_covariance_loss: 58.7814 - out_fielding_position_loss: 2.0711 - val_loss: 13.0675 - val_out_stats_loss: 5.2807 - val_out_counts_loss: 2.2865 - val_out_mean_covariance_loss: 63.4185 - val_out_fielding_position_loss: 2.3295
Epoch 57/1000

Epoch 00057: val_loss did not improve
 - 5s - loss: 11.5655 - out_stats_loss: 4.8096 - out_counts_loss: 1.7581 - out_mean_covariance_loss: 58.1756 - out_fielding_position_loss: 2.0890 - val_loss: 13.1665 - val_out_stats_loss: 5.3106 - val_out_counts_loss: 2.3394 - val_out_mean_covariance_loss: 63.5149 - val_out_fielding_position_loss: 2.3407
Epoch 58/1000

Epoch 00058: val_loss did not improve
 - 5s - loss: 11.5653 - out_stats_loss: 4.8200 - out_counts_loss: 1.7555 - out_mean_covariance_loss: 58.3383 - out_fielding_position_loss: 2.0729 - val_loss: 13.0743 - val_out_stats_loss: 5.2841 - val_out_counts_loss: 2.2921 - val_out_mean_covariance_loss: 63.3831 - val_out_fielding_position_loss: 2.3290
Epoch 59/1000

Epoch 00059: val_loss did not improve
 - 5s - loss: 11.4817 - out_stats_loss: 4.7984 - out_counts_loss: 1.7251 - out_mean_covariance_loss: 58.0612 - out_fielding_position_loss: 2.0552 - val_loss: 13.1061 - val_out_stats_loss: 5.2975 - val_out_counts_loss: 2.3153 - val_out_mean_covariance_loss: 63.3342 - val_out_fielding_position_loss: 2.3266
Epoch 60/1000

Epoch 00060: val_loss did not improve
 - 5s - loss: 11.4600 - out_stats_loss: 4.7998 - out_counts_loss: 1.7174 - out_mean_covariance_loss: 58.1073 - out_fielding_position_loss: 2.0375 - val_loss: 13.0862 - val_out_stats_loss: 5.3016 - val_out_counts_loss: 2.3053 - val_out_mean_covariance_loss: 63.2360 - val_out_fielding_position_loss: 2.3174
Epoch 61/1000

Epoch 00061: val_loss did not improve
 - 5s - loss: 11.3707 - out_stats_loss: 4.7601 - out_counts_loss: 1.7087 - out_mean_covariance_loss: 57.3307 - out_fielding_position_loss: 2.0353 - val_loss: 13.1091 - val_out_stats_loss: 5.2937 - val_out_counts_loss: 2.3199 - val_out_mean_covariance_loss: 63.3169 - val_out_fielding_position_loss: 2.3297
Epoch 62/1000

Epoch 00062: val_loss did not improve
 - 5s - loss: 11.3766 - out_stats_loss: 4.7696 - out_counts_loss: 1.7133 - out_mean_covariance_loss: 57.2481 - out_fielding_position_loss: 2.0313 - val_loss: 13.1647 - val_out_stats_loss: 5.3149 - val_out_counts_loss: 2.3484 - val_out_mean_covariance_loss: 63.4475 - val_out_fielding_position_loss: 2.3291
Epoch 63/1000

Epoch 00063: val_loss did not improve
 - 5s - loss: 11.3353 - out_stats_loss: 4.7551 - out_counts_loss: 1.6934 - out_mean_covariance_loss: 57.2507 - out_fielding_position_loss: 2.0243 - val_loss: 13.1150 - val_out_stats_loss: 5.2937 - val_out_counts_loss: 2.3310 - val_out_mean_covariance_loss: 63.4652 - val_out_fielding_position_loss: 2.3171
Epoch 64/1000

Epoch 00064: val_loss did not improve
 - 5s - loss: 11.3306 - out_stats_loss: 4.7684 - out_counts_loss: 1.6868 - out_mean_covariance_loss: 57.2618 - out_fielding_position_loss: 2.0123 - val_loss: 13.1211 - val_out_stats_loss: 5.2981 - val_out_counts_loss: 2.3392 - val_out_mean_covariance_loss: 63.4172 - val_out_fielding_position_loss: 2.3129
Epoch 65/1000

Epoch 00065: val_loss did not improve
 - 5s - loss: 11.3687 - out_stats_loss: 4.7758 - out_counts_loss: 1.6906 - out_mean_covariance_loss: 57.5709 - out_fielding_position_loss: 2.0237 - val_loss: 13.0485 - val_out_stats_loss: 5.2814 - val_out_counts_loss: 2.2992 - val_out_mean_covariance_loss: 63.1729 - val_out_fielding_position_loss: 2.3092
Epoch 66/1000

Epoch 00066: val_loss did not improve
 - 5s - loss: 11.2588 - out_stats_loss: 4.7507 - out_counts_loss: 1.6664 - out_mean_covariance_loss: 56.9818 - out_fielding_position_loss: 1.9926 - val_loss: 13.1036 - val_out_stats_loss: 5.2890 - val_out_counts_loss: 2.3357 - val_out_mean_covariance_loss: 63.2335 - val_out_fielding_position_loss: 2.3172
Epoch 67/1000

Epoch 00067: val_loss did not improve
 - 5s - loss: 11.2814 - out_stats_loss: 4.7541 - out_counts_loss: 1.6693 - out_mean_covariance_loss: 57.0306 - out_fielding_position_loss: 2.0065 - val_loss: 13.1256 - val_out_stats_loss: 5.2969 - val_out_counts_loss: 2.3528 - val_out_mean_covariance_loss: 63.2634 - val_out_fielding_position_loss: 2.3128
Epoch 68/1000

Epoch 00068: val_loss did not improve
 - 5s - loss: 11.2802 - out_stats_loss: 4.7573 - out_counts_loss: 1.6711 - out_mean_covariance_loss: 57.1178 - out_fielding_position_loss: 1.9959 - val_loss: 13.1213 - val_out_stats_loss: 5.2947 - val_out_counts_loss: 2.3413 - val_out_mean_covariance_loss: 63.3718 - val_out_fielding_position_loss: 2.3167
Epoch 69/1000

Epoch 00069: val_loss did not improve
 - 5s - loss: 11.2144 - out_stats_loss: 4.7409 - out_counts_loss: 1.6472 - out_mean_covariance_loss: 56.9240 - out_fielding_position_loss: 1.9801 - val_loss: 13.1410 - val_out_stats_loss: 5.3083 - val_out_counts_loss: 2.3610 - val_out_mean_covariance_loss: 63.2572 - val_out_fielding_position_loss: 2.3088
Epoch 70/1000

Epoch 00070: val_loss did not improve
 - 5s - loss: 11.2611 - out_stats_loss: 4.7740 - out_counts_loss: 1.6574 - out_mean_covariance_loss: 57.2484 - out_fielding_position_loss: 1.9673 - val_loss: 13.1679 - val_out_stats_loss: 5.3013 - val_out_counts_loss: 2.3787 - val_out_mean_covariance_loss: 63.2888 - val_out_fielding_position_loss: 2.3234
Epoch 71/1000

Epoch 00071: val_loss did not improve
 - 5s - loss: 11.2042 - out_stats_loss: 4.7483 - out_counts_loss: 1.6500 - out_mean_covariance_loss: 56.8945 - out_fielding_position_loss: 1.9611 - val_loss: 13.1941 - val_out_stats_loss: 5.3352 - val_out_counts_loss: 2.3776 - val_out_mean_covariance_loss: 63.5444 - val_out_fielding_position_loss: 2.3041
Epoch 72/1000

Epoch 00072: val_loss did not improve
 - 5s - loss: 11.1944 - out_stats_loss: 4.7464 - out_counts_loss: 1.6456 - out_mean_covariance_loss: 57.0686 - out_fielding_position_loss: 1.9489 - val_loss: 13.2427 - val_out_stats_loss: 5.3266 - val_out_counts_loss: 2.4345 - val_out_mean_covariance_loss: 63.4666 - val_out_fielding_position_loss: 2.3083
Epoch 73/1000

Epoch 00073: val_loss did not improve
 - 5s - loss: 11.1063 - out_stats_loss: 4.7088 - out_counts_loss: 1.6291 - out_mean_covariance_loss: 56.5354 - out_fielding_position_loss: 1.9416 - val_loss: 13.0974 - val_out_stats_loss: 5.2816 - val_out_counts_loss: 2.3553 - val_out_mean_covariance_loss: 63.1808 - val_out_fielding_position_loss: 2.3014
Epoch 74/1000

Epoch 00074: val_loss did not improve
 - 5s - loss: 11.1043 - out_stats_loss: 4.7137 - out_counts_loss: 1.6354 - out_mean_covariance_loss: 56.2974 - out_fielding_position_loss: 1.9404 - val_loss: 13.0947 - val_out_stats_loss: 5.2843 - val_out_counts_loss: 2.3594 - val_out_mean_covariance_loss: 63.2665 - val_out_fielding_position_loss: 2.2876
Epoch 75/1000

Epoch 00075: val_loss did not improve
 - 5s - loss: 11.0653 - out_stats_loss: 4.6964 - out_counts_loss: 1.6210 - out_mean_covariance_loss: 56.2590 - out_fielding_position_loss: 1.9350 - val_loss: 13.1390 - val_out_stats_loss: 5.2969 - val_out_counts_loss: 2.3764 - val_out_mean_covariance_loss: 63.2900 - val_out_fielding_position_loss: 2.3012
Epoch 76/1000

Epoch 00076: val_loss did not improve
 - 5s - loss: 11.0288 - out_stats_loss: 4.6787 - out_counts_loss: 1.6161 - out_mean_covariance_loss: 56.0841 - out_fielding_position_loss: 1.9298 - val_loss: 13.1528 - val_out_stats_loss: 5.3096 - val_out_counts_loss: 2.3827 - val_out_mean_covariance_loss: 63.2172 - val_out_fielding_position_loss: 2.2997
Epoch 77/1000

Epoch 00077: val_loss did not improve
 - 5s - loss: 11.0601 - out_stats_loss: 4.7121 - out_counts_loss: 1.6030 - out_mean_covariance_loss: 56.5273 - out_fielding_position_loss: 1.9186 - val_loss: 13.1159 - val_out_stats_loss: 5.2905 - val_out_counts_loss: 2.3717 - val_out_mean_covariance_loss: 63.2178 - val_out_fielding_position_loss: 2.2928
Epoch 78/1000

Epoch 00078: val_loss did not improve
 - 5s - loss: 10.9790 - out_stats_loss: 4.6717 - out_counts_loss: 1.6043 - out_mean_covariance_loss: 55.7554 - out_fielding_position_loss: 1.9153 - val_loss: 13.0927 - val_out_stats_loss: 5.2835 - val_out_counts_loss: 2.3672 - val_out_mean_covariance_loss: 63.1400 - val_out_fielding_position_loss: 2.2850
Epoch 79/1000

Epoch 00079: val_loss did not improve
 - 5s - loss: 10.9951 - out_stats_loss: 4.6892 - out_counts_loss: 1.6029 - out_mean_covariance_loss: 55.8937 - out_fielding_position_loss: 1.9083 - val_loss: 13.2317 - val_out_stats_loss: 5.3213 - val_out_counts_loss: 2.4344 - val_out_mean_covariance_loss: 63.4106 - val_out_fielding_position_loss: 2.3055
Epoch 80/1000

Epoch 00080: val_loss did not improve
 - 5s - loss: 11.0021 - out_stats_loss: 4.6924 - out_counts_loss: 1.5945 - out_mean_covariance_loss: 56.2223 - out_fielding_position_loss: 1.9040 - val_loss: 13.1697 - val_out_stats_loss: 5.3106 - val_out_counts_loss: 2.4043 - val_out_mean_covariance_loss: 63.2639 - val_out_fielding_position_loss: 2.2916
Epoch 81/1000

Epoch 00081: val_loss did not improve
 - 5s - loss: 10.9626 - out_stats_loss: 4.6775 - out_counts_loss: 1.5963 - out_mean_covariance_loss: 56.0106 - out_fielding_position_loss: 1.8883 - val_loss: 13.1499 - val_out_stats_loss: 5.2988 - val_out_counts_loss: 2.3963 - val_out_mean_covariance_loss: 63.2690 - val_out_fielding_position_loss: 2.2914
Epoch 82/1000

Epoch 00082: val_loss did not improve
 - 5s - loss: 10.8997 - out_stats_loss: 4.6473 - out_counts_loss: 1.5884 - out_mean_covariance_loss: 55.5323 - out_fielding_position_loss: 1.8874 - val_loss: 13.2639 - val_out_stats_loss: 5.3532 - val_out_counts_loss: 2.4441 - val_out_mean_covariance_loss: 63.3990 - val_out_fielding_position_loss: 2.2966
Epoch 83/1000

Epoch 00083: val_loss did not improve
 - 5s - loss: 10.8808 - out_stats_loss: 4.6592 - out_counts_loss: 1.5804 - out_mean_covariance_loss: 55.2708 - out_fielding_position_loss: 1.8776 - val_loss: 13.1899 - val_out_stats_loss: 5.3154 - val_out_counts_loss: 2.4241 - val_out_mean_covariance_loss: 63.2893 - val_out_fielding_position_loss: 2.2859
Epoch 84/1000

Epoch 00084: val_loss did not improve
 - 5s - loss: 10.8651 - out_stats_loss: 4.6472 - out_counts_loss: 1.5725 - out_mean_covariance_loss: 55.4401 - out_fielding_position_loss: 1.8733 - val_loss: 13.1823 - val_out_stats_loss: 5.3073 - val_out_counts_loss: 2.4200 - val_out_mean_covariance_loss: 63.2996 - val_out_fielding_position_loss: 2.2900
Epoch 85/1000

Epoch 00085: val_loss did not improve
 - 5s - loss: 10.9083 - out_stats_loss: 4.6679 - out_counts_loss: 1.5763 - out_mean_covariance_loss: 55.7692 - out_fielding_position_loss: 1.8756 - val_loss: 13.1870 - val_out_stats_loss: 5.3180 - val_out_counts_loss: 2.4140 - val_out_mean_covariance_loss: 63.3298 - val_out_fielding_position_loss: 2.2885
Epoch 86/1000

Epoch 00086: val_loss did not improve
 - 5s - loss: 10.8130 - out_stats_loss: 4.6280 - out_counts_loss: 1.5616 - out_mean_covariance_loss: 55.1477 - out_fielding_position_loss: 1.8661 - val_loss: 13.1544 - val_out_stats_loss: 5.2984 - val_out_counts_loss: 2.4050 - val_out_mean_covariance_loss: 63.3489 - val_out_fielding_position_loss: 2.2836
Epoch 87/1000

Epoch 00087: val_loss did not improve
 - 5s - loss: 10.8262 - out_stats_loss: 4.6400 - out_counts_loss: 1.5564 - out_mean_covariance_loss: 55.3612 - out_fielding_position_loss: 1.8617 - val_loss: 13.1767 - val_out_stats_loss: 5.3117 - val_out_counts_loss: 2.4153 - val_out_mean_covariance_loss: 63.4413 - val_out_fielding_position_loss: 2.2777
Epoch 88/1000

Epoch 00088: val_loss did not improve
 - 5s - loss: 10.8269 - out_stats_loss: 4.6433 - out_counts_loss: 1.5617 - out_mean_covariance_loss: 55.4431 - out_fielding_position_loss: 1.8498 - val_loss: 13.2268 - val_out_stats_loss: 5.3223 - val_out_counts_loss: 2.4464 - val_out_mean_covariance_loss: 63.4728 - val_out_fielding_position_loss: 2.2846
Epoch 89/1000

Epoch 00089: val_loss did not improve
 - 5s - loss: 10.7765 - out_stats_loss: 4.6287 - out_counts_loss: 1.5500 - out_mean_covariance_loss: 55.0366 - out_fielding_position_loss: 1.8460 - val_loss: 13.2729 - val_out_stats_loss: 5.3467 - val_out_counts_loss: 2.4488 - val_out_mean_covariance_loss: 63.5425 - val_out_fielding_position_loss: 2.3003
Epoch 90/1000

Epoch 00090: val_loss did not improve
 - 5s - loss: 10.7655 - out_stats_loss: 4.6240 - out_counts_loss: 1.5481 - out_mean_covariance_loss: 55.0888 - out_fielding_position_loss: 1.8389 - val_loss: 13.1777 - val_out_stats_loss: 5.3067 - val_out_counts_loss: 2.4172 - val_out_mean_covariance_loss: 63.3473 - val_out_fielding_position_loss: 2.2864
/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Years: [1958,2016]
Shift: 2
Fold: 4
Training into models/bc/shift2/max2016/simple-rnn/6.h5
/usr/local/lib/python3.5/dist-packages/keras/legacy/layers.py:533: UserWarning: The `MaxoutDense` layer is deprecated and will be removed after 06/2017.
  warnings.warn('The `MaxoutDense` layer is deprecated '
