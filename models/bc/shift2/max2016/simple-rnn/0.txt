__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
in_age (InputLayer)             (None, None, 2)      0                                            
__________________________________________________________________________________________________
in_bio (InputLayer)             (None, None, 7)      0                                            
__________________________________________________________________________________________________
in_fielding_position (InputLaye (None, None, 2)      0                                            
__________________________________________________________________________________________________
in_out_fielding_position (Input (None, None, 12)     0                                            
__________________________________________________________________________________________________
in_out_league_offense (InputLay (None, None, 9)      0                                            
__________________________________________________________________________________________________
in_out_park_factors (InputLayer (None, None, 8)      0                                            
__________________________________________________________________________________________________
in_out_plate_discipline (InputL (None, None, 8)      0                                            
__________________________________________________________________________________________________
in_out_running (InputLayer)     (None, None, 18)     0                                            
__________________________________________________________________________________________________
in_out_saber (InputLayer)       (None, None, 14)     0                                            
__________________________________________________________________________________________________
in_out_stats_extended (InputLay (None, None, 36)     0                                            
__________________________________________________________________________________________________
in_park_factors (InputLayer)    (None, None, 8)      0                                            
__________________________________________________________________________________________________
masked_in_age (Masking)         (None, None, 2)      0           in_age[0][0]                     
__________________________________________________________________________________________________
masked_in_bio (Masking)         (None, None, 7)      0           in_bio[0][0]                     
__________________________________________________________________________________________________
masked_in_fielding_position (Ma (None, None, 2)      0           in_fielding_position[0][0]       
__________________________________________________________________________________________________
masked_in_out_fielding_position (None, None, 12)     0           in_out_fielding_position[0][0]   
__________________________________________________________________________________________________
masked_in_out_league_offense (M (None, None, 9)      0           in_out_league_offense[0][0]      
__________________________________________________________________________________________________
masked_in_out_park_factors (Mas (None, None, 8)      0           in_out_park_factors[0][0]        
__________________________________________________________________________________________________
masked_in_out_plate_discipline  (None, None, 8)      0           in_out_plate_discipline[0][0]    
__________________________________________________________________________________________________
masked_in_out_running (Masking) (None, None, 18)     0           in_out_running[0][0]             
__________________________________________________________________________________________________
masked_in_out_saber (Masking)   (None, None, 14)     0           in_out_saber[0][0]               
__________________________________________________________________________________________________
masked_in_out_stats_extended (M (None, None, 36)     0           in_out_stats_extended[0][0]      
__________________________________________________________________________________________________
masked_in_park_factors (Masking (None, None, 8)      0           in_park_factors[0][0]            
__________________________________________________________________________________________________
time_distributed_10 (TimeDistri (None, None, 1)      0           masked_in_age[0][0]              
__________________________________________________________________________________________________
time_distributed_4 (TimeDistrib (None, None, 6)      0           masked_in_bio[0][0]              
__________________________________________________________________________________________________
time_distributed_9 (TimeDistrib (None, None, 1)      0           masked_in_fielding_position[0][0]
__________________________________________________________________________________________________
time_distributed_7 (TimeDistrib (None, None, 11)     0           masked_in_out_fielding_position[0
__________________________________________________________________________________________________
time_distributed_1 (TimeDistrib (None, None, 8)      0           masked_in_out_league_offense[0][0
__________________________________________________________________________________________________
time_distributed_3 (TimeDistrib (None, None, 7)      0           masked_in_out_park_factors[0][0] 
__________________________________________________________________________________________________
time_distributed_2 (TimeDistrib (None, None, 7)      0           masked_in_out_plate_discipline[0]
__________________________________________________________________________________________________
time_distributed_6 (TimeDistrib (None, None, 17)     0           masked_in_out_running[0][0]      
__________________________________________________________________________________________________
time_distributed_8 (TimeDistrib (None, None, 13)     0           masked_in_out_saber[0][0]        
__________________________________________________________________________________________________
time_distributed_11 (TimeDistri (None, None, 35)     0           masked_in_out_stats_extended[0][0
__________________________________________________________________________________________________
time_distributed_5 (TimeDistrib (None, None, 7)      0           masked_in_park_factors[0][0]     
__________________________________________________________________________________________________
norm_in_age (BatchNormalization (None, None, 1)      4           time_distributed_10[0][0]        
__________________________________________________________________________________________________
norm_in_bio (BatchNormalization (None, None, 6)      24          time_distributed_4[0][0]         
__________________________________________________________________________________________________
norm_in_fielding_position (Batc (None, None, 1)      4           time_distributed_9[0][0]         
__________________________________________________________________________________________________
norm_in_out_fielding_position ( (None, None, 11)     44          time_distributed_7[0][0]         
__________________________________________________________________________________________________
norm_in_out_league_offense (Bat (None, None, 8)      32          time_distributed_1[0][0]         
__________________________________________________________________________________________________
norm_in_out_park_factors (Batch (None, None, 7)      28          time_distributed_3[0][0]         
__________________________________________________________________________________________________
norm_in_out_plate_discipline (B (None, None, 7)      28          time_distributed_2[0][0]         
__________________________________________________________________________________________________2018-02-06 06:26:54.830201: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-02-06 06:27:01.484616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: eca0:00:00.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2018-02-06 06:27:01.484662: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: eca0:00:00.0, compute capability: 3.7)

norm_in_out_running (BatchNorma (None, None, 17)     68          time_distributed_6[0][0]         
__________________________________________________________________________________________________
norm_in_out_saber (BatchNormali (None, None, 13)     52          time_distributed_8[0][0]         
__________________________________________________________________________________________________
norm_in_out_stats_extended (Bat (None, None, 35)     140         time_distributed_11[0][0]        
__________________________________________________________________________________________________
norm_in_park_factors (BatchNorm (None, None, 7)      28          time_distributed_5[0][0]         
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, None, 113)    0           norm_in_age[0][0]                
                                                                 norm_in_bio[0][0]                
                                                                 norm_in_fielding_position[0][0]  
                                                                 norm_in_out_fielding_position[0][
                                                                 norm_in_out_league_offense[0][0] 
                                                                 norm_in_out_park_factors[0][0]   
                                                                 norm_in_out_plate_discipline[0][0
                                                                 norm_in_out_running[0][0]        
                                                                 norm_in_out_saber[0][0]          
                                                                 norm_in_out_stats_extended[0][0] 
                                                                 norm_in_park_factors[0][0]       
__________________________________________________________________________________________________
gru_1 (GRU)                     (None, None, 113)    76953       concatenate_1[0][0]              
__________________________________________________________________________________________________
gru_2 (GRU)                     (None, None, 113)    76953       gru_1[0][0]                      
__________________________________________________________________________________________________
mv_out_stats (TimeDistributed)  (None, None, 5)      4560        gru_2[0][0]                      
__________________________________________________________________________________________________
mv_out_counts (TimeDistributed) (None, None, 3)      2736        gru_2[0][0]                      
__________________________________________________________________________________________________
mv_out_mean_covariance (TimeDis (None, None, 72)     65664       gru_2[0][0]                      
__________________________________________________________________________________________________
mv_out_fielding_position (TimeD (None, None, 11)     10032       gru_2[0][0]                      
__________________________________________________________________________________________________
out_stats (Activation)          (None, None, 5)      0           mv_out_stats[0][0]               
__________________________________________________________________________________________________
out_counts (Activation)         (None, None, 3)      0           mv_out_counts[0][0]              
__________________________________________________________________________________________________
out_mean_covariance (Activation (None, None, 72)     0           mv_out_mean_covariance[0][0]     
__________________________________________________________________________________________________
out_fielding_position (Activati (None, None, 11)     0           mv_out_fielding_position[0][0]   
==================================================================================================
Total params: 237,350
Trainable params: 237,124
Non-trainable params: 226
__________________________________________________________________________________________________
Train on 5879 samples, validate on 1409 samples
Epoch 1/1000

Epoch 00001: val_loss improved from inf to 19.22817, saving model to models/bc/shift2/max2016/simple-rnn/0.h5
 - 15s - loss: 20.7772 - out_stats_loss: 7.1006 - out_counts_loss: 3.8266 - out_mean_covariance_loss: 105.6782 - out_fielding_position_loss: 4.5661 - val_loss: 19.2282 - val_out_stats_loss: 6.6519 - val_out_counts_loss: 3.2354 - val_out_mean_covariance_loss: 100.1362 - val_out_fielding_position_loss: 4.3341
Epoch 2/1000

Epoch 00002: val_loss improved from 19.22817 to 16.67149, saving model to models/bc/shift2/max2016/simple-rnn/0.h5
 - 5s - loss: 17.8878 - out_stats_loss: 6.1235 - out_counts_loss: 2.9360 - out_mean_covariance_loss: 93.6958 - out_fielding_position_loss: 4.1434 - val_loss: 16.6715 - val_out_stats_loss: 5.6607 - val_out_counts_loss: 2.6753 - val_out_mean_covariance_loss: 87.7903 - val_out_fielding_position_loss: 3.9459
Epoch 3/1000

Epoch 00003: val_loss improved from 16.67149 to 15.10182, saving model to models/bc/shift2/max2016/simple-rnn/0.h5
 - 5s - loss: 15.8042 - out_stats_loss: 5.3041 - out_counts_loss: 2.5959 - out_mean_covariance_loss: 81.8144 - out_fielding_position_loss: 3.8136 - val_loss: 15.1018 - val_out_stats_loss: 5.1201 - val_out_counts_loss: 2.4220 - val_out_mean_covariance_loss: 78.5914 - val_out_fielding_position_loss: 3.6302
Epoch 4/1000

Epoch 00004: val_loss improved from 15.10182 to 14.32662, saving model to models/bc/shift2/max2016/simple-rnn/0.h5
 - 5s - loss: 14.7641 - out_stats_loss: 4.9731 - out_counts_loss: 2.4769 - out_mean_covariance_loss: 75.2655 - out_fielding_position_loss: 3.5508 - val_loss: 14.3266 - val_out_stats_loss: 4.9155 - val_out_counts_loss: 2.3301 - val_out_mean_covariance_loss: 74.0334 - val_out_fielding_position_loss: 3.3794
Epoch 5/1000

Epoch 00005: val_loss improved from 14.32662 to 13.83880, saving model to models/bc/shift2/max2016/simple-rnn/0.h5
 - 5s - loss: 14.1215 - out_stats_loss: 4.8244 - out_counts_loss: 2.4015 - out_mean_covariance_loss: 71.7093 - out_fielding_position_loss: 3.3101 - val_loss: 13.8388 - val_out_stats_loss: 4.8062 - val_out_counts_loss: 2.2856 - val_out_mean_covariance_loss: 71.5773 - val_out_fielding_position_loss: 3.1681
Epoch 6/1000

Epoch 00006: val_loss improved from 13.83880 to 13.52447, saving model to models/bc/shift2/max2016/simple-rnn/0.h5
 - 5s - loss: 13.7686 - out_stats_loss: 4.7398 - out_counts_loss: 2.3976 - out_mean_covariance_loss: 69.9577 - out_fielding_position_loss: 3.1333 - val_loss: 13.5245 - val_out_stats_loss: 4.7525 - val_out_counts_loss: 2.2718 - val_out_mean_covariance_loss: 69.9295 - val_out_fielding_position_loss: 3.0037
Epoch 7/1000

Epoch 00007: val_loss improved from 13.52447 to 13.25226, saving model to models/bc/shift2/max2016/simple-rnn/0.h5
 - 5s - loss: 13.4288 - out_stats_loss: 4.6775 - out_counts_loss: 2.3295 - out_mean_covariance_loss: 68.7612 - out_fielding_position_loss: 2.9837 - val_loss: 13.2523 - val_out_stats_loss: 4.6944 - val_out_counts_loss: 2.2427 - val_out_mean_covariance_loss: 68.9823 - val_out_fielding_position_loss: 2.8661
Epoch 8/1000

Epoch 00008: val_loss improved from 13.25226 to 13.06937, saving model to models/bc/shift2/max2016/simple-rnn/0.h5
 - 5s - loss: 13.2111 - out_stats_loss: 4.6435 - out_counts_loss: 2.3102 - out_mean_covariance_loss: 67.9275 - out_fielding_position_loss: 2.8609 - val_loss: 13.0694 - val_out_stats_loss: 4.6571 - val_out_counts_loss: 2.2206 - val_out_mean_covariance_loss: 68.3382 - val_out_fielding_position_loss: 2.7748
Epoch 9/1000

Epoch 00009: val_loss improved from 13.06937 to 12.94237, saving model to models/bc/shift2/max2016/simple-rnn/0.h5
 - 5s - loss: 13.0129 - out_stats_loss: 4.5933 - out_counts_loss: 2.2905 - out_mean_covariance_loss: 66.8562 - out_fielding_position_loss: 2.7863 - val_loss: 12.9424 - val_out_stats_loss: 4.6305 - val_out_counts_loss: 2.2210 - val_out_mean_covariance_loss: 67.7716 - val_out_fielding_position_loss: 2.7024
Epoch 10/1000

Epoch 00010: val_loss improved from 12.94237 to 12.83778, saving model to models/bc/shift2/max2016/simple-rnn/0.h5
 - 5s - loss: 12.8505 - out_stats_loss: 4.5544 - out_counts_loss: 2.2598 - out_mean_covariance_loss: 66.5080 - out_fielding_position_loss: 2.7109 - val_loss: 12.8378 - val_out_stats_loss: 4.6089 - val_out_counts_loss: 2.2141 - val_out_mean_covariance_loss: 67.3418 - val_out_fielding_position_loss: 2.6477
Epoch 11/1000

Epoch 00011: val_loss improved from 12.83778 to 12.75691, saving model to models/bc/shift2/max2016/simple-rnn/0.h5
 - 5s - loss: 12.7342 - out_stats_loss: 4.5154 - out_counts_loss: 2.2646 - out_mean_covariance_loss: 65.6493 - out_fielding_position_loss: 2.6718 - val_loss: 12.7569 - val_out_stats_loss: 4.5912 - val_out_counts_loss: 2.2011 - val_out_mean_covariance_loss: 67.0667 - val_out_fielding_position_loss: 2.6113
Epoch 12/1000

Epoch 00012: val_loss improved from 12.75691 to 12.68759, saving model to models/bc/shift2/max2016/simple-rnn/0.h5
 - 5s - loss: 12.6952 - out_stats_loss: 4.5351 - out_counts_loss: 2.2397 - out_mean_covariance_loss: 65.9676 - out_fielding_position_loss: 2.6219 - val_loss: 12.6876 - val_out_stats_loss: 4.5732 - val_out_counts_loss: 2.1978 - val_out_mean_covariance_loss: 66.7407 - val_out_fielding_position_loss: 2.5796
Epoch 13/1000

Epoch 00013: val_loss did not improve
 - 5s - loss: 12.5584 - out_stats_loss: 4.4740 - out_counts_loss: 2.2422 - out_mean_covariance_loss: 65.0568 - out_fielding_position_loss: 2.5894 - val_loss: 12.7029 - val_out_stats_loss: 4.5516 - val_out_counts_loss: 2.2536 - val_out_mean_covariance_loss: 66.7583 - val_out_fielding_position_loss: 2.5597
Epoch 14/1000

Epoch 00014: val_loss improved from 12.68759 to 12.55468, saving model to models/bc/shift2/max2016/simple-rnn/0.h5
 - 5s - loss: 12.5249 - out_stats_loss: 4.4813 - out_counts_loss: 2.2076 - out_mean_covariance_loss: 65.4799 - out_fielding_position_loss: 2.5620 - val_loss: 12.5547 - val_out_stats_loss: 4.5214 - val_out_counts_loss: 2.1838 - val_out_mean_covariance_loss: 66.1888 - val_out_fielding_position_loss: 2.5400
Epoch 15/1000

Epoch 00015: val_loss did not improve
 - 5s - loss: 12.3556 - out_stats_loss: 4.4223 - out_counts_loss: 2.1892 - out_mean_covariance_loss: 64.1395 - out_fielding_position_loss: 2.5371 - val_loss: 12.5650 - val_out_stats_loss: 4.5280 - val_out_counts_loss: 2.2031 - val_out_mean_covariance_loss: 66.1831 - val_out_fielding_position_loss: 2.5248
Epoch 16/1000

Epoch 00016: val_loss improved from 12.55468 to 12.50097, saving model to models/bc/shift2/max2016/simple-rnn/0.h5
 - 5s - loss: 12.4262 - out_stats_loss: 4.4532 - out_counts_loss: 2.2114 - out_mean_covariance_loss: 64.8227 - out_fielding_position_loss: 2.5204 - val_loss: 12.5010 - val_out_stats_loss: 4.4981 - val_out_counts_loss: 2.1993 - val_out_mean_covariance_loss: 65.7681 - val_out_fielding_position_loss: 2.5151
Epoch 17/1000

Epoch 00017: val_loss improved from 12.50097 to 12.45046, saving model to models/bc/shift2/max2016/simple-rnn/0.h5
 - 5s - loss: 12.2679 - out_stats_loss: 4.3973 - out_counts_loss: 2.1667 - out_mean_covariance_loss: 64.0058 - out_fielding_position_loss: 2.5036 - val_loss: 12.4505 - val_out_stats_loss: 4.4837 - val_out_counts_loss: 2.1871 - val_out_mean_covariance_loss: 65.5578 - val_out_fielding_position_loss: 2.5018
Epoch 18/1000

Epoch 00018: val_loss improved from 12.45046 to 12.41501, saving model to models/bc/shift2/max2016/simple-rnn/0.h5
 - 5s - loss: 12.1884 - out_stats_loss: 4.3823 - out_counts_loss: 2.1510 - out_mean_covariance_loss: 63.6768 - out_fielding_position_loss: 2.4713 - val_loss: 12.4150 - val_out_stats_loss: 4.4730 - val_out_counts_loss: 2.1856 - val_out_mean_covariance_loss: 65.3306 - val_out_fielding_position_loss: 2.4899
Epoch 19/1000

Epoch 00019: val_loss improved from 12.41501 to 12.40603, saving model to models/bc/shift2/max2016/simple-rnn/0.h5
 - 5s - loss: 12.1514 - out_stats_loss: 4.3776 - out_counts_loss: 2.1302 - out_mean_covariance_loss: 63.7075 - out_fielding_position_loss: 2.4583 - val_loss: 12.4060 - val_out_stats_loss: 4.4627 - val_out_counts_loss: 2.1914 - val_out_mean_covariance_loss: 65.4321 - val_out_fielding_position_loss: 2.4804
Epoch 20/1000

Epoch 00020: val_loss improved from 12.40603 to 12.37855, saving model to models/bc/shift2/max2016/simple-rnn/0.h5
 - 5s - loss: 12.1073 - out_stats_loss: 4.3545 - out_counts_loss: 2.1296 - out_mean_covariance_loss: 63.5416 - out_fielding_position_loss: 2.4461 - val_loss: 12.3786 - val_out_stats_loss: 4.4656 - val_out_counts_loss: 2.1800 - val_out_mean_covariance_loss: 65.1754 - val_out_fielding_position_loss: 2.4742
Epoch 21/1000

Epoch 00021: val_loss improved from 12.37855 to 12.35271, saving model to models/bc/shift2/max2016/simple-rnn/0.h5
 - 5s - loss: 12.0398 - out_stats_loss: 4.3499 - out_counts_loss: 2.1091 - out_mean_covariance_loss: 63.0033 - out_fielding_position_loss: 2.4307 - val_loss: 12.3527 - val_out_stats_loss: 4.4592 - val_out_counts_loss: 2.1801 - val_out_mean_covariance_loss: 64.9402 - val_out_fielding_position_loss: 2.4663
Epoch 22/1000

Epoch 00022: val_loss improved from 12.35271 to 12.31789, saving model to models/bc/shift2/max2016/simple-rnn/0.h5
 - 5s - loss: 11.9960 - out_stats_loss: 4.3392 - out_counts_loss: 2.0987 - out_mean_covariance_loss: 62.8115 - out_fielding_position_loss: 2.4176 - val_loss: 12.3179 - val_out_stats_loss: 4.4434 - val_out_counts_loss: 2.1762 - val_out_mean_covariance_loss: 64.8587 - val_out_fielding_position_loss: 2.4554
Epoch 23/1000

Epoch 00023: val_loss improved from 12.31789 to 12.30776, saving model to models/bc/shift2/max2016/simple-rnn/0.h5
 - 5s - loss: 11.9562 - out_stats_loss: 4.3330 - out_counts_loss: 2.0851 - out_mean_covariance_loss: 62.7376 - out_fielding_position_loss: 2.4012 - val_loss: 12.3078 - val_out_stats_loss: 4.4425 - val_out_counts_loss: 2.1819 - val_out_mean_covariance_loss: 64.7291 - val_out_fielding_position_loss: 2.4469
Epoch 24/1000

Epoch 00024: val_loss did not improve
 - 5s - loss: 11.8765 - out_stats_loss: 4.3095 - out_counts_loss: 2.0759 - out_mean_covariance_loss: 62.2080 - out_fielding_position_loss: 2.3806 - val_loss: 12.3142 - val_out_stats_loss: 4.4475 - val_out_counts_loss: 2.1850 - val_out_mean_covariance_loss: 64.7084 - val_out_fielding_position_loss: 2.4462
Epoch 25/1000

Epoch 00025: val_loss improved from 12.30776 to 12.27380, saving model to models/bc/shift2/max2016/simple-rnn/0.h5
 - 5s - loss: 11.8484 - out_stats_loss: 4.3102 - out_counts_loss: 2.0564 - out_mean_covariance_loss: 62.3893 - out_fielding_position_loss: 2.3623 - val_loss: 12.2738 - val_out_stats_loss: 4.4329 - val_out_counts_loss: 2.1813 - val_out_mean_covariance_loss: 64.4843 - val_out_fielding_position_loss: 2.4353
Epoch 26/1000

Epoch 00026: val_loss did not improve
 - 5s - loss: 11.7680 - out_stats_loss: 4.2839 - out_counts_loss: 2.0257 - out_mean_covariance_loss: 61.9618 - out_fielding_position_loss: 2.3604 - val_loss: 12.2767 - val_out_stats_loss: 4.4440 - val_out_counts_loss: 2.1821 - val_out_mean_covariance_loss: 64.4523 - val_out_fielding_position_loss: 2.4280
Epoch 27/1000

Epoch 00027: val_loss did not improve
 - 5s - loss: 11.6929 - out_stats_loss: 4.2634 - out_counts_loss: 2.0299 - out_mean_covariance_loss: 61.4857 - out_fielding_position_loss: 2.3253 - val_loss: 12.3013 - val_out_stats_loss: 4.4460 - val_out_counts_loss: 2.2106 - val_out_mean_covariance_loss: 64.4336 - val_out_fielding_position_loss: 2.4231
Epoch 28/1000

Epoch 00028: val_loss did not improve
 - 5s - loss: 11.7276 - out_stats_loss: 4.2817 - out_counts_loss: 2.0223 - out_mean_covariance_loss: 61.8738 - out_fielding_position_loss: 2.3299 - val_loss: 12.3331 - val_out_stats_loss: 4.4552 - val_out_counts_loss: 2.2313 - val_out_mean_covariance_loss: 64.6405 - val_out_fielding_position_loss: 2.4145
Epoch 29/1000

Epoch 00029: val_loss improved from 12.27380 to 12.23410, saving model to models/bc/shift2/max2016/simple-rnn/0.h5
 - 5s - loss: 11.6695 - out_stats_loss: 4.2677 - out_counts_loss: 2.0074 - out_mean_covariance_loss: 61.6471 - out_fielding_position_loss: 2.3120 - val_loss: 12.2341 - val_out_stats_loss: 4.4295 - val_out_counts_loss: 2.1848 - val_out_mean_covariance_loss: 64.2586 - val_out_fielding_position_loss: 2.4068
Epoch 30/1000

Epoch 00030: val_loss improved from 12.23410 to 12.22388, saving model to models/bc/shift2/max2016/simple-rnn/0.h5
 - 5s - loss: 11.5858 - out_stats_loss: 4.2423 - out_counts_loss: 1.9796 - out_mean_covariance_loss: 61.1536 - out_fielding_position_loss: 2.3062 - val_loss: 12.2239 - val_out_stats_loss: 4.4240 - val_out_counts_loss: 2.1925 - val_out_mean_covariance_loss: 64.1840 - val_out_fielding_position_loss: 2.3982
Epoch 31/1000

Epoch 00031: val_loss did not improve
 - 5s - loss: 11.5660 - out_stats_loss: 4.2526 - out_counts_loss: 1.9763 - out_mean_covariance_loss: 61.1544 - out_fielding_position_loss: 2.2793 - val_loss: 12.2308 - val_out_stats_loss: 4.4312 - val_out_counts_loss: 2.1940 - val_out_mean_covariance_loss: 64.1259 - val_out_fielding_position_loss: 2.3993
Epoch 32/1000

Epoch 00032: val_loss did not improve
 - 5s - loss: 11.5431 - out_stats_loss: 4.2551 - out_counts_loss: 1.9591 - out_mean_covariance_loss: 61.1851 - out_fielding_position_loss: 2.2696 - val_loss: 12.2879 - val_out_stats_loss: 4.4337 - val_out_counts_loss: 2.2477 - val_out_mean_covariance_loss: 64.2928 - val_out_fielding_position_loss: 2.3918
Epoch 33/1000

Epoch 00033: val_loss improved from 12.22388 to 12.19146, saving model to models/bc/shift2/max2016/simple-rnn/0.h5
 - 5s - loss: 11.4759 - out_stats_loss: 4.2302 - out_counts_loss: 1.9591 - out_mean_covariance_loss: 60.6373 - out_fielding_position_loss: 2.2547 - val_loss: 12.1915 - val_out_stats_loss: 4.4233 - val_out_counts_loss: 2.1945 - val_out_mean_covariance_loss: 63.9577 - val_out_fielding_position_loss: 2.3757
Epoch 34/1000

Epoch 00034: val_loss did not improve
 - 5s - loss: 11.4339 - out_stats_loss: 4.2223 - out_counts_loss: 1.9292 - out_mean_covariance_loss: 60.9290 - out_fielding_position_loss: 2.2360 - val_loss: 12.2016 - val_out_stats_loss: 4.4253 - val_out_counts_loss: 2.2059 - val_out_mean_covariance_loss: 63.9508 - val_out_fielding_position_loss: 2.3728
Epoch 35/1000

Epoch 00035: val_loss did not improve
 - 5s - loss: 11.4257 - out_stats_loss: 4.2284 - out_counts_loss: 1.9302 - out_mean_covariance_loss: 60.9036 - out_fielding_position_loss: 2.2219 - val_loss: 12.2172 - val_out_stats_loss: 4.4270 - val_out_counts_loss: 2.2240 - val_out_mean_covariance_loss: 63.9373 - val_out_fielding_position_loss: 2.3693
Epoch 36/1000

Epoch 00036: val_loss did not improve
 - 5s - loss: 11.3434 - out_stats_loss: 4.2040 - out_counts_loss: 1.9123 - out_mean_covariance_loss: 60.3109 - out_fielding_position_loss: 2.2116 - val_loss: 12.3357 - val_out_stats_loss: 4.4647 - val_out_counts_loss: 2.2894 - val_out_mean_covariance_loss: 64.2434 - val_out_fielding_position_loss: 2.3694
Epoch 37/1000

Epoch 00037: val_loss did not improve
 - 5s - loss: 11.3250 - out_stats_loss: 4.2056 - out_counts_loss: 1.9020 - out_mean_covariance_loss: 60.5687 - out_fielding_position_loss: 2.1889 - val_loss: 12.2864 - val_out_stats_loss: 4.4574 - val_out_counts_loss: 2.2583 - val_out_mean_covariance_loss: 64.2085 - val_out_fielding_position_loss: 2.3602
Epoch 38/1000

Epoch 00038: val_loss improved from 12.19146 to 12.18152, saving model to models/bc/shift2/max2016/simple-rnn/0.h5
 - 5s - loss: 11.2393 - out_stats_loss: 4.1742 - out_counts_loss: 1.8878 - out_mean_covariance_loss: 59.7119 - out_fielding_position_loss: 2.1917 - val_loss: 12.1815 - val_out_stats_loss: 4.4225 - val_out_counts_loss: 2.2258 - val_out_mean_covariance_loss: 63.7507 - val_out_fielding_position_loss: 2.3456
Epoch 39/1000

Epoch 00039: val_loss did not improve
 - 5s - loss: 11.2158 - out_stats_loss: 4.1701 - out_counts_loss: 1.8840 - out_mean_covariance_loss: 59.6987 - out_fielding_position_loss: 2.1767 - val_loss: 12.2110 - val_out_stats_loss: 4.4393 - val_out_counts_loss: 2.2444 - val_out_mean_covariance_loss: 63.6985 - val_out_fielding_position_loss: 2.3424
Epoch 40/1000

Epoch 00040: val_loss did not improve
 - 5s - loss: 11.1744 - out_stats_loss: 4.1840 - out_counts_loss: 1.8500 - out_mean_covariance_loss: 59.7713 - out_fielding_position_loss: 2.1519 - val_loss: 12.1949 - val_out_stats_loss: 4.4352 - val_out_counts_loss: 2.2389 - val_out_mean_covariance_loss: 63.6561 - val_out_fielding_position_loss: 2.3380
Epoch 41/1000

Epoch 00041: val_loss did not improve
 - 5s - loss: 11.1066 - out_stats_loss: 4.1501 - out_counts_loss: 1.8554 - out_mean_covariance_loss: 59.0732 - out_fielding_position_loss: 2.1475 - val_loss: 12.2209 - val_out_stats_loss: 4.4318 - val_out_counts_loss: 2.2708 - val_out_mean_covariance_loss: 63.7149 - val_out_fielding_position_loss: 2.3325
Epoch 42/1000

Epoch 00042: val_loss did not improve
 - 5s - loss: 11.1673 - out_stats_loss: 4.1926 - out_counts_loss: 1.8359 - out_mean_covariance_loss: 60.0397 - out_fielding_position_loss: 2.1367 - val_loss: 12.2415 - val_out_stats_loss: 4.4386 - val_out_counts_loss: 2.2707 - val_out_mean_covariance_loss: 63.9059 - val_out_fielding_position_loss: 2.3368
Epoch 43/1000

Epoch 00043: val_loss improved from 12.18152 to 12.14768, saving model to models/bc/shift2/max2016/simple-rnn/0.h5
 - 5s - loss: 11.0563 - out_stats_loss: 4.1398 - out_counts_loss: 1.8334 - out_mean_covariance_loss: 59.1497 - out_fielding_position_loss: 2.1256 - val_loss: 12.1477 - val_out_stats_loss: 4.4164 - val_out_counts_loss: 2.2420 - val_out_mean_covariance_loss: 63.4814 - val_out_fielding_position_loss: 2.3152
Epoch 44/1000

Epoch 00044: val_loss did not improve
 - 5s - loss: 11.0912 - out_stats_loss: 4.1667 - out_counts_loss: 1.8285 - out_mean_covariance_loss: 59.5510 - out_fielding_position_loss: 2.1185 - val_loss: 12.2104 - val_out_stats_loss: 4.4303 - val_out_counts_loss: 2.2828 - val_out_mean_covariance_loss: 63.5866 - val_out_fielding_position_loss: 2.3180
Epoch 45/1000

Epoch 00045: val_loss did not improve
 - 5s - loss: 11.0117 - out_stats_loss: 4.1451 - out_counts_loss: 1.8096 - out_mean_covariance_loss: 58.9872 - out_fielding_position_loss: 2.1075 - val_loss: 12.1603 - val_out_stats_loss: 4.4241 - val_out_counts_loss: 2.2548 - val_out_mean_covariance_loss: 63.4593 - val_out_fielding_position_loss: 2.3084
Epoch 46/1000

Epoch 00046: val_loss did not improve
 - 5s - loss: 10.9703 - out_stats_loss: 4.1292 - out_counts_loss: 1.8052 - out_mean_covariance_loss: 59.0695 - out_fielding_position_loss: 2.0825 - val_loss: 12.1722 - val_out_stats_loss: 4.4287 - val_out_counts_loss: 2.2683 - val_out_mean_covariance_loss: 63.5095 - val_out_fielding_position_loss: 2.2996
Epoch 47/1000

Epoch 00047: val_loss did not improve
 - 5s - loss: 10.9390 - out_stats_loss: 4.1281 - out_counts_loss: 1.7922 - out_mean_covariance_loss: 58.8417 - out_fielding_position_loss: 2.0766 - val_loss: 12.1797 - val_out_stats_loss: 4.4371 - val_out_counts_loss: 2.2670 - val_out_mean_covariance_loss: 63.5959 - val_out_fielding_position_loss: 2.2959
Epoch 48/1000

Epoch 00048: val_loss did not improve
 - 5s - loss: 10.8999 - out_stats_loss: 4.1168 - out_counts_loss: 1.7859 - out_mean_covariance_loss: 58.5984 - out_fielding_position_loss: 2.0673 - val_loss: 12.1576 - val_out_stats_loss: 4.4221 - val_out_counts_loss: 2.2746 - val_out_mean_covariance_loss: 63.4294 - val_out_fielding_position_loss: 2.2894
Epoch 49/1000

Epoch 00049: val_loss did not improve
 - 5s - loss: 10.9286 - out_stats_loss: 4.1321 - out_counts_loss: 1.7891 - out_mean_covariance_loss: 58.8271 - out_fielding_position_loss: 2.0660 - val_loss: 12.1792 - val_out_stats_loss: 4.4353 - val_out_counts_loss: 2.2879 - val_out_mean_covariance_loss: 63.3296 - val_out_fielding_position_loss: 2.2895
Epoch 50/1000

Epoch 00050: val_loss did not improve
 - 5s - loss: 10.8854 - out_stats_loss: 4.1213 - out_counts_loss: 1.7794 - out_mean_covariance_loss: 58.5646 - out_fielding_position_loss: 2.0565 - val_loss: 12.1590 - val_out_stats_loss: 4.4201 - val_out_counts_loss: 2.2927 - val_out_mean_covariance_loss: 63.2960 - val_out_fielding_position_loss: 2.2814
Epoch 51/1000

Epoch 00051: val_loss did not improve
 - 5s - loss: 10.8085 - out_stats_loss: 4.0873 - out_counts_loss: 1.7664 - out_mean_covariance_loss: 58.2918 - out_fielding_position_loss: 2.0402 - val_loss: 12.1748 - val_out_stats_loss: 4.4303 - val_out_counts_loss: 2.3020 - val_out_mean_covariance_loss: 63.3014 - val_out_fielding_position_loss: 2.2773
Epoch 52/1000

Epoch 00052: val_loss did not improve
 - 5s - loss: 10.7356 - out_stats_loss: 4.0713 - out_counts_loss: 1.7529 - out_mean_covariance_loss: 57.8231 - out_fielding_position_loss: 2.0203 - val_loss: 12.1509 - val_out_stats_loss: 4.4300 - val_out_counts_loss: 2.2850 - val_out_mean_covariance_loss: 63.3259 - val_out_fielding_position_loss: 2.2697
Epoch 53/1000

Epoch 00053: val_loss did not improve
 - 5s - loss: 10.6994 - out_stats_loss: 4.0760 - out_counts_loss: 1.7299 - out_mean_covariance_loss: 57.7612 - out_fielding_position_loss: 2.0055 - val_loss: 12.1658 - val_out_stats_loss: 4.4302 - val_out_counts_loss: 2.3028 - val_out_mean_covariance_loss: 63.2777 - val_out_fielding_position_loss: 2.2689
Epoch 54/1000

Epoch 00054: val_loss did not improve
 - 5s - loss: 10.7477 - out_stats_loss: 4.0874 - out_counts_loss: 1.7403 - out_mean_covariance_loss: 58.0186 - out_fielding_position_loss: 2.0190 - val_loss: 12.1584 - val_out_stats_loss: 4.4317 - val_out_counts_loss: 2.3021 - val_out_mean_covariance_loss: 63.2154 - val_out_fielding_position_loss: 2.2639
Epoch 55/1000

Epoch 00055: val_loss improved from 12.14768 to 12.14214, saving model to models/bc/shift2/max2016/simple-rnn/0.h5
 - 5s - loss: 10.6983 - out_stats_loss: 4.0865 - out_counts_loss: 1.7228 - out_mean_covariance_loss: 58.0669 - out_fielding_position_loss: 1.9857 - val_loss: 12.1421 - val_out_stats_loss: 4.4231 - val_out_counts_loss: 2.3030 - val_out_mean_covariance_loss: 63.1818 - val_out_fielding_position_loss: 2.2570
Epoch 56/1000

Epoch 00056: val_loss did not improve
 - 5s - loss: 10.6964 - out_stats_loss: 4.0941 - out_counts_loss: 1.7203 - out_mean_covariance_loss: 57.9506 - out_fielding_position_loss: 1.9843 - val_loss: 12.2150 - val_out_stats_loss: 4.4666 - val_out_counts_loss: 2.3294 - val_out_mean_covariance_loss: 63.2354 - val_out_fielding_position_loss: 2.2573
Epoch 57/1000

Epoch 00057: val_loss did not improve
 - 5s - loss: 10.6085 - out_stats_loss: 4.0527 - out_counts_loss: 1.7228 - out_mean_covariance_loss: 57.3799 - out_fielding_position_loss: 1.9639 - val_loss: 12.1513 - val_out_stats_loss: 4.4340 - val_out_counts_loss: 2.3112 - val_out_mean_covariance_loss: 63.0154 - val_out_fielding_position_loss: 2.2554
Epoch 58/1000

Epoch 00058: val_loss did not improve
 - 5s - loss: 10.6439 - out_stats_loss: 4.0732 - out_counts_loss: 1.7107 - out_mean_covariance_loss: 57.7408 - out_fielding_position_loss: 1.9730 - val_loss: 12.1996 - val_out_stats_loss: 4.4499 - val_out_counts_loss: 2.3363 - val_out_mean_covariance_loss: 63.1579 - val_out_fielding_position_loss: 2.2555
Epoch 59/1000

Epoch 00059: val_loss did not improve
 - 5s - loss: 10.5848 - out_stats_loss: 4.0489 - out_counts_loss: 1.7096 - out_mean_covariance_loss: 57.3316 - out_fielding_position_loss: 1.9597 - val_loss: 12.3561 - val_out_stats_loss: 4.4822 - val_out_counts_loss: 2.4302 - val_out_mean_covariance_loss: 63.6598 - val_out_fielding_position_loss: 2.2608
Epoch 60/1000

Epoch 00060: val_loss did not improve
 - 5s - loss: 10.5507 - out_stats_loss: 4.0433 - out_counts_loss: 1.6872 - out_mean_covariance_loss: 57.2692 - out_fielding_position_loss: 1.9568 - val_loss: 12.2419 - val_out_stats_loss: 4.4495 - val_out_counts_loss: 2.3730 - val_out_mean_covariance_loss: 63.2854 - val_out_fielding_position_loss: 2.2551
Epoch 61/1000

Epoch 00061: val_loss did not improve
 - 5s - loss: 10.5178 - out_stats_loss: 4.0321 - out_counts_loss: 1.6902 - out_mean_covariance_loss: 57.0006 - out_fielding_position_loss: 1.9455 - val_loss: 12.1703 - val_out_stats_loss: 4.4378 - val_out_counts_loss: 2.3356 - val_out_mean_covariance_loss: 63.1117 - val_out_fielding_position_loss: 2.2414
Epoch 62/1000

Epoch 00062: val_loss did not improve
 - 5s - loss: 10.5140 - out_stats_loss: 4.0465 - out_counts_loss: 1.6733 - out_mean_covariance_loss: 57.2716 - out_fielding_position_loss: 1.9306 - val_loss: 12.2401 - val_out_stats_loss: 4.4616 - val_out_counts_loss: 2.3656 - val_out_mean_covariance_loss: 63.3943 - val_out_fielding_position_loss: 2.2432
Epoch 63/1000

Epoch 00063: val_loss did not improve
 - 5s - loss: 10.4551 - out_stats_loss: 4.0274 - out_counts_loss: 1.6655 - out_mean_covariance_loss: 56.8818 - out_fielding_position_loss: 1.9181 - val_loss: 12.1671 - val_out_stats_loss: 4.4282 - val_out_counts_loss: 2.3492 - val_out_mean_covariance_loss: 63.1109 - val_out_fielding_position_loss: 2.2341
Epoch 64/1000

Epoch 00064: val_loss did not improve
 - 5s - loss: 10.4504 - out_stats_loss: 4.0310 - out_counts_loss: 1.6708 - out_mean_covariance_loss: 56.9287 - out_fielding_position_loss: 1.9022 - val_loss: 12.2142 - val_out_stats_loss: 4.4507 - val_out_counts_loss: 2.3658 - val_out_mean_covariance_loss: 63.2734 - val_out_fielding_position_loss: 2.2340
Epoch 65/1000

Epoch 00065: val_loss did not improve
 - 5s - loss: 10.4453 - out_stats_loss: 4.0371 - out_counts_loss: 1.6503 - out_mean_covariance_loss: 56.9661 - out_fielding_position_loss: 1.9096 - val_loss: 12.2485 - val_out_stats_loss: 4.4542 - val_out_counts_loss: 2.3840 - val_out_mean_covariance_loss: 63.4901 - val_out_fielding_position_loss: 2.2359
Epoch 66/1000

Epoch 00066: val_loss did not improve
 - 5s - loss: 10.4273 - out_stats_loss: 4.0303 - out_counts_loss: 1.6504 - out_mean_covariance_loss: 56.8701 - out_fielding_position_loss: 1.9031 - val_loss: 12.1892 - val_out_stats_loss: 4.4437 - val_out_counts_loss: 2.3659 - val_out_mean_covariance_loss: 63.0489 - val_out_fielding_position_loss: 2.2271
Epoch 67/1000

Epoch 00067: val_loss did not improve
 - 5s - loss: 10.3621 - out_stats_loss: 4.0065 - out_counts_loss: 1.6450 - out_mean_covariance_loss: 56.4046 - out_fielding_position_loss: 1.8904 - val_loss: 12.1851 - val_out_stats_loss: 4.4465 - val_out_counts_loss: 2.3647 - val_out_mean_covariance_loss: 63.1114 - val_out_fielding_position_loss: 2.2184
Epoch 68/1000

Epoch 00068: val_loss did not improve
 - 5s - loss: 10.3112 - out_stats_loss: 3.9955 - out_counts_loss: 1.6275 - out_mean_covariance_loss: 56.2093 - out_fielding_position_loss: 1.8777 - val_loss: 12.1790 - val_out_stats_loss: 4.4338 - val_out_counts_loss: 2.3779 - val_out_mean_covariance_loss: 63.0254 - val_out_fielding_position_loss: 2.2160
Epoch 69/1000

Epoch 00069: val_loss did not improve
 - 5s - loss: 10.3091 - out_stats_loss: 4.0018 - out_counts_loss: 1.6221 - out_mean_covariance_loss: 56.3668 - out_fielding_position_loss: 1.8669 - val_loss: 12.2532 - val_out_stats_loss: 4.4491 - val_out_counts_loss: 2.4128 - val_out_mean_covariance_loss: 63.3762 - val_out_fielding_position_loss: 2.2225
Epoch 70/1000

Epoch 00070: val_loss did not improve
 - 5s - loss: 10.2839 - out_stats_loss: 3.9736 - out_counts_loss: 1.6349 - out_mean_covariance_loss: 55.9280 - out_fielding_position_loss: 1.8790 - val_loss: 12.1999 - val_out_stats_loss: 4.4427 - val_out_counts_loss: 2.3819 - val_out_mean_covariance_loss: 63.1884 - val_out_fielding_position_loss: 2.2159
Epoch 71/1000

Epoch 00071: val_loss did not improve
 - 5s - loss: 10.2268 - out_stats_loss: 3.9723 - out_counts_loss: 1.6131 - out_mean_covariance_loss: 55.8090 - out_fielding_position_loss: 1.8509 - val_loss: 12.1861 - val_out_stats_loss: 4.4328 - val_out_counts_loss: 2.3881 - val_out_mean_covariance_loss: 63.0858 - val_out_fielding_position_loss: 2.2110
Epoch 72/1000

Epoch 00072: val_loss did not improve
 - 5s - loss: 10.2685 - out_stats_loss: 3.9951 - out_counts_loss: 1.6037 - out_mean_covariance_loss: 56.2542 - out_fielding_position_loss: 1.8570 - val_loss: 12.2208 - val_out_stats_loss: 4.4435 - val_out_counts_loss: 2.4084 - val_out_mean_covariance_loss: 63.1543 - val_out_fielding_position_loss: 2.2112
Epoch 73/1000

Epoch 00073: val_loss did not improve
 - 5s - loss: 10.2092 - out_stats_loss: 3.9700 - out_counts_loss: 1.6047 - out_mean_covariance_loss: 55.6122 - out_fielding_position_loss: 1.8540 - val_loss: 12.2114 - val_out_stats_loss: 4.4505 - val_out_counts_loss: 2.3933 - val_out_mean_covariance_loss: 63.3274 - val_out_fielding_position_loss: 2.2013
Epoch 74/1000

Epoch 00074: val_loss did not improve
 - 5s - loss: 10.2423 - out_stats_loss: 3.9909 - out_counts_loss: 1.6049 - out_mean_covariance_loss: 56.1561 - out_fielding_position_loss: 1.8387 - val_loss: 12.3700 - val_out_stats_loss: 4.4901 - val_out_counts_loss: 2.4782 - val_out_mean_covariance_loss: 63.5892 - val_out_fielding_position_loss: 2.2223
Epoch 75/1000

Epoch 00075: val_loss did not improve
 - 5s - loss: 10.2276 - out_stats_loss: 3.9859 - out_counts_loss: 1.5974 - out_mean_covariance_loss: 55.9632 - out_fielding_position_loss: 1.8461 - val_loss: 12.2661 - val_out_stats_loss: 4.4597 - val_out_counts_loss: 2.4314 - val_out_mean_covariance_loss: 63.3286 - val_out_fielding_position_loss: 2.2086
Epoch 76/1000

Epoch 00076: val_loss did not improve
 - 5s - loss: 10.1948 - out_stats_loss: 3.9851 - out_counts_loss: 1.5959 - out_mean_covariance_loss: 55.8354 - out_fielding_position_loss: 1.8221 - val_loss: 12.2641 - val_out_stats_loss: 4.4434 - val_out_counts_loss: 2.4359 - val_out_mean_covariance_loss: 63.4671 - val_out_fielding_position_loss: 2.2115
Epoch 77/1000

Epoch 00077: val_loss did not improve
 - 5s - loss: 10.1716 - out_stats_loss: 3.9792 - out_counts_loss: 1.5846 - out_mean_covariance_loss: 55.6752 - out_fielding_position_loss: 1.8240 - val_loss: 12.2519 - val_out_stats_loss: 4.4599 - val_out_counts_loss: 2.4158 - val_out_mean_covariance_loss: 63.4569 - val_out_fielding_position_loss: 2.2034
Epoch 78/1000

Epoch 00078: val_loss did not improve
 - 5s - loss: 10.1826 - out_stats_loss: 3.9887 - out_counts_loss: 1.5731 - out_mean_covariance_loss: 56.2649 - out_fielding_position_loss: 1.8076 - val_loss: 12.2632 - val_out_stats_loss: 4.4665 - val_out_counts_loss: 2.4254 - val_out_mean_covariance_loss: 63.4127 - val_out_fielding_position_loss: 2.2007
Epoch 79/1000

Epoch 00079: val_loss did not improve
 - 5s - loss: 10.1493 - out_stats_loss: 3.9625 - out_counts_loss: 1.5890 - out_mean_covariance_loss: 55.5020 - out_fielding_position_loss: 1.8226 - val_loss: 12.2567 - val_out_stats_loss: 4.4506 - val_out_counts_loss: 2.4401 - val_out_mean_covariance_loss: 63.2847 - val_out_fielding_position_loss: 2.2017
Epoch 80/1000

Epoch 00080: val_loss did not improve
 - 5s - loss: 10.1116 - out_stats_loss: 3.9714 - out_counts_loss: 1.5534 - out_mean_covariance_loss: 55.6885 - out_fielding_position_loss: 1.8023 - val_loss: 12.2776 - val_out_stats_loss: 4.4532 - val_out_counts_loss: 2.4507 - val_out_mean_covariance_loss: 63.4839 - val_out_fielding_position_loss: 2.1996
Epoch 81/1000

Epoch 00081: val_loss did not improve
 - 5s - loss: 10.0949 - out_stats_loss: 3.9550 - out_counts_loss: 1.5637 - out_mean_covariance_loss: 55.4677 - out_fielding_position_loss: 1.8028 - val_loss: 12.2914 - val_out_stats_loss: 4.4783 - val_out_counts_loss: 2.4440 - val_out_mean_covariance_loss: 63.3441 - val_out_fielding_position_loss: 2.2019
Epoch 82/1000

Epoch 00082: val_loss did not improve
 - 5s - loss: 10.0124 - out_stats_loss: 3.9341 - out_counts_loss: 1.5539 - out_mean_covariance_loss: 54.9117 - out_fielding_position_loss: 1.7788 - val_loss: 12.3435 - val_out_stats_loss: 4.4720 - val_out_counts_loss: 2.4890 - val_out_mean_covariance_loss: 63.5851 - val_out_fielding_position_loss: 2.2032
Epoch 83/1000

Epoch 00083: val_loss did not improve
 - 5s - loss: 10.0948 - out_stats_loss: 3.9660 - out_counts_loss: 1.5612 - out_mean_covariance_loss: 55.6807 - out_fielding_position_loss: 1.7836 - val_loss: 12.2409 - val_out_stats_loss: 4.4551 - val_out_counts_loss: 2.4316 - val_out_mean_covariance_loss: 63.3953 - val_out_fielding_position_loss: 2.1843
Epoch 84/1000

Epoch 00084: val_loss did not improve
 - 5s - loss: 10.0663 - out_stats_loss: 3.9629 - out_counts_loss: 1.5585 - out_mean_covariance_loss: 55.5913 - out_fielding_position_loss: 1.7653 - val_loss: 12.3386 - val_out_stats_loss: 4.4805 - val_out_counts_loss: 2.4833 - val_out_mean_covariance_loss: 63.5503 - val_out_fielding_position_loss: 2.1972
Epoch 85/1000

Epoch 00085: val_loss did not improve
 - 5s - loss: 10.0167 - out_stats_loss: 3.9424 - out_counts_loss: 1.5475 - out_mean_covariance_loss: 55.0822 - out_fielding_position_loss: 1.7727 - val_loss: 12.3906 - val_out_stats_loss: 4.4955 - val_out_counts_loss: 2.5067 - val_out_mean_covariance_loss: 63.7119 - val_out_fielding_position_loss: 2.2029
Epoch 86/1000

Epoch 00086: val_loss did not improve
 - 5s - loss: 9.9916 - out_stats_loss: 3.9303 - out_counts_loss: 1.5540 - out_mean_covariance_loss: 54.7849 - out_fielding_position_loss: 1.7680 - val_loss: 12.4946 - val_out_stats_loss: 4.5141 - val_out_counts_loss: 2.5513 - val_out_mean_covariance_loss: 64.2234 - val_out_fielding_position_loss: 2.2180
Epoch 87/1000

Epoch 00087: val_loss did not improve
 - 5s - loss: 10.0524 - out_stats_loss: 3.9665 - out_counts_loss: 1.5424 - out_mean_covariance_loss: 55.6347 - out_fielding_position_loss: 1.7618 - val_loss: 12.2960 - val_out_stats_loss: 4.4672 - val_out_counts_loss: 2.4701 - val_out_mean_covariance_loss: 63.5259 - val_out_fielding_position_loss: 2.1824
Epoch 88/1000

Epoch 00088: val_loss did not improve
 - 5s - loss: 9.9595 - out_stats_loss: 3.9280 - out_counts_loss: 1.5384 - out_mean_covariance_loss: 54.9795 - out_fielding_position_loss: 1.7442 - val_loss: 12.3301 - val_out_stats_loss: 4.4751 - val_out_counts_loss: 2.4763 - val_out_mean_covariance_loss: 63.7258 - val_out_fielding_position_loss: 2.1923
Epoch 89/1000

Epoch 00089: val_loss did not improve
 - 5s - loss: 9.9619 - out_stats_loss: 3.9503 - out_counts_loss: 1.5194 - out_mean_covariance_loss: 55.1697 - out_fielding_position_loss: 1.7338 - val_loss: 12.4931 - val_out_stats_loss: 4.5400 - val_out_counts_loss: 2.5354 - val_out_mean_covariance_loss: 64.2249 - val_out_fielding_position_loss: 2.2064
Epoch 90/1000

Epoch 00090: val_loss did not improve
 - 5s - loss: 9.9721 - out_stats_loss: 3.9456 - out_counts_loss: 1.5372 - out_mean_covariance_loss: 54.9986 - out_fielding_position_loss: 1.7394 - val_loss: 12.2941 - val_out_stats_loss: 4.4704 - val_out_counts_loss: 2.4737 - val_out_mean_covariance_loss: 63.4030 - val_out_fielding_position_loss: 2.1799
Epoch 91/1000

Epoch 00091: val_loss did not improve
 - 5s - loss: 9.9750 - out_stats_loss: 3.9471 - out_counts_loss: 1.5284 - out_mean_covariance_loss: 55.1985 - out_fielding_position_loss: 1.7396 - val_loss: 12.4983 - val_out_stats_loss: 4.5216 - val_out_counts_loss: 2.5514 - val_out_mean_covariance_loss: 64.1325 - val_out_fielding_position_loss: 2.2188
Epoch 92/1000

Epoch 00092: val_loss did not improve
 - 5s - loss: 9.9226 - out_stats_loss: 3.9211 - out_counts_loss: 1.5336 - out_mean_covariance_loss: 54.7504 - out_fielding_position_loss: 1.7303 - val_loss: 12.4229 - val_out_stats_loss: 4.5120 - val_out_counts_loss: 2.5172 - val_out_mean_covariance_loss: 63.9664 - val_out_fielding_position_loss: 2.1954
Epoch 93/1000

Epoch 00093: val_loss did not improve
 - 5s - loss: 9.8541 - out_stats_loss: 3.9074 - out_counts_loss: 1.5025 - out_mean_covariance_loss: 54.5675 - out_fielding_position_loss: 1.7159 - val_loss: 12.3279 - val_out_stats_loss: 4.4750 - val_out_counts_loss: 2.4837 - val_out_mean_covariance_loss: 63.8091 - val_out_fielding_position_loss: 2.1787
Epoch 94/1000

Epoch 00094: val_loss did not improve
 - 5s - loss: 9.8321 - out_stats_loss: 3.9070 - out_counts_loss: 1.4979 - out_mean_covariance_loss: 54.3636 - out_fielding_position_loss: 1.7090 - val_loss: 12.3593 - val_out_stats_loss: 4.4863 - val_out_counts_loss: 2.5001 - val_out_mean_covariance_loss: 63.8093 - val_out_fielding_position_loss: 2.1825
Epoch 95/1000

Epoch 00095: val_loss did not improve
 - 5s - loss: 9.8667 - out_stats_loss: 3.9196 - out_counts_loss: 1.5134 - out_mean_covariance_loss: 54.3933 - out_fielding_position_loss: 1.7141 - val_loss: 12.3518 - val_out_stats_loss: 4.4764 - val_out_counts_loss: 2.5140 - val_out_mean_covariance_loss: 63.7469 - val_out_fielding_position_loss: 2.1741
Epoch 96/1000

Epoch 00096: val_loss did not improve
 - 5s - loss: 9.7992 - out_stats_loss: 3.8942 - out_counts_loss: 1.4915 - out_mean_covariance_loss: 54.1974 - out_fielding_position_loss: 1.7035 - val_loss: 12.3960 - val_out_stats_loss: 4.4972 - val_out_counts_loss: 2.5130 - val_out_mean_covariance_loss: 64.0951 - val_out_fielding_position_loss: 2.1810
Epoch 97/1000

Epoch 00097: val_loss did not improve
 - 5s - loss: 9.7762 - out_stats_loss: 3.8867 - out_counts_loss: 1.4839 - out_mean_covariance_loss: 54.1556 - out_fielding_position_loss: 1.6978 - val_loss: 12.3328 - val_out_stats_loss: 4.4742 - val_out_counts_loss: 2.4880 - val_out_mean_covariance_loss: 63.9097 - val_out_fielding_position_loss: 2.1752
Epoch 98/1000

Epoch 00098: val_loss did not improve
 - 5s - loss: 9.7827 - out_stats_loss: 3.9008 - out_counts_loss: 1.4747 - out_mean_covariance_loss: 54.4421 - out_fielding_position_loss: 1.6851 - val_loss: 12.4492 - val_out_stats_loss: 4.4952 - val_out_counts_loss: 2.5402 - val_out_mean_covariance_loss: 64.1884 - val_out_fielding_position_loss: 2.2043
Epoch 99/1000

Epoch 00099: val_loss did not improve
 - 5s - loss: 9.7472 - out_stats_loss: 3.8812 - out_counts_loss: 1.4694 - out_mean_covariance_loss: 54.0578 - out_fielding_position_loss: 1.6937 - val_loss: 12.4660 - val_out_stats_loss: 4.5176 - val_out_counts_loss: 2.5370 - val_out_mean_covariance_loss: 64.3220 - val_out_fielding_position_loss: 2.1954
Epoch 100/1000

Epoch 00100: val_loss did not improve
 - 5s - loss: 9.7739 - out_stats_loss: 3.8873 - out_counts_loss: 1.4859 - out_mean_covariance_loss: 54.0852 - out_fielding_position_loss: 1.6965 - val_loss: 12.4009 - val_out_stats_loss: 4.4842 - val_out_counts_loss: 2.5196 - val_out_mean_covariance_loss: 64.0586 - val_out_fielding_position_loss: 2.1941
Epoch 101/1000

Epoch 00101: val_loss did not improve
 - 5s - loss: 9.7956 - out_stats_loss: 3.9151 - out_counts_loss: 1.4717 - out_mean_covariance_loss: 54.5644 - out_fielding_position_loss: 1.6806 - val_loss: 12.3725 - val_out_stats_loss: 4.4881 - val_out_counts_loss: 2.5047 - val_out_mean_covariance_loss: 64.2026 - val_out_fielding_position_loss: 2.1696
Epoch 102/1000

Epoch 00102: val_loss did not improve
 - 5s - loss: 9.7628 - out_stats_loss: 3.9018 - out_counts_loss: 1.4648 - out_mean_covariance_loss: 54.2832 - out_fielding_position_loss: 1.6821 - val_loss: 12.5110 - val_out_stats_loss: 4.5225 - val_out_counts_loss: 2.5699 - val_out_mean_covariance_loss: 64.4654 - val_out_fielding_position_loss: 2.1954
Epoch 103/1000

Epoch 00103: val_loss did not improve
 - 5s - loss: 9.6774 - out_stats_loss: 3.8679 - out_counts_loss: 1.4633 - out_mean_covariance_loss: 53.7288 - out_fielding_position_loss: 1.6598 - val_loss: 12.5804 - val_out_stats_loss: 4.5424 - val_out_counts_loss: 2.6020 - val_out_mean_covariance_loss: 64.6768 - val_out_fielding_position_loss: 2.2021
Epoch 104/1000

Epoch 00104: val_loss did not improve
 - 5s - loss: 9.6965 - out_stats_loss: 3.8821 - out_counts_loss: 1.4659 - out_mean_covariance_loss: 53.9831 - out_fielding_position_loss: 1.6493 - val_loss: 12.5386 - val_out_stats_loss: 4.5196 - val_out_counts_loss: 2.5894 - val_out_mean_covariance_loss: 64.5288 - val_out_fielding_position_loss: 2.2032
Epoch 105/1000

Epoch 00105: val_loss did not improve
 - 5s - loss: 9.6452 - out_stats_loss: 3.8570 - out_counts_loss: 1.4528 - out_mean_covariance_loss: 53.4726 - out_fielding_position_loss: 1.6617 - val_loss: 12.5074 - val_out_stats_loss: 4.5398 - val_out_counts_loss: 2.5514 - val_out_mean_covariance_loss: 64.7292 - val_out_fielding_position_loss: 2.1798
/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Years: [1958,2016]
Shift: 2
Fold: 4
Training into models/bc/shift2/max2016/simple-rnn/0.h5
/usr/local/lib/python3.5/dist-packages/keras/legacy/layers.py:533: UserWarning: The `MaxoutDense` layer is deprecated and will be removed after 06/2017.
  warnings.warn('The `MaxoutDense` layer is deprecated '
