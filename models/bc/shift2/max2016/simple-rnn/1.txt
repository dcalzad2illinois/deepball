__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
in_age (InputLayer)             (None, None, 2)      0                                            
__________________________________________________________________________________________________
in_bio (InputLayer)             (None, None, 7)      0                                            
__________________________________________________________________________________________________
in_fielding_position (InputLaye (None, None, 2)      0                                            
__________________________________________________________________________________________________
in_out_fielding_position (Input (None, None, 12)     0                                            
__________________________________________________________________________________________________
in_out_league_offense (InputLay (None, None, 9)      0                                            
__________________________________________________________________________________________________
in_out_park_factors (InputLayer (None, None, 8)      0                                            
__________________________________________________________________________________________________
in_out_plate_discipline (InputL (None, None, 8)      0                                            
__________________________________________________________________________________________________
in_out_running (InputLayer)     (None, None, 18)     0                                            
__________________________________________________________________________________________________
in_out_saber (InputLayer)       (None, None, 14)     0                                            
__________________________________________________________________________________________________
in_out_stats_extended (InputLay (None, None, 36)     0                                            
__________________________________________________________________________________________________
in_park_factors (InputLayer)    (None, None, 8)      0                                            
__________________________________________________________________________________________________
masked_in_age (Masking)         (None, None, 2)      0           in_age[0][0]                     
__________________________________________________________________________________________________
masked_in_bio (Masking)         (None, None, 7)      0           in_bio[0][0]                     
__________________________________________________________________________________________________
masked_in_fielding_position (Ma (None, None, 2)      0           in_fielding_position[0][0]       
__________________________________________________________________________________________________
masked_in_out_fielding_position (None, None, 12)     0           in_out_fielding_position[0][0]   
__________________________________________________________________________________________________
masked_in_out_league_offense (M (None, None, 9)      0           in_out_league_offense[0][0]      
__________________________________________________________________________________________________
masked_in_out_park_factors (Mas (None, None, 8)      0           in_out_park_factors[0][0]        
__________________________________________________________________________________________________
masked_in_out_plate_discipline  (None, None, 8)      0           in_out_plate_discipline[0][0]    
__________________________________________________________________________________________________
masked_in_out_running (Masking) (None, None, 18)     0           in_out_running[0][0]             
__________________________________________________________________________________________________
masked_in_out_saber (Masking)   (None, None, 14)     0           in_out_saber[0][0]               
__________________________________________________________________________________________________
masked_in_out_stats_extended (M (None, None, 36)     0           in_out_stats_extended[0][0]      
__________________________________________________________________________________________________
masked_in_park_factors (Masking (None, None, 8)      0           in_park_factors[0][0]            
__________________________________________________________________________________________________
time_distributed_9 (TimeDistrib (None, None, 1)      0           masked_in_age[0][0]              
__________________________________________________________________________________________________
time_distributed_4 (TimeDistrib (None, None, 6)      0           masked_in_bio[0][0]              
__________________________________________________________________________________________________
time_distributed_3 (TimeDistrib (None, None, 1)      0           masked_in_fielding_position[0][0]
__________________________________________________________________________________________________
time_distributed_10 (TimeDistri (None, None, 11)     0           masked_in_out_fielding_position[0
__________________________________________________________________________________________________
time_distributed_6 (TimeDistrib (None, None, 8)      0           masked_in_out_league_offense[0][0
__________________________________________________________________________________________________
time_distributed_8 (TimeDistrib (None, None, 7)      0           masked_in_out_park_factors[0][0] 
__________________________________________________________________________________________________
time_distributed_2 (TimeDistrib (None, None, 7)      0           masked_in_out_plate_discipline[0]
__________________________________________________________________________________________________
time_distributed_11 (TimeDistri (None, None, 17)     0           masked_in_out_running[0][0]      
__________________________________________________________________________________________________
time_distributed_1 (TimeDistrib (None, None, 13)     0           masked_in_out_saber[0][0]        
__________________________________________________________________________________________________
time_distributed_5 (TimeDistrib (None, None, 35)     0           masked_in_out_stats_extended[0][0
__________________________________________________________________________________________________
time_distributed_7 (TimeDistrib (None, None, 7)      0           masked_in_park_factors[0][0]     
__________________________________________________________________________________________________
norm_in_age (BatchNormalization (None, None, 1)      4           time_distributed_9[0][0]         
__________________________________________________________________________________________________
norm_in_bio (BatchNormalization (None, None, 6)      24          time_distributed_4[0][0]         
__________________________________________________________________________________________________
norm_in_fielding_position (Batc (None, None, 1)      4           time_distributed_3[0][0]         
__________________________________________________________________________________________________
norm_in_out_fielding_position ( (None, None, 11)     44          time_distributed_10[0][0]        
__________________________________________________________________________________________________
norm_in_out_league_offense (Bat (None, None, 8)      32          time_distributed_6[0][0]         
__________________________________________________________________________________________________
norm_in_out_park_factors (Batch (None, None, 7)      28          time_distributed_8[0][0]         
__________________________________________________________________________________________________
norm_in_out_plate_discipline (B (None, None, 7)      28          time_distributed_2[0][0]         
__________________________________________________________________________________________________2018-02-06 13:47:23.776086: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-02-06 13:47:31.166486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: eca0:00:00.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2018-02-06 13:47:31.166532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: eca0:00:00.0, compute capability: 3.7)

norm_in_out_running (BatchNorma (None, None, 17)     68          time_distributed_11[0][0]        
__________________________________________________________________________________________________
norm_in_out_saber (BatchNormali (None, None, 13)     52          time_distributed_1[0][0]         
__________________________________________________________________________________________________
norm_in_out_stats_extended (Bat (None, None, 35)     140         time_distributed_5[0][0]         
__________________________________________________________________________________________________
norm_in_park_factors (BatchNorm (None, None, 7)      28          time_distributed_7[0][0]         
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, None, 113)    0           norm_in_age[0][0]                
                                                                 norm_in_bio[0][0]                
                                                                 norm_in_fielding_position[0][0]  
                                                                 norm_in_out_fielding_position[0][
                                                                 norm_in_out_league_offense[0][0] 
                                                                 norm_in_out_park_factors[0][0]   
                                                                 norm_in_out_plate_discipline[0][0
                                                                 norm_in_out_running[0][0]        
                                                                 norm_in_out_saber[0][0]          
                                                                 norm_in_out_stats_extended[0][0] 
                                                                 norm_in_park_factors[0][0]       
__________________________________________________________________________________________________
gru_1 (GRU)                     (None, None, 113)    76953       concatenate_1[0][0]              
__________________________________________________________________________________________________
gru_2 (GRU)                     (None, None, 113)    76953       gru_1[0][0]                      
__________________________________________________________________________________________________
mv_out_stats (TimeDistributed)  (None, None, 5)      4560        gru_2[0][0]                      
__________________________________________________________________________________________________
mv_out_counts (TimeDistributed) (None, None, 3)      2736        gru_2[0][0]                      
__________________________________________________________________________________________________
mv_out_mean_covariance (TimeDis (None, None, 72)     65664       gru_2[0][0]                      
__________________________________________________________________________________________________
mv_out_fielding_position (TimeD (None, None, 11)     10032       gru_2[0][0]                      
__________________________________________________________________________________________________
out_stats (Activation)          (None, None, 5)      0           mv_out_stats[0][0]               
__________________________________________________________________________________________________
out_counts (Activation)         (None, None, 3)      0           mv_out_counts[0][0]              
__________________________________________________________________________________________________
out_mean_covariance (Activation (None, None, 72)     0           mv_out_mean_covariance[0][0]     
__________________________________________________________________________________________________
out_fielding_position (Activati (None, None, 11)     0           mv_out_fielding_position[0][0]   
==================================================================================================
Total params: 237,350
Trainable params: 237,124
Non-trainable params: 226
__________________________________________________________________________________________________
Train on 5879 samples, validate on 1409 samples
Epoch 1/1000

Epoch 00001: val_loss improved from inf to 19.17564, saving model to models/bc/shift2/max2016/simple-rnn/1.h5
 - 16s - loss: 20.6345 - out_stats_loss: 7.1285 - out_counts_loss: 3.7819 - out_mean_covariance_loss: 104.1430 - out_fielding_position_loss: 4.5169 - val_loss: 19.1756 - val_out_stats_loss: 6.6988 - val_out_counts_loss: 3.2092 - val_out_mean_covariance_loss: 99.9665 - val_out_fielding_position_loss: 4.2693
Epoch 2/1000

Epoch 00002: val_loss improved from 19.17564 to 16.61524, saving model to models/bc/shift2/max2016/simple-rnn/1.h5
 - 5s - loss: 17.8016 - out_stats_loss: 6.1206 - out_counts_loss: 2.9281 - out_mean_covariance_loss: 92.9849 - out_fielding_position_loss: 4.1037 - val_loss: 16.6152 - val_out_stats_loss: 5.6817 - val_out_counts_loss: 2.6241 - val_out_mean_covariance_loss: 88.1215 - val_out_fielding_position_loss: 3.9033
Epoch 3/1000

Epoch 00003: val_loss improved from 16.61524 to 15.10591, saving model to models/bc/shift2/max2016/simple-rnn/1.h5
 - 5s - loss: 15.7811 - out_stats_loss: 5.3179 - out_counts_loss: 2.6019 - out_mean_covariance_loss: 82.2417 - out_fielding_position_loss: 3.7492 - val_loss: 15.1059 - val_out_stats_loss: 5.1397 - val_out_counts_loss: 2.4316 - val_out_mean_covariance_loss: 78.9098 - val_out_fielding_position_loss: 3.5891
Epoch 4/1000

Epoch 00004: val_loss improved from 15.10591 to 14.32807, saving model to models/bc/shift2/max2016/simple-rnn/1.h5
 - 5s - loss: 14.7124 - out_stats_loss: 4.9757 - out_counts_loss: 2.4725 - out_mean_covariance_loss: 75.6475 - out_fielding_position_loss: 3.4819 - val_loss: 14.3281 - val_out_stats_loss: 4.9372 - val_out_counts_loss: 2.3405 - val_out_mean_covariance_loss: 74.4096 - val_out_fielding_position_loss: 3.3299
Epoch 5/1000

Epoch 00005: val_loss improved from 14.32807 to 13.88606, saving model to models/bc/shift2/max2016/simple-rnn/1.h5
 - 5s - loss: 14.1211 - out_stats_loss: 4.8293 - out_counts_loss: 2.4172 - out_mean_covariance_loss: 72.3674 - out_fielding_position_loss: 3.2562 - val_loss: 13.8861 - val_out_stats_loss: 4.8453 - val_out_counts_loss: 2.3138 - val_out_mean_covariance_loss: 71.9783 - val_out_fielding_position_loss: 3.1281
Epoch 6/1000

Epoch 00006: val_loss improved from 13.88606 to 13.53572, saving model to models/bc/shift2/max2016/simple-rnn/1.h5
 - 5s - loss: 13.7522 - out_stats_loss: 4.7808 - out_counts_loss: 2.3671 - out_mean_covariance_loss: 70.5208 - out_fielding_position_loss: 3.0783 - val_loss: 13.5357 - val_out_stats_loss: 4.7732 - val_out_counts_loss: 2.2696 - val_out_mean_covariance_loss: 70.3148 - val_out_fielding_position_loss: 2.9772
Epoch 7/1000

Epoch 00007: val_loss improved from 13.53572 to 13.30982, saving model to models/bc/shift2/max2016/simple-rnn/1.h5
 - 5s - loss: 13.4465 - out_stats_loss: 4.7025 - out_counts_loss: 2.3329 - out_mean_covariance_loss: 69.1294 - out_fielding_position_loss: 2.9546 - val_loss: 13.3098 - val_out_stats_loss: 4.7392 - val_out_counts_loss: 2.2469 - val_out_mean_covariance_loss: 69.3579 - val_out_fielding_position_loss: 2.8559
Epoch 8/1000

Epoch 00008: val_loss improved from 13.30982 to 13.14019, saving model to models/bc/shift2/max2016/simple-rnn/1.h5
 - 5s - loss: 13.2346 - out_stats_loss: 4.6601 - out_counts_loss: 2.3059 - out_mean_covariance_loss: 68.0381 - out_fielding_position_loss: 2.8666 - val_loss: 13.1402 - val_out_stats_loss: 4.7014 - val_out_counts_loss: 2.2454 - val_out_mean_covariance_loss: 68.6850 - val_out_fielding_position_loss: 2.7591
Epoch 9/1000

Epoch 00009: val_loss improved from 13.14019 to 13.05988, saving model to models/bc/shift2/max2016/simple-rnn/1.h5
 - 5s - loss: 13.0253 - out_stats_loss: 4.6056 - out_counts_loss: 2.2963 - out_mean_covariance_loss: 67.1790 - out_fielding_position_loss: 2.7645 - val_loss: 13.0599 - val_out_stats_loss: 4.7057 - val_out_counts_loss: 2.2567 - val_out_mean_covariance_loss: 68.1102 - val_out_fielding_position_loss: 2.6920
Epoch 10/1000

Epoch 00010: val_loss improved from 13.05988 to 12.89178, saving model to models/bc/shift2/max2016/simple-rnn/1.h5
 - 5s - loss: 12.8874 - out_stats_loss: 4.5699 - out_counts_loss: 2.2889 - out_mean_covariance_loss: 66.4333 - out_fielding_position_loss: 2.7069 - val_loss: 12.8918 - val_out_stats_loss: 4.6518 - val_out_counts_loss: 2.2232 - val_out_mean_covariance_loss: 67.6597 - val_out_fielding_position_loss: 2.6338
Epoch 11/1000

Epoch 00011: val_loss improved from 12.89178 to 12.82271, saving model to models/bc/shift2/max2016/simple-rnn/1.h5
 - 5s - loss: 12.7711 - out_stats_loss: 4.5605 - out_counts_loss: 2.2615 - out_mean_covariance_loss: 66.1815 - out_fielding_position_loss: 2.6400 - val_loss: 12.8227 - val_out_stats_loss: 4.6335 - val_out_counts_loss: 2.2270 - val_out_mean_covariance_loss: 67.2865 - val_out_fielding_position_loss: 2.5979
Epoch 12/1000

Epoch 00012: val_loss improved from 12.82271 to 12.74988, saving model to models/bc/shift2/max2016/simple-rnn/1.h5
 - 5s - loss: 12.6955 - out_stats_loss: 4.5429 - out_counts_loss: 2.2392 - out_mean_covariance_loss: 66.1950 - out_fielding_position_loss: 2.6037 - val_loss: 12.7499 - val_out_stats_loss: 4.6131 - val_out_counts_loss: 2.2150 - val_out_mean_covariance_loss: 66.9949 - val_out_fielding_position_loss: 2.5720
Epoch 13/1000

Epoch 00013: val_loss improved from 12.74988 to 12.68209, saving model to models/bc/shift2/max2016/simple-rnn/1.h5
 - 5s - loss: 12.6113 - out_stats_loss: 4.5092 - out_counts_loss: 2.2345 - out_mean_covariance_loss: 65.5684 - out_fielding_position_loss: 2.5892 - val_loss: 12.6821 - val_out_stats_loss: 4.5924 - val_out_counts_loss: 2.2055 - val_out_mean_covariance_loss: 66.7424 - val_out_fielding_position_loss: 2.5471
Epoch 14/1000

Epoch 00014: val_loss did not improve
 - 5s - loss: 12.4747 - out_stats_loss: 4.4810 - out_counts_loss: 2.2103 - out_mean_covariance_loss: 64.8022 - out_fielding_position_loss: 2.5433 - val_loss: 12.6895 - val_out_stats_loss: 4.5925 - val_out_counts_loss: 2.2355 - val_out_mean_covariance_loss: 66.6660 - val_out_fielding_position_loss: 2.5282
Epoch 15/1000

Epoch 00015: val_loss improved from 12.68209 to 12.61577, saving model to models/bc/shift2/max2016/simple-rnn/1.h5
 - 5s - loss: 12.4771 - out_stats_loss: 4.4828 - out_counts_loss: 2.2007 - out_mean_covariance_loss: 65.1793 - out_fielding_position_loss: 2.5346 - val_loss: 12.6158 - val_out_stats_loss: 4.5636 - val_out_counts_loss: 2.2196 - val_out_mean_covariance_loss: 66.3483 - val_out_fielding_position_loss: 2.5151
Epoch 16/1000

Epoch 00016: val_loss improved from 12.61577 to 12.57250, saving model to models/bc/shift2/max2016/simple-rnn/1.h5
 - 5s - loss: 12.4685 - out_stats_loss: 4.4704 - out_counts_loss: 2.2258 - out_mean_covariance_loss: 64.9014 - out_fielding_position_loss: 2.5273 - val_loss: 12.5725 - val_out_stats_loss: 4.5586 - val_out_counts_loss: 2.2046 - val_out_mean_covariance_loss: 66.0909 - val_out_fielding_position_loss: 2.5048
Epoch 17/1000

Epoch 00017: val_loss improved from 12.57250 to 12.51433, saving model to models/bc/shift2/max2016/simple-rnn/1.h5
 - 5s - loss: 12.3557 - out_stats_loss: 4.4337 - out_counts_loss: 2.1845 - out_mean_covariance_loss: 64.5884 - out_fielding_position_loss: 2.5081 - val_loss: 12.5143 - val_out_stats_loss: 4.5256 - val_out_counts_loss: 2.2025 - val_out_mean_covariance_loss: 65.8242 - val_out_fielding_position_loss: 2.4950
Epoch 18/1000

Epoch 00018: val_loss improved from 12.51433 to 12.48898, saving model to models/bc/shift2/max2016/simple-rnn/1.h5
 - 5s - loss: 12.2697 - out_stats_loss: 4.4177 - out_counts_loss: 2.1692 - out_mean_covariance_loss: 64.0182 - out_fielding_position_loss: 2.4820 - val_loss: 12.4890 - val_out_stats_loss: 4.5198 - val_out_counts_loss: 2.1931 - val_out_mean_covariance_loss: 65.8666 - val_out_fielding_position_loss: 2.4827
Epoch 19/1000

Epoch 00019: val_loss improved from 12.48898 to 12.47434, saving model to models/bc/shift2/max2016/simple-rnn/1.h5
 - 5s - loss: 12.2054 - out_stats_loss: 4.3971 - out_counts_loss: 2.1564 - out_mean_covariance_loss: 63.4889 - out_fielding_position_loss: 2.4775 - val_loss: 12.4743 - val_out_stats_loss: 4.5199 - val_out_counts_loss: 2.2022 - val_out_mean_covariance_loss: 65.6018 - val_out_fielding_position_loss: 2.4721
Epoch 20/1000

Epoch 00020: val_loss improved from 12.47434 to 12.45772, saving model to models/bc/shift2/max2016/simple-rnn/1.h5
 - 5s - loss: 12.1050 - out_stats_loss: 4.3582 - out_counts_loss: 2.1370 - out_mean_covariance_loss: 63.1154 - out_fielding_position_loss: 2.4540 - val_loss: 12.4577 - val_out_stats_loss: 4.5060 - val_out_counts_loss: 2.2055 - val_out_mean_covariance_loss: 65.5330 - val_out_fielding_position_loss: 2.4696
Epoch 21/1000

Epoch 00021: val_loss did not improve
 - 5s - loss: 12.0951 - out_stats_loss: 4.3699 - out_counts_loss: 2.1191 - out_mean_covariance_loss: 63.2819 - out_fielding_position_loss: 2.4420 - val_loss: 12.5155 - val_out_stats_loss: 4.5355 - val_out_counts_loss: 2.2420 - val_out_mean_covariance_loss: 65.5929 - val_out_fielding_position_loss: 2.4584
Epoch 22/1000

Epoch 00022: val_loss improved from 12.45772 to 12.40165, saving model to models/bc/shift2/max2016/simple-rnn/1.h5
 - 5s - loss: 12.0867 - out_stats_loss: 4.3642 - out_counts_loss: 2.1220 - out_mean_covariance_loss: 63.2467 - out_fielding_position_loss: 2.4381 - val_loss: 12.4016 - val_out_stats_loss: 4.4908 - val_out_counts_loss: 2.1960 - val_out_mean_covariance_loss: 65.2647 - val_out_fielding_position_loss: 2.4516
Epoch 23/1000

Epoch 00023: val_loss improved from 12.40165 to 12.39927, saving model to models/bc/shift2/max2016/simple-rnn/1.h5
 - 5s - loss: 11.9752 - out_stats_loss: 4.3346 - out_counts_loss: 2.0877 - out_mean_covariance_loss: 62.7454 - out_fielding_position_loss: 2.4157 - val_loss: 12.3993 - val_out_stats_loss: 4.4879 - val_out_counts_loss: 2.2081 - val_out_mean_covariance_loss: 65.1227 - val_out_fielding_position_loss: 2.4472
Epoch 24/1000

Epoch 00024: val_loss improved from 12.39927 to 12.38425, saving model to models/bc/shift2/max2016/simple-rnn/1.h5
 - 5s - loss: 12.0071 - out_stats_loss: 4.3437 - out_counts_loss: 2.1036 - out_mean_covariance_loss: 63.0411 - out_fielding_position_loss: 2.4077 - val_loss: 12.3843 - val_out_stats_loss: 4.4879 - val_out_counts_loss: 2.2016 - val_out_mean_covariance_loss: 65.0413 - val_out_fielding_position_loss: 2.4427
Epoch 25/1000

Epoch 00025: val_loss improved from 12.38425 to 12.35050, saving model to models/bc/shift2/max2016/simple-rnn/1.h5
 - 5s - loss: 11.9578 - out_stats_loss: 4.3374 - out_counts_loss: 2.0986 - out_mean_covariance_loss: 62.8377 - out_fielding_position_loss: 2.3799 - val_loss: 12.3505 - val_out_stats_loss: 4.4713 - val_out_counts_loss: 2.2027 - val_out_mean_covariance_loss: 64.9018 - val_out_fielding_position_loss: 2.4314
Epoch 26/1000

Epoch 00026: val_loss did not improve
 - 5s - loss: 11.8299 - out_stats_loss: 4.2935 - out_counts_loss: 2.0595 - out_mean_covariance_loss: 62.1392 - out_fielding_position_loss: 2.3699 - val_loss: 12.4135 - val_out_stats_loss: 4.5031 - val_out_counts_loss: 2.2291 - val_out_mean_covariance_loss: 65.0394 - val_out_fielding_position_loss: 2.4293
Epoch 27/1000

Epoch 00027: val_loss improved from 12.35050 to 12.31999, saving model to models/bc/shift2/max2016/simple-rnn/1.h5
 - 5s - loss: 11.7959 - out_stats_loss: 4.2934 - out_counts_loss: 2.0479 - out_mean_covariance_loss: 61.9005 - out_fielding_position_loss: 2.3596 - val_loss: 12.3200 - val_out_stats_loss: 4.4686 - val_out_counts_loss: 2.1973 - val_out_mean_covariance_loss: 64.7128 - val_out_fielding_position_loss: 2.4184
Epoch 28/1000

Epoch 00028: val_loss did not improve
 - 5s - loss: 11.8400 - out_stats_loss: 4.3106 - out_counts_loss: 2.0745 - out_mean_covariance_loss: 62.2350 - out_fielding_position_loss: 2.3432 - val_loss: 12.4456 - val_out_stats_loss: 4.5089 - val_out_counts_loss: 2.2683 - val_out_mean_covariance_loss: 64.9682 - val_out_fielding_position_loss: 2.4200
Epoch 29/1000

Epoch 00029: val_loss improved from 12.31999 to 12.29681, saving model to models/bc/shift2/max2016/simple-rnn/1.h5
 - 5s - loss: 11.7999 - out_stats_loss: 4.3057 - out_counts_loss: 2.0644 - out_mean_covariance_loss: 61.8938 - out_fielding_position_loss: 2.3351 - val_loss: 12.2968 - val_out_stats_loss: 4.4712 - val_out_counts_loss: 2.1883 - val_out_mean_covariance_loss: 64.6599 - val_out_fielding_position_loss: 2.4043
Epoch 30/1000

Epoch 00030: val_loss improved from 12.29681 to 12.27521, saving model to models/bc/shift2/max2016/simple-rnn/1.h5
 - 5s - loss: 11.7018 - out_stats_loss: 4.2749 - out_counts_loss: 2.0343 - out_mean_covariance_loss: 61.5320 - out_fielding_position_loss: 2.3159 - val_loss: 12.2752 - val_out_stats_loss: 4.4518 - val_out_counts_loss: 2.1956 - val_out_mean_covariance_loss: 64.4675 - val_out_fielding_position_loss: 2.4045
Epoch 31/1000

Epoch 00031: val_loss did not improve
 - 5s - loss: 11.6591 - out_stats_loss: 4.2697 - out_counts_loss: 1.9870 - out_mean_covariance_loss: 61.9000 - out_fielding_position_loss: 2.3074 - val_loss: 12.3345 - val_out_stats_loss: 4.4781 - val_out_counts_loss: 2.2306 - val_out_mean_covariance_loss: 64.5604 - val_out_fielding_position_loss: 2.3978
Epoch 32/1000

Epoch 00032: val_loss did not improve
 - 5s - loss: 11.6034 - out_stats_loss: 4.2498 - out_counts_loss: 1.9934 - out_mean_covariance_loss: 61.2334 - out_fielding_position_loss: 2.2985 - val_loss: 12.2892 - val_out_stats_loss: 4.4565 - val_out_counts_loss: 2.2141 - val_out_mean_covariance_loss: 64.4265 - val_out_fielding_position_loss: 2.3972
Epoch 33/1000

Epoch 00033: val_loss did not improve
 - 5s - loss: 11.5551 - out_stats_loss: 4.2421 - out_counts_loss: 1.9705 - out_mean_covariance_loss: 61.2244 - out_fielding_position_loss: 2.2813 - val_loss: 12.3126 - val_out_stats_loss: 4.4735 - val_out_counts_loss: 2.2241 - val_out_mean_covariance_loss: 64.4615 - val_out_fielding_position_loss: 2.3919
Epoch 34/1000

Epoch 00034: val_loss did not improve
 - 5s - loss: 11.5759 - out_stats_loss: 4.2552 - out_counts_loss: 1.9718 - out_mean_covariance_loss: 61.4402 - out_fielding_position_loss: 2.2768 - val_loss: 12.3228 - val_out_stats_loss: 4.4667 - val_out_counts_loss: 2.2437 - val_out_mean_covariance_loss: 64.4705 - val_out_fielding_position_loss: 2.3889
Epoch 35/1000

Epoch 00035: val_loss improved from 12.27521 to 12.26823, saving model to models/bc/shift2/max2016/simple-rnn/1.h5
 - 5s - loss: 11.4733 - out_stats_loss: 4.2225 - out_counts_loss: 1.9536 - out_mean_covariance_loss: 60.6038 - out_fielding_position_loss: 2.2670 - val_loss: 12.2682 - val_out_stats_loss: 4.4506 - val_out_counts_loss: 2.2204 - val_out_mean_covariance_loss: 64.3260 - val_out_fielding_position_loss: 2.3809
Epoch 36/1000

Epoch 00036: val_loss did not improve
 - 5s - loss: 11.4691 - out_stats_loss: 4.2300 - out_counts_loss: 1.9380 - out_mean_covariance_loss: 60.8907 - out_fielding_position_loss: 2.2566 - val_loss: 12.3606 - val_out_stats_loss: 4.4738 - val_out_counts_loss: 2.2777 - val_out_mean_covariance_loss: 64.4469 - val_out_fielding_position_loss: 2.3867
Epoch 37/1000

Epoch 00037: val_loss did not improve
 - 5s - loss: 11.4438 - out_stats_loss: 4.2277 - out_counts_loss: 1.9350 - out_mean_covariance_loss: 60.8596 - out_fielding_position_loss: 2.2381 - val_loss: 12.3338 - val_out_stats_loss: 4.4637 - val_out_counts_loss: 2.2702 - val_out_mean_covariance_loss: 64.3125 - val_out_fielding_position_loss: 2.3843
Epoch 38/1000

Epoch 00038: val_loss did not improve
 - 5s - loss: 11.3415 - out_stats_loss: 4.1927 - out_counts_loss: 1.9095 - out_mean_covariance_loss: 60.2760 - out_fielding_position_loss: 2.2256 - val_loss: 12.2794 - val_out_stats_loss: 4.4574 - val_out_counts_loss: 2.2436 - val_out_mean_covariance_loss: 64.2001 - val_out_fielding_position_loss: 2.3683
Epoch 39/1000

Epoch 00039: val_loss did not improve
 - 5s - loss: 11.3566 - out_stats_loss: 4.2075 - out_counts_loss: 1.9152 - out_mean_covariance_loss: 60.3363 - out_fielding_position_loss: 2.2170 - val_loss: 12.4025 - val_out_stats_loss: 4.5014 - val_out_counts_loss: 2.3098 - val_out_mean_covariance_loss: 64.4446 - val_out_fielding_position_loss: 2.3691
Epoch 40/1000

Epoch 00040: val_loss improved from 12.26823 to 12.25868, saving model to models/bc/shift2/max2016/simple-rnn/1.h5
 - 5s - loss: 11.2940 - out_stats_loss: 4.1912 - out_counts_loss: 1.8874 - out_mean_covariance_loss: 60.3162 - out_fielding_position_loss: 2.1996 - val_loss: 12.2587 - val_out_stats_loss: 4.4579 - val_out_counts_loss: 2.2339 - val_out_mean_covariance_loss: 64.1040 - val_out_fielding_position_loss: 2.3617
Epoch 41/1000

Epoch 00041: val_loss did not improve
 - 5s - loss: 11.2601 - out_stats_loss: 4.1779 - out_counts_loss: 1.8910 - out_mean_covariance_loss: 59.8766 - out_fielding_position_loss: 2.1974 - val_loss: 12.2637 - val_out_stats_loss: 4.4614 - val_out_counts_loss: 2.2422 - val_out_mean_covariance_loss: 64.0614 - val_out_fielding_position_loss: 2.3570
Epoch 42/1000

Epoch 00042: val_loss did not improve
 - 5s - loss: 11.2625 - out_stats_loss: 4.1987 - out_counts_loss: 1.8760 - out_mean_covariance_loss: 60.3039 - out_fielding_position_loss: 2.1726 - val_loss: 12.2986 - val_out_stats_loss: 4.4690 - val_out_counts_loss: 2.2719 - val_out_mean_covariance_loss: 64.0553 - val_out_fielding_position_loss: 2.3549
Epoch 43/1000

Epoch 00043: val_loss improved from 12.25868 to 12.25138, saving model to models/bc/shift2/max2016/simple-rnn/1.h5
 - 5s - loss: 11.2118 - out_stats_loss: 4.1867 - out_counts_loss: 1.8596 - out_mean_covariance_loss: 59.8528 - out_fielding_position_loss: 2.1728 - val_loss: 12.2514 - val_out_stats_loss: 4.4497 - val_out_counts_loss: 2.2562 - val_out_mean_covariance_loss: 63.9302 - val_out_fielding_position_loss: 2.3490
Epoch 44/1000

Epoch 00044: val_loss did not improve
 - 5s - loss: 11.1355 - out_stats_loss: 4.1682 - out_counts_loss: 1.8374 - out_mean_covariance_loss: 59.5320 - out_fielding_position_loss: 2.1532 - val_loss: 12.2708 - val_out_stats_loss: 4.4565 - val_out_counts_loss: 2.2726 - val_out_mean_covariance_loss: 63.9685 - val_out_fielding_position_loss: 2.3432
Epoch 45/1000

Epoch 00045: val_loss did not improve
 - 5s - loss: 11.1399 - out_stats_loss: 4.1767 - out_counts_loss: 1.8343 - out_mean_covariance_loss: 59.8523 - out_fielding_position_loss: 2.1364 - val_loss: 12.3101 - val_out_stats_loss: 4.4734 - val_out_counts_loss: 2.2832 - val_out_mean_covariance_loss: 64.1656 - val_out_fielding_position_loss: 2.3453
Epoch 46/1000

Epoch 00046: val_loss did not improve
 - 5s - loss: 11.1320 - out_stats_loss: 4.1693 - out_counts_loss: 1.8462 - out_mean_covariance_loss: 59.6708 - out_fielding_position_loss: 2.1330 - val_loss: 12.2765 - val_out_stats_loss: 4.4558 - val_out_counts_loss: 2.2885 - val_out_mean_covariance_loss: 63.8524 - val_out_fielding_position_loss: 2.3396
Epoch 47/1000

Epoch 00047: val_loss did not improve
 - 5s - loss: 11.0312 - out_stats_loss: 4.1382 - out_counts_loss: 1.8032 - out_mean_covariance_loss: 59.3529 - out_fielding_position_loss: 2.1220 - val_loss: 12.3204 - val_out_stats_loss: 4.4751 - val_out_counts_loss: 2.3063 - val_out_mean_covariance_loss: 63.9510 - val_out_fielding_position_loss: 2.3415
Epoch 48/1000

Epoch 00048: val_loss did not improve
 - 5s - loss: 10.9956 - out_stats_loss: 4.1358 - out_counts_loss: 1.7988 - out_mean_covariance_loss: 59.1475 - out_fielding_position_loss: 2.1036 - val_loss: 12.4339 - val_out_stats_loss: 4.5033 - val_out_counts_loss: 2.3633 - val_out_mean_covariance_loss: 64.3946 - val_out_fielding_position_loss: 2.3476
Epoch 49/1000

Epoch 00049: val_loss did not improve
 - 5s - loss: 10.9858 - out_stats_loss: 4.1268 - out_counts_loss: 1.8057 - out_mean_covariance_loss: 58.9587 - out_fielding_position_loss: 2.1054 - val_loss: 12.2954 - val_out_stats_loss: 4.4604 - val_out_counts_loss: 2.3114 - val_out_mean_covariance_loss: 63.8160 - val_out_fielding_position_loss: 2.3328
Epoch 50/1000

Epoch 00050: val_loss did not improve
 - 5s - loss: 11.0123 - out_stats_loss: 4.1587 - out_counts_loss: 1.7894 - out_mean_covariance_loss: 59.5968 - out_fielding_position_loss: 2.0844 - val_loss: 12.3267 - val_out_stats_loss: 4.4726 - val_out_counts_loss: 2.3205 - val_out_mean_covariance_loss: 63.9634 - val_out_fielding_position_loss: 2.3354
Epoch 51/1000

Epoch 00051: val_loss did not improve
 - 5s - loss: 10.9472 - out_stats_loss: 4.1351 - out_counts_loss: 1.7801 - out_mean_covariance_loss: 58.8515 - out_fielding_position_loss: 2.0894 - val_loss: 12.2959 - val_out_stats_loss: 4.4634 - val_out_counts_loss: 2.3177 - val_out_mean_covariance_loss: 63.8194 - val_out_fielding_position_loss: 2.3239
Epoch 52/1000

Epoch 00052: val_loss did not improve
 - 5s - loss: 10.8898 - out_stats_loss: 4.1172 - out_counts_loss: 1.7681 - out_mean_covariance_loss: 58.8672 - out_fielding_position_loss: 2.0612 - val_loss: 12.3523 - val_out_stats_loss: 4.4812 - val_out_counts_loss: 2.3520 - val_out_mean_covariance_loss: 63.9298 - val_out_fielding_position_loss: 2.3227
Epoch 53/1000

Epoch 00053: val_loss did not improve
 - 5s - loss: 10.8312 - out_stats_loss: 4.0839 - out_counts_loss: 1.7645 - out_mean_covariance_loss: 58.1714 - out_fielding_position_loss: 2.0742 - val_loss: 12.3629 - val_out_stats_loss: 4.4747 - val_out_counts_loss: 2.3635 - val_out_mean_covariance_loss: 63.8773 - val_out_fielding_position_loss: 2.3309
Epoch 54/1000

Epoch 00054: val_loss did not improve
 - 5s - loss: 10.8012 - out_stats_loss: 4.0978 - out_counts_loss: 1.7392 - out_mean_covariance_loss: 58.3318 - out_fielding_position_loss: 2.0476 - val_loss: 12.3594 - val_out_stats_loss: 4.4712 - val_out_counts_loss: 2.3592 - val_out_mean_covariance_loss: 64.1853 - val_out_fielding_position_loss: 2.3197
Epoch 55/1000

Epoch 00055: val_loss did not improve
 - 5s - loss: 10.8389 - out_stats_loss: 4.1156 - out_counts_loss: 1.7393 - out_mean_covariance_loss: 58.8934 - out_fielding_position_loss: 2.0394 - val_loss: 12.3898 - val_out_stats_loss: 4.4832 - val_out_counts_loss: 2.3821 - val_out_mean_covariance_loss: 64.1968 - val_out_fielding_position_loss: 2.3147
Epoch 56/1000

Epoch 00056: val_loss did not improve
 - 5s - loss: 10.8576 - out_stats_loss: 4.1389 - out_counts_loss: 1.7417 - out_mean_covariance_loss: 58.8692 - out_fielding_position_loss: 2.0336 - val_loss: 12.4207 - val_out_stats_loss: 4.5181 - val_out_counts_loss: 2.3790 - val_out_mean_covariance_loss: 63.9140 - val_out_fielding_position_loss: 2.3279
Epoch 57/1000

Epoch 00057: val_loss did not improve
 - 5s - loss: 10.8198 - out_stats_loss: 4.1232 - out_counts_loss: 1.7375 - out_mean_covariance_loss: 58.5421 - out_fielding_position_loss: 2.0320 - val_loss: 12.3246 - val_out_stats_loss: 4.4699 - val_out_counts_loss: 2.3521 - val_out_mean_covariance_loss: 63.8090 - val_out_fielding_position_loss: 2.3122
Epoch 58/1000

Epoch 00058: val_loss did not improve
 - 5s - loss: 10.7194 - out_stats_loss: 4.0712 - out_counts_loss: 1.7260 - out_mean_covariance_loss: 57.9593 - out_fielding_position_loss: 2.0243 - val_loss: 12.3572 - val_out_stats_loss: 4.4768 - val_out_counts_loss: 2.3747 - val_out_mean_covariance_loss: 63.8681 - val_out_fielding_position_loss: 2.3123
Epoch 59/1000

Epoch 00059: val_loss did not improve
 - 5s - loss: 10.7103 - out_stats_loss: 4.0713 - out_counts_loss: 1.7237 - out_mean_covariance_loss: 57.9766 - out_fielding_position_loss: 2.0164 - val_loss: 12.3265 - val_out_stats_loss: 4.4583 - val_out_counts_loss: 2.3646 - val_out_mean_covariance_loss: 63.8766 - val_out_fielding_position_loss: 2.3099
Epoch 60/1000

Epoch 00060: val_loss did not improve
 - 5s - loss: 10.6234 - out_stats_loss: 4.0528 - out_counts_loss: 1.7055 - out_mean_covariance_loss: 57.2684 - out_fielding_position_loss: 2.0017 - val_loss: 12.3271 - val_out_stats_loss: 4.4674 - val_out_counts_loss: 2.3734 - val_out_mean_covariance_loss: 63.6749 - val_out_fielding_position_loss: 2.3025
Epoch 61/1000

Epoch 00061: val_loss did not improve
 - 5s - loss: 10.6262 - out_stats_loss: 4.0650 - out_counts_loss: 1.6913 - out_mean_covariance_loss: 57.6586 - out_fielding_position_loss: 1.9870 - val_loss: 12.3618 - val_out_stats_loss: 4.4741 - val_out_counts_loss: 2.3887 - val_out_mean_covariance_loss: 63.9461 - val_out_fielding_position_loss: 2.3017
Epoch 62/1000

Epoch 00062: val_loss did not improve
 - 5s - loss: 10.5948 - out_stats_loss: 4.0586 - out_counts_loss: 1.6868 - out_mean_covariance_loss: 57.5291 - out_fielding_position_loss: 1.9729 - val_loss: 12.4295 - val_out_stats_loss: 4.4906 - val_out_counts_loss: 2.4302 - val_out_mean_covariance_loss: 63.9695 - val_out_fielding_position_loss: 2.3102
Epoch 63/1000

Epoch 00063: val_loss did not improve
 - 5s - loss: 10.5596 - out_stats_loss: 4.0412 - out_counts_loss: 1.6799 - out_mean_covariance_loss: 56.9794 - out_fielding_position_loss: 1.9895 - val_loss: 12.3575 - val_out_stats_loss: 4.4765 - val_out_counts_loss: 2.3912 - val_out_mean_covariance_loss: 63.7490 - val_out_fielding_position_loss: 2.3023
Epoch 64/1000

Epoch 00064: val_loss did not improve
 - 5s - loss: 10.5779 - out_stats_loss: 4.0528 - out_counts_loss: 1.6818 - out_mean_covariance_loss: 57.4453 - out_fielding_position_loss: 1.9710 - val_loss: 12.3919 - val_out_stats_loss: 4.4822 - val_out_counts_loss: 2.4123 - val_out_mean_covariance_loss: 63.9368 - val_out_fielding_position_loss: 2.3006
Epoch 65/1000

Epoch 00065: val_loss did not improve
 - 5s - loss: 10.5152 - out_stats_loss: 4.0481 - out_counts_loss: 1.6629 - out_mean_covariance_loss: 57.0815 - out_fielding_position_loss: 1.9501 - val_loss: 12.4226 - val_out_stats_loss: 4.4813 - val_out_counts_loss: 2.4390 - val_out_mean_covariance_loss: 63.9431 - val_out_fielding_position_loss: 2.3052
Epoch 66/1000

Epoch 00066: val_loss did not improve
 - 5s - loss: 10.5281 - out_stats_loss: 4.0435 - out_counts_loss: 1.6731 - out_mean_covariance_loss: 57.2562 - out_fielding_position_loss: 1.9487 - val_loss: 12.3847 - val_out_stats_loss: 4.4809 - val_out_counts_loss: 2.4156 - val_out_mean_covariance_loss: 63.8963 - val_out_fielding_position_loss: 2.2934
Epoch 67/1000

Epoch 00067: val_loss did not improve
 - 5s - loss: 10.5027 - out_stats_loss: 4.0415 - out_counts_loss: 1.6560 - out_mean_covariance_loss: 57.2704 - out_fielding_position_loss: 1.9417 - val_loss: 12.4109 - val_out_stats_loss: 4.4784 - val_out_counts_loss: 2.4332 - val_out_mean_covariance_loss: 63.8460 - val_out_fielding_position_loss: 2.3071
Epoch 68/1000

Epoch 00068: val_loss did not improve
 - 5s - loss: 10.4697 - out_stats_loss: 4.0359 - out_counts_loss: 1.6481 - out_mean_covariance_loss: 57.1357 - out_fielding_position_loss: 1.9289 - val_loss: 12.4846 - val_out_stats_loss: 4.5064 - val_out_counts_loss: 2.4764 - val_out_mean_covariance_loss: 64.0750 - val_out_fielding_position_loss: 2.2980
Epoch 69/1000

Epoch 00069: val_loss did not improve
 - 5s - loss: 10.4778 - out_stats_loss: 4.0419 - out_counts_loss: 1.6462 - out_mean_covariance_loss: 57.2548 - out_fielding_position_loss: 1.9269 - val_loss: 12.3695 - val_out_stats_loss: 4.4702 - val_out_counts_loss: 2.4210 - val_out_mean_covariance_loss: 63.7818 - val_out_fielding_position_loss: 2.2892
Epoch 70/1000

Epoch 00070: val_loss did not improve
 - 5s - loss: 10.4446 - out_stats_loss: 4.0334 - out_counts_loss: 1.6414 - out_mean_covariance_loss: 57.0399 - out_fielding_position_loss: 1.9178 - val_loss: 12.3967 - val_out_stats_loss: 4.4850 - val_out_counts_loss: 2.4378 - val_out_mean_covariance_loss: 63.7358 - val_out_fielding_position_loss: 2.2871
Epoch 71/1000

Epoch 00071: val_loss did not improve
 - 5s - loss: 10.3627 - out_stats_loss: 3.9937 - out_counts_loss: 1.6308 - out_mean_covariance_loss: 56.4400 - out_fielding_position_loss: 1.9162 - val_loss: 12.4065 - val_out_stats_loss: 4.4873 - val_out_counts_loss: 2.4345 - val_out_mean_covariance_loss: 63.9320 - val_out_fielding_position_loss: 2.2881
Epoch 72/1000

Epoch 00072: val_loss did not improve
 - 5s - loss: 10.3818 - out_stats_loss: 4.0153 - out_counts_loss: 1.6333 - out_mean_covariance_loss: 56.5018 - out_fielding_position_loss: 1.9081 - val_loss: 12.4230 - val_out_stats_loss: 4.4880 - val_out_counts_loss: 2.4550 - val_out_mean_covariance_loss: 63.8141 - val_out_fielding_position_loss: 2.2893
Epoch 73/1000

Epoch 00073: val_loss did not improve
 - 5s - loss: 10.3052 - out_stats_loss: 3.9870 - out_counts_loss: 1.6178 - out_mean_covariance_loss: 56.2726 - out_fielding_position_loss: 1.8867 - val_loss: 12.4105 - val_out_stats_loss: 4.4837 - val_out_counts_loss: 2.4562 - val_out_mean_covariance_loss: 63.8690 - val_out_fielding_position_loss: 2.2771
Epoch 74/1000

Epoch 00074: val_loss did not improve
 - 5s - loss: 10.2814 - out_stats_loss: 3.9853 - out_counts_loss: 1.6080 - out_mean_covariance_loss: 56.0668 - out_fielding_position_loss: 1.8848 - val_loss: 12.4088 - val_out_stats_loss: 4.4829 - val_out_counts_loss: 2.4604 - val_out_mean_covariance_loss: 63.8364 - val_out_fielding_position_loss: 2.2737
Epoch 75/1000

Epoch 00075: val_loss did not improve
 - 5s - loss: 10.2861 - out_stats_loss: 3.9902 - out_counts_loss: 1.6078 - out_mean_covariance_loss: 56.1075 - out_fielding_position_loss: 1.8827 - val_loss: 12.4729 - val_out_stats_loss: 4.4991 - val_out_counts_loss: 2.4872 - val_out_mean_covariance_loss: 64.0542 - val_out_fielding_position_loss: 2.2839
Epoch 76/1000

Epoch 00076: val_loss did not improve
 - 5s - loss: 10.2337 - out_stats_loss: 3.9779 - out_counts_loss: 1.5891 - out_mean_covariance_loss: 55.9266 - out_fielding_position_loss: 1.8703 - val_loss: 12.4309 - val_out_stats_loss: 4.4843 - val_out_counts_loss: 2.4705 - val_out_mean_covariance_loss: 63.9625 - val_out_fielding_position_loss: 2.2780
Epoch 77/1000

Epoch 00077: val_loss did not improve
 - 5s - loss: 10.2589 - out_stats_loss: 3.9819 - out_counts_loss: 1.5959 - out_mean_covariance_loss: 56.1411 - out_fielding_position_loss: 1.8740 - val_loss: 12.4823 - val_out_stats_loss: 4.4947 - val_out_counts_loss: 2.5005 - val_out_mean_covariance_loss: 64.1197 - val_out_fielding_position_loss: 2.2811
Epoch 78/1000

Epoch 00078: val_loss did not improve
 - 5s - loss: 10.2022 - out_stats_loss: 3.9784 - out_counts_loss: 1.5736 - out_mean_covariance_loss: 55.9922 - out_fielding_position_loss: 1.8505 - val_loss: 12.4803 - val_out_stats_loss: 4.4983 - val_out_counts_loss: 2.4868 - val_out_mean_covariance_loss: 64.2073 - val_out_fielding_position_loss: 2.2848
Epoch 79/1000

Epoch 00079: val_loss did not improve
 - 5s - loss: 10.1962 - out_stats_loss: 3.9737 - out_counts_loss: 1.5730 - out_mean_covariance_loss: 56.0061 - out_fielding_position_loss: 1.8492 - val_loss: 12.5319 - val_out_stats_loss: 4.5335 - val_out_counts_loss: 2.5088 - val_out_mean_covariance_loss: 64.2461 - val_out_fielding_position_loss: 2.2772
Epoch 80/1000

Epoch 00080: val_loss did not improve
 - 5s - loss: 10.2334 - out_stats_loss: 3.9830 - out_counts_loss: 1.5948 - out_mean_covariance_loss: 56.0320 - out_fielding_position_loss: 1.8541 - val_loss: 12.4825 - val_out_stats_loss: 4.4970 - val_out_counts_loss: 2.5000 - val_out_mean_covariance_loss: 64.1821 - val_out_fielding_position_loss: 2.2763
Epoch 81/1000

Epoch 00081: val_loss did not improve
 - 5s - loss: 10.1334 - out_stats_loss: 3.9587 - out_counts_loss: 1.5733 - out_mean_covariance_loss: 55.3465 - out_fielding_position_loss: 1.8341 - val_loss: 12.4418 - val_out_stats_loss: 4.4862 - val_out_counts_loss: 2.4873 - val_out_mean_covariance_loss: 63.9915 - val_out_fielding_position_loss: 2.2688
Epoch 82/1000

Epoch 00082: val_loss did not improve
 - 5s - loss: 10.1093 - out_stats_loss: 3.9514 - out_counts_loss: 1.5626 - out_mean_covariance_loss: 55.2532 - out_fielding_position_loss: 1.8326 - val_loss: 12.4613 - val_out_stats_loss: 4.4941 - val_out_counts_loss: 2.4927 - val_out_mean_covariance_loss: 64.0268 - val_out_fielding_position_loss: 2.2732
Epoch 83/1000

Epoch 00083: val_loss did not improve
 - 5s - loss: 10.1475 - out_stats_loss: 3.9786 - out_counts_loss: 1.5574 - out_mean_covariance_loss: 55.7679 - out_fielding_position_loss: 1.8232 - val_loss: 12.4751 - val_out_stats_loss: 4.4924 - val_out_counts_loss: 2.5059 - val_out_mean_covariance_loss: 64.0568 - val_out_fielding_position_loss: 2.2739
Epoch 84/1000

Epoch 00084: val_loss did not improve
 - 5s - loss: 10.1059 - out_stats_loss: 3.9515 - out_counts_loss: 1.5679 - out_mean_covariance_loss: 55.2695 - out_fielding_position_loss: 1.8230 - val_loss: 12.4618 - val_out_stats_loss: 4.4972 - val_out_counts_loss: 2.4937 - val_out_mean_covariance_loss: 64.1227 - val_out_fielding_position_loss: 2.2648
Epoch 85/1000

Epoch 00085: val_loss did not improve
 - 5s - loss: 10.1337 - out_stats_loss: 3.9671 - out_counts_loss: 1.5596 - out_mean_covariance_loss: 55.7265 - out_fielding_position_loss: 1.8207 - val_loss: 12.5596 - val_out_stats_loss: 4.5147 - val_out_counts_loss: 2.5394 - val_out_mean_covariance_loss: 64.4136 - val_out_fielding_position_loss: 2.2847
Epoch 86/1000

Epoch 00086: val_loss did not improve
 - 5s - loss: 10.0351 - out_stats_loss: 3.9270 - out_counts_loss: 1.5537 - out_mean_covariance_loss: 54.9759 - out_fielding_position_loss: 1.8057 - val_loss: 12.4733 - val_out_stats_loss: 4.4920 - val_out_counts_loss: 2.5069 - val_out_mean_covariance_loss: 64.2087 - val_out_fielding_position_loss: 2.2640
Epoch 87/1000

Epoch 00087: val_loss did not improve
 - 5s - loss: 10.0277 - out_stats_loss: 3.9414 - out_counts_loss: 1.5404 - out_mean_covariance_loss: 55.0295 - out_fielding_position_loss: 1.7943 - val_loss: 12.5469 - val_out_stats_loss: 4.5166 - val_out_counts_loss: 2.5433 - val_out_mean_covariance_loss: 64.3370 - val_out_fielding_position_loss: 2.2701
Epoch 88/1000

Epoch 00088: val_loss did not improve
 - 5s - loss: 10.0194 - out_stats_loss: 3.9371 - out_counts_loss: 1.5320 - out_mean_covariance_loss: 55.1524 - out_fielding_position_loss: 1.7926 - val_loss: 12.5107 - val_out_stats_loss: 4.4990 - val_out_counts_loss: 2.5198 - val_out_mean_covariance_loss: 64.4075 - val_out_fielding_position_loss: 2.2716
Epoch 89/1000

Epoch 00089: val_loss did not improve
 - 5s - loss: 10.0203 - out_stats_loss: 3.9459 - out_counts_loss: 1.5248 - out_mean_covariance_loss: 55.2323 - out_fielding_position_loss: 1.7879 - val_loss: 12.7293 - val_out_stats_loss: 4.5676 - val_out_counts_loss: 2.6136 - val_out_mean_covariance_loss: 65.1283 - val_out_fielding_position_loss: 2.2918
Epoch 90/1000

Epoch 00090: val_loss did not improve
 - 5s - loss: 9.9860 - out_stats_loss: 3.9326 - out_counts_loss: 1.5279 - out_mean_covariance_loss: 55.0629 - out_fielding_position_loss: 1.7724 - val_loss: 12.5431 - val_out_stats_loss: 4.5087 - val_out_counts_loss: 2.5300 - val_out_mean_covariance_loss: 64.6512 - val_out_fielding_position_loss: 2.2719
Epoch 91/1000

Epoch 00091: val_loss did not improve
 - 5s - loss: 9.9604 - out_stats_loss: 3.9299 - out_counts_loss: 1.5056 - out_mean_covariance_loss: 54.9208 - out_fielding_position_loss: 1.7789 - val_loss: 12.5503 - val_out_stats_loss: 4.5048 - val_out_counts_loss: 2.5579 - val_out_mean_covariance_loss: 64.4436 - val_out_fielding_position_loss: 2.2655
Epoch 92/1000

Epoch 00092: val_loss did not improve
 - 5s - loss: 9.9826 - out_stats_loss: 3.9293 - out_counts_loss: 1.5271 - out_mean_covariance_loss: 55.0371 - out_fielding_position_loss: 1.7743 - val_loss: 12.5475 - val_out_stats_loss: 4.5200 - val_out_counts_loss: 2.5323 - val_out_mean_covariance_loss: 64.4408 - val_out_fielding_position_loss: 2.2731
Epoch 93/1000

Epoch 00093: val_loss did not improve
 - 5s - loss: 9.9707 - out_stats_loss: 3.9363 - out_counts_loss: 1.5223 - out_mean_covariance_loss: 55.0703 - out_fielding_position_loss: 1.7587 - val_loss: 12.6750 - val_out_stats_loss: 4.5419 - val_out_counts_loss: 2.5995 - val_out_mean_covariance_loss: 64.8561 - val_out_fielding_position_loss: 2.2908
/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Years: [1958,2016]
Shift: 2
Fold: 4
Training into models/bc/shift2/max2016/simple-rnn/1.h5
/usr/local/lib/python3.5/dist-packages/keras/legacy/layers.py:533: UserWarning: The `MaxoutDense` layer is deprecated and will be removed after 06/2017.
  warnings.warn('The `MaxoutDense` layer is deprecated '
