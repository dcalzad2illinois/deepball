__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
in_age (InputLayer)             (None, None, 2)      0                                            
__________________________________________________________________________________________________
in_bio (InputLayer)             (None, None, 7)      0                                            
__________________________________________________________________________________________________
in_fielding_position (InputLaye (None, None, 2)      0                                            
__________________________________________________________________________________________________
in_out_fielding_position (Input (None, None, 12)     0                                            
__________________________________________________________________________________________________
in_out_league_offense (InputLay (None, None, 9)      0                                            
__________________________________________________________________________________________________
in_out_park_factors (InputLayer (None, None, 8)      0                                            
__________________________________________________________________________________________________
in_out_plate_discipline (InputL (None, None, 8)      0                                            
__________________________________________________________________________________________________
in_out_running (InputLayer)     (None, None, 18)     0                                            
__________________________________________________________________________________________________
in_out_saber (InputLayer)       (None, None, 14)     0                                            
__________________________________________________________________________________________________
in_out_stats_extended (InputLay (None, None, 36)     0                                            
__________________________________________________________________________________________________
in_park_factors (InputLayer)    (None, None, 8)      0                                            
__________________________________________________________________________________________________
masked_in_age (Masking)         (None, None, 2)      0           in_age[0][0]                     
__________________________________________________________________________________________________
masked_in_bio (Masking)         (None, None, 7)      0           in_bio[0][0]                     
__________________________________________________________________________________________________
masked_in_fielding_position (Ma (None, None, 2)      0           in_fielding_position[0][0]       
__________________________________________________________________________________________________
masked_in_out_fielding_position (None, None, 12)     0           in_out_fielding_position[0][0]   
__________________________________________________________________________________________________
masked_in_out_league_offense (M (None, None, 9)      0           in_out_league_offense[0][0]      
__________________________________________________________________________________________________
masked_in_out_park_factors (Mas (None, None, 8)      0           in_out_park_factors[0][0]        
__________________________________________________________________________________________________
masked_in_out_plate_discipline  (None, None, 8)      0           in_out_plate_discipline[0][0]    
__________________________________________________________________________________________________
masked_in_out_running (Masking) (None, None, 18)     0           in_out_running[0][0]             
__________________________________________________________________________________________________
masked_in_out_saber (Masking)   (None, None, 14)     0           in_out_saber[0][0]               
__________________________________________________________________________________________________
masked_in_out_stats_extended (M (None, None, 36)     0           in_out_stats_extended[0][0]      
__________________________________________________________________________________________________
masked_in_park_factors (Masking (None, None, 8)      0           in_park_factors[0][0]            
__________________________________________________________________________________________________
time_distributed_9 (TimeDistrib (None, None, 1)      0           masked_in_age[0][0]              
__________________________________________________________________________________________________
time_distributed_4 (TimeDistrib (None, None, 6)      0           masked_in_bio[0][0]              
__________________________________________________________________________________________________
time_distributed_1 (TimeDistrib (None, None, 1)      0           masked_in_fielding_position[0][0]
__________________________________________________________________________________________________
time_distributed_11 (TimeDistri (None, None, 11)     0           masked_in_out_fielding_position[0
__________________________________________________________________________________________________
time_distributed_10 (TimeDistri (None, None, 8)      0           masked_in_out_league_offense[0][0
__________________________________________________________________________________________________
time_distributed_7 (TimeDistrib (None, None, 7)      0           masked_in_out_park_factors[0][0] 
__________________________________________________________________________________________________
time_distributed_8 (TimeDistrib (None, None, 7)      0           masked_in_out_plate_discipline[0]
__________________________________________________________________________________________________
time_distributed_3 (TimeDistrib (None, None, 17)     0           masked_in_out_running[0][0]      
__________________________________________________________________________________________________
time_distributed_5 (TimeDistrib (None, None, 13)     0           masked_in_out_saber[0][0]        
__________________________________________________________________________________________________
time_distributed_2 (TimeDistrib (None, None, 35)     0           masked_in_out_stats_extended[0][0
__________________________________________________________________________________________________
time_distributed_6 (TimeDistrib (None, None, 7)      0           masked_in_park_factors[0][0]     
__________________________________________________________________________________________________
norm_in_age (BatchNormalization (None, None, 1)      4           time_distributed_9[0][0]         
__________________________________________________________________________________________________
norm_in_bio (BatchNormalization (None, None, 6)      24          time_distributed_4[0][0]         
__________________________________________________________________________________________________
norm_in_fielding_position (Batc (None, None, 1)      4           time_distributed_1[0][0]         
__________________________________________________________________________________________________
norm_in_out_fielding_position ( (None, None, 11)     44          time_distributed_11[0][0]        
__________________________________________________________________________________________________
norm_in_out_league_offense (Bat (None, None, 8)      32          time_distributed_10[0][0]        
__________________________________________________________________________________________________
norm_in_out_park_factors (Batch (None, None, 7)      28          time_distributed_7[0][0]         
__________________________________________________________________________________________________
norm_in_out_plate_discipline (B (None, None, 7)      28          time_distributed_8[0][0]         
__________________________________________________________________________________________________2018-02-07 09:12:10.872057: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-02-07 09:12:17.628640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: eca0:00:00.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2018-02-07 09:12:17.628688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: eca0:00:00.0, compute capability: 3.7)

norm_in_out_running (BatchNorma (None, None, 17)     68          time_distributed_3[0][0]         
__________________________________________________________________________________________________
norm_in_out_saber (BatchNormali (None, None, 13)     52          time_distributed_5[0][0]         
__________________________________________________________________________________________________
norm_in_out_stats_extended (Bat (None, None, 35)     140         time_distributed_2[0][0]         
__________________________________________________________________________________________________
norm_in_park_factors (BatchNorm (None, None, 7)      28          time_distributed_6[0][0]         
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, None, 113)    0           norm_in_age[0][0]                
                                                                 norm_in_bio[0][0]                
                                                                 norm_in_fielding_position[0][0]  
                                                                 norm_in_out_fielding_position[0][
                                                                 norm_in_out_league_offense[0][0] 
                                                                 norm_in_out_park_factors[0][0]   
                                                                 norm_in_out_plate_discipline[0][0
                                                                 norm_in_out_running[0][0]        
                                                                 norm_in_out_saber[0][0]          
                                                                 norm_in_out_stats_extended[0][0] 
                                                                 norm_in_park_factors[0][0]       
__________________________________________________________________________________________________
gru_1 (GRU)                     (None, None, 113)    76953       concatenate_1[0][0]              
__________________________________________________________________________________________________
gru_2 (GRU)                     (None, None, 113)    76953       gru_1[0][0]                      
__________________________________________________________________________________________________
mv_out_stats (TimeDistributed)  (None, None, 5)      4560        gru_2[0][0]                      
__________________________________________________________________________________________________
mv_out_counts (TimeDistributed) (None, None, 3)      2736        gru_2[0][0]                      
__________________________________________________________________________________________________
mv_out_mean_covariance (TimeDis (None, None, 72)     65664       gru_2[0][0]                      
__________________________________________________________________________________________________
mv_out_fielding_position (TimeD (None, None, 11)     10032       gru_2[0][0]                      
__________________________________________________________________________________________________
out_stats (Activation)          (None, None, 5)      0           mv_out_stats[0][0]               
__________________________________________________________________________________________________
out_counts (Activation)         (None, None, 3)      0           mv_out_counts[0][0]              
__________________________________________________________________________________________________
out_mean_covariance (Activation (None, None, 72)     0           mv_out_mean_covariance[0][0]     
__________________________________________________________________________________________________
out_fielding_position (Activati (None, None, 11)     0           mv_out_fielding_position[0][0]   
==================================================================================================
Total params: 237,350
Trainable params: 237,124
Non-trainable params: 226
__________________________________________________________________________________________________
Train on 5748 samples, validate on 1385 samples
Epoch 1/1000

Epoch 00001: val_loss improved from inf to 20.21407, saving model to models/bc/shift2/max2015/simple-rnn/4.h5
 - 15s - loss: 21.7513 - out_stats_loss: 8.2128 - out_counts_loss: 3.7820 - out_mean_covariance_loss: 104.9311 - out_fielding_position_loss: 4.5100 - val_loss: 20.2141 - val_out_stats_loss: 7.7188 - val_out_counts_loss: 3.1786 - val_out_mean_covariance_loss: 100.3108 - val_out_fielding_position_loss: 4.3011
Epoch 2/1000

Epoch 00002: val_loss improved from 20.21407 to 17.56644, saving model to models/bc/shift2/max2015/simple-rnn/4.h5
 - 5s - loss: 18.5694 - out_stats_loss: 6.9680 - out_counts_loss: 2.8977 - out_mean_covariance_loss: 92.1259 - out_fielding_position_loss: 4.0975 - val_loss: 17.5664 - val_out_stats_loss: 6.5979 - val_out_counts_loss: 2.6339 - val_out_mean_covariance_loss: 88.0398 - val_out_fielding_position_loss: 3.9326
Epoch 3/1000

Epoch 00003: val_loss improved from 17.56644 to 16.04586, saving model to models/bc/shift2/max2015/simple-rnn/4.h5
 - 5s - loss: 16.5984 - out_stats_loss: 6.1545 - out_counts_loss: 2.5801 - out_mean_covariance_loss: 81.8980 - out_fielding_position_loss: 3.7689 - val_loss: 16.0459 - val_out_stats_loss: 6.0239 - val_out_counts_loss: 2.4267 - val_out_mean_covariance_loss: 78.9689 - val_out_fielding_position_loss: 3.6468
Epoch 4/1000

Epoch 00004: val_loss improved from 16.04586 to 15.30421, saving model to models/bc/shift2/max2015/simple-rnn/4.h5
 - 5s - loss: 15.5642 - out_stats_loss: 5.8168 - out_counts_loss: 2.4638 - out_mean_covariance_loss: 75.5339 - out_fielding_position_loss: 3.5070 - val_loss: 15.3042 - val_out_stats_loss: 5.8235 - val_out_counts_loss: 2.3465 - val_out_mean_covariance_loss: 74.7091 - val_out_fielding_position_loss: 3.3988
Epoch 5/1000

Epoch 00005: val_loss improved from 15.30421 to 14.79911, saving model to models/bc/shift2/max2015/simple-rnn/4.h5
 - 5s - loss: 14.9939 - out_stats_loss: 5.6615 - out_counts_loss: 2.4078 - out_mean_covariance_loss: 72.1271 - out_fielding_position_loss: 3.3182 - val_loss: 14.7991 - val_out_stats_loss: 5.7247 - val_out_counts_loss: 2.2856 - val_out_mean_covariance_loss: 72.1504 - val_out_fielding_position_loss: 3.1813
Epoch 6/1000

Epoch 00006: val_loss improved from 14.79911 to 14.48150, saving model to models/bc/shift2/max2015/simple-rnn/4.h5
 - 5s - loss: 14.5206 - out_stats_loss: 5.5590 - out_counts_loss: 2.3505 - out_mean_covariance_loss: 70.1845 - out_fielding_position_loss: 3.1020 - val_loss: 14.4815 - val_out_stats_loss: 5.6608 - val_out_counts_loss: 2.2731 - val_out_mean_covariance_loss: 70.7063 - val_out_fielding_position_loss: 3.0123
Epoch 7/1000

Epoch 00007: val_loss improved from 14.48150 to 14.19544, saving model to models/bc/shift2/max2015/simple-rnn/4.h5
 - 5s - loss: 14.2202 - out_stats_loss: 5.4957 - out_counts_loss: 2.3158 - out_mean_covariance_loss: 68.8825 - out_fielding_position_loss: 2.9646 - val_loss: 14.1954 - val_out_stats_loss: 5.5841 - val_out_counts_loss: 2.2407 - val_out_mean_covariance_loss: 69.3317 - val_out_fielding_position_loss: 2.9041
Epoch 8/1000

Epoch 00008: val_loss improved from 14.19544 to 14.01518, saving model to models/bc/shift2/max2015/simple-rnn/4.h5
 - 5s - loss: 13.9496 - out_stats_loss: 5.4180 - out_counts_loss: 2.2913 - out_mean_covariance_loss: 67.5533 - out_fielding_position_loss: 2.8626 - val_loss: 14.0152 - val_out_stats_loss: 5.5450 - val_out_counts_loss: 2.2279 - val_out_mean_covariance_loss: 68.6497 - val_out_fielding_position_loss: 2.8099
Epoch 9/1000

Epoch 00009: val_loss improved from 14.01518 to 13.90797, saving model to models/bc/shift2/max2015/simple-rnn/4.h5
 - 5s - loss: 13.7570 - out_stats_loss: 5.3703 - out_counts_loss: 2.2800 - out_mean_covariance_loss: 66.5805 - out_fielding_position_loss: 2.7777 - val_loss: 13.9080 - val_out_stats_loss: 5.5396 - val_out_counts_loss: 2.2140 - val_out_mean_covariance_loss: 68.2205 - val_out_fielding_position_loss: 2.7434
Epoch 10/1000

Epoch 00010: val_loss improved from 13.90797 to 13.79669, saving model to models/bc/shift2/max2015/simple-rnn/4.h5
 - 5s - loss: 13.6456 - out_stats_loss: 5.3506 - out_counts_loss: 2.2598 - out_mean_covariance_loss: 66.2997 - out_fielding_position_loss: 2.7202 - val_loss: 13.7967 - val_out_stats_loss: 5.4927 - val_out_counts_loss: 2.2183 - val_out_mean_covariance_loss: 67.9543 - val_out_fielding_position_loss: 2.6880
Epoch 11/1000

Epoch 00011: val_loss improved from 13.79669 to 13.69849, saving model to models/bc/shift2/max2015/simple-rnn/4.h5
 - 5s - loss: 13.5174 - out_stats_loss: 5.3155 - out_counts_loss: 2.2510 - out_mean_covariance_loss: 65.4184 - out_fielding_position_loss: 2.6799 - val_loss: 13.6985 - val_out_stats_loss: 5.4638 - val_out_counts_loss: 2.2094 - val_out_mean_covariance_loss: 67.5511 - val_out_fielding_position_loss: 2.6477
Epoch 12/1000

Epoch 00012: val_loss improved from 13.69849 to 13.59694, saving model to models/bc/shift2/max2015/simple-rnn/4.h5
 - 5s - loss: 13.4066 - out_stats_loss: 5.2888 - out_counts_loss: 2.2343 - out_mean_covariance_loss: 65.1518 - out_fielding_position_loss: 2.6259 - val_loss: 13.5969 - val_out_stats_loss: 5.4290 - val_out_counts_loss: 2.1995 - val_out_mean_covariance_loss: 67.1317 - val_out_fielding_position_loss: 2.6119
Epoch 13/1000

Epoch 00013: val_loss improved from 13.59694 to 13.56237, saving model to models/bc/shift2/max2015/simple-rnn/4.h5
 - 5s - loss: 13.3383 - out_stats_loss: 5.2772 - out_counts_loss: 2.2109 - out_mean_covariance_loss: 65.2984 - out_fielding_position_loss: 2.5853 - val_loss: 13.5624 - val_out_stats_loss: 5.4209 - val_out_counts_loss: 2.2018 - val_out_mean_covariance_loss: 67.0497 - val_out_fielding_position_loss: 2.5872
Epoch 14/1000

Epoch 00014: val_loss improved from 13.56237 to 13.49049, saving model to models/bc/shift2/max2015/simple-rnn/4.h5
 - 5s - loss: 13.2743 - out_stats_loss: 5.2463 - out_counts_loss: 2.2053 - out_mean_covariance_loss: 64.6297 - out_fielding_position_loss: 2.5911 - val_loss: 13.4905 - val_out_stats_loss: 5.4007 - val_out_counts_loss: 2.1965 - val_out_mean_covariance_loss: 66.5439 - val_out_fielding_position_loss: 2.5661
Epoch 15/1000

Epoch 00015: val_loss improved from 13.49049 to 13.45877, saving model to models/bc/shift2/max2015/simple-rnn/4.h5
 - 5s - loss: 13.1999 - out_stats_loss: 5.2239 - out_counts_loss: 2.2033 - out_mean_covariance_loss: 64.1769 - out_fielding_position_loss: 2.5638 - val_loss: 13.4588 - val_out_stats_loss: 5.3819 - val_out_counts_loss: 2.1971 - val_out_mean_covariance_loss: 66.5341 - val_out_fielding_position_loss: 2.5532
Epoch 16/1000

Epoch 00016: val_loss improved from 13.45877 to 13.41333, saving model to models/bc/shift2/max2015/simple-rnn/4.h5
 - 5s - loss: 13.0554 - out_stats_loss: 5.1718 - out_counts_loss: 2.1682 - out_mean_covariance_loss: 63.6533 - out_fielding_position_loss: 2.5328 - val_loss: 13.4133 - val_out_stats_loss: 5.3793 - val_out_counts_loss: 2.1843 - val_out_mean_covariance_loss: 66.3031 - val_out_fielding_position_loss: 2.5345
Epoch 17/1000

Epoch 00017: val_loss did not improve
 - 5s - loss: 13.0129 - out_stats_loss: 5.1579 - out_counts_loss: 2.1645 - out_mean_covariance_loss: 63.4925 - out_fielding_position_loss: 2.5159 - val_loss: 13.4309 - val_out_stats_loss: 5.3886 - val_out_counts_loss: 2.2155 - val_out_mean_covariance_loss: 66.1813 - val_out_fielding_position_loss: 2.5178
Epoch 18/1000

Epoch 00018: val_loss improved from 13.41333 to 13.35339, saving model to models/bc/shift2/max2015/simple-rnn/4.h5
 - 5s - loss: 12.9623 - out_stats_loss: 5.1481 - out_counts_loss: 2.1453 - out_mean_covariance_loss: 63.5297 - out_fielding_position_loss: 2.4925 - val_loss: 13.3534 - val_out_stats_loss: 5.3625 - val_out_counts_loss: 2.1838 - val_out_mean_covariance_loss: 65.9658 - val_out_fielding_position_loss: 2.5088
Epoch 19/1000

Epoch 00019: val_loss improved from 13.35339 to 13.35020, saving model to models/bc/shift2/max2015/simple-rnn/4.h5
 - 5s - loss: 12.9206 - out_stats_loss: 5.1466 - out_counts_loss: 2.1360 - out_mean_covariance_loss: 63.2731 - out_fielding_position_loss: 2.4744 - val_loss: 13.3502 - val_out_stats_loss: 5.3542 - val_out_counts_loss: 2.1978 - val_out_mean_covariance_loss: 65.9377 - val_out_fielding_position_loss: 2.5013
Epoch 20/1000

Epoch 00020: val_loss improved from 13.35020 to 13.29566, saving model to models/bc/shift2/max2015/simple-rnn/4.h5
 - 5s - loss: 12.8573 - out_stats_loss: 5.1252 - out_counts_loss: 2.1280 - out_mean_covariance_loss: 62.9942 - out_fielding_position_loss: 2.4544 - val_loss: 13.2957 - val_out_stats_loss: 5.3411 - val_out_counts_loss: 2.1822 - val_out_mean_covariance_loss: 65.6468 - val_out_fielding_position_loss: 2.4899
Epoch 21/1000

Epoch 00021: val_loss improved from 13.29566 to 13.28991, saving model to models/bc/shift2/max2015/simple-rnn/4.h5
 - 5s - loss: 12.8217 - out_stats_loss: 5.1221 - out_counts_loss: 2.1087 - out_mean_covariance_loss: 63.0489 - out_fielding_position_loss: 2.4384 - val_loss: 13.2899 - val_out_stats_loss: 5.3336 - val_out_counts_loss: 2.1916 - val_out_mean_covariance_loss: 65.6338 - val_out_fielding_position_loss: 2.4830
Epoch 22/1000

Epoch 00022: val_loss did not improve
 - 5s - loss: 12.7853 - out_stats_loss: 5.1140 - out_counts_loss: 2.1076 - out_mean_covariance_loss: 62.6782 - out_fielding_position_loss: 2.4298 - val_loss: 13.3082 - val_out_stats_loss: 5.3578 - val_out_counts_loss: 2.1957 - val_out_mean_covariance_loss: 65.5565 - val_out_fielding_position_loss: 2.4768
Epoch 23/1000

Epoch 00023: val_loss improved from 13.28991 to 13.26979, saving model to models/bc/shift2/max2015/simple-rnn/4.h5
 - 5s - loss: 12.6887 - out_stats_loss: 5.0847 - out_counts_loss: 2.0821 - out_mean_covariance_loss: 62.1201 - out_fielding_position_loss: 2.4160 - val_loss: 13.2698 - val_out_stats_loss: 5.3412 - val_out_counts_loss: 2.1871 - val_out_mean_covariance_loss: 65.4588 - val_out_fielding_position_loss: 2.4686
Epoch 24/1000

Epoch 00024: val_loss improved from 13.26979 to 13.25692, saving model to models/bc/shift2/max2015/simple-rnn/4.h5
 - 5s - loss: 12.7205 - out_stats_loss: 5.1073 - out_counts_loss: 2.0749 - out_mean_covariance_loss: 62.7971 - out_fielding_position_loss: 2.3983 - val_loss: 13.2569 - val_out_stats_loss: 5.3243 - val_out_counts_loss: 2.2100 - val_out_mean_covariance_loss: 65.3373 - val_out_fielding_position_loss: 2.4558
Epoch 25/1000

Epoch 00025: val_loss did not improve
 - 5s - loss: 12.6119 - out_stats_loss: 5.0567 - out_counts_loss: 2.0608 - out_mean_covariance_loss: 62.0004 - out_fielding_position_loss: 2.3945 - val_loss: 13.2688 - val_out_stats_loss: 5.3232 - val_out_counts_loss: 2.2248 - val_out_mean_covariance_loss: 65.3062 - val_out_fielding_position_loss: 2.4555
Epoch 26/1000

Epoch 00026: val_loss improved from 13.25692 to 13.23511, saving model to models/bc/shift2/max2015/simple-rnn/4.h5
 - 5s - loss: 12.5914 - out_stats_loss: 5.0525 - out_counts_loss: 2.0580 - out_mean_covariance_loss: 62.0287 - out_fielding_position_loss: 2.3795 - val_loss: 13.2351 - val_out_stats_loss: 5.3296 - val_out_counts_loss: 2.2049 - val_out_mean_covariance_loss: 65.1206 - val_out_fielding_position_loss: 2.4446
Epoch 27/1000

Epoch 00027: val_loss improved from 13.23511 to 13.17641, saving model to models/bc/shift2/max2015/simple-rnn/4.h5
 - 5s - loss: 12.5073 - out_stats_loss: 5.0247 - out_counts_loss: 2.0370 - out_mean_covariance_loss: 61.5942 - out_fielding_position_loss: 2.3659 - val_loss: 13.1764 - val_out_stats_loss: 5.3018 - val_out_counts_loss: 2.1861 - val_out_mean_covariance_loss: 64.9555 - val_out_fielding_position_loss: 2.4408
Epoch 28/1000

Epoch 00028: val_loss did not improve
 - 5s - loss: 12.4392 - out_stats_loss: 5.0101 - out_counts_loss: 2.0083 - out_mean_covariance_loss: 61.5887 - out_fielding_position_loss: 2.3413 - val_loss: 13.1829 - val_out_stats_loss: 5.3074 - val_out_counts_loss: 2.1899 - val_out_mean_covariance_loss: 65.0247 - val_out_fielding_position_loss: 2.4343
Epoch 29/1000

Epoch 00029: val_loss improved from 13.17641 to 13.16698, saving model to models/bc/shift2/max2015/simple-rnn/4.h5
 - 5s - loss: 12.3931 - out_stats_loss: 4.9955 - out_counts_loss: 2.0153 - out_mean_covariance_loss: 61.0635 - out_fielding_position_loss: 2.3291 - val_loss: 13.1670 - val_out_stats_loss: 5.3075 - val_out_counts_loss: 2.1881 - val_out_mean_covariance_loss: 64.8747 - val_out_fielding_position_loss: 2.4276
Epoch 30/1000

Epoch 00030: val_loss did not improve
 - 5s - loss: 12.3581 - out_stats_loss: 4.9857 - out_counts_loss: 1.9968 - out_mean_covariance_loss: 61.0212 - out_fielding_position_loss: 2.3245 - val_loss: 13.2049 - val_out_stats_loss: 5.3291 - val_out_counts_loss: 2.2030 - val_out_mean_covariance_loss: 64.9111 - val_out_fielding_position_loss: 2.4272
Epoch 31/1000

Epoch 00031: val_loss did not improve
 - 5s - loss: 12.3215 - out_stats_loss: 4.9793 - out_counts_loss: 1.9889 - out_mean_covariance_loss: 60.8299 - out_fielding_position_loss: 2.3119 - val_loss: 13.2511 - val_out_stats_loss: 5.3386 - val_out_counts_loss: 2.2404 - val_out_mean_covariance_loss: 64.9417 - val_out_fielding_position_loss: 2.4251
Epoch 32/1000

Epoch 00032: val_loss did not improve
 - 5s - loss: 12.3350 - out_stats_loss: 4.9932 - out_counts_loss: 1.9762 - out_mean_covariance_loss: 61.1821 - out_fielding_position_loss: 2.3064 - val_loss: 13.1777 - val_out_stats_loss: 5.3120 - val_out_counts_loss: 2.2095 - val_out_mean_covariance_loss: 64.7469 - val_out_fielding_position_loss: 2.4189
Epoch 33/1000

Epoch 00033: val_loss did not improve
 - 5s - loss: 12.2836 - out_stats_loss: 4.9848 - out_counts_loss: 1.9663 - out_mean_covariance_loss: 60.9093 - out_fielding_position_loss: 2.2871 - val_loss: 13.1792 - val_out_stats_loss: 5.3169 - val_out_counts_loss: 2.2098 - val_out_mean_covariance_loss: 64.8336 - val_out_fielding_position_loss: 2.4109
Epoch 34/1000

Epoch 00034: val_loss did not improve
 - 5s - loss: 12.2227 - out_stats_loss: 4.9609 - out_counts_loss: 1.9517 - out_mean_covariance_loss: 60.6257 - out_fielding_position_loss: 2.2788 - val_loss: 13.2292 - val_out_stats_loss: 5.3571 - val_out_counts_loss: 2.2254 - val_out_mean_covariance_loss: 64.7193 - val_out_fielding_position_loss: 2.4106
Epoch 35/1000

Epoch 00035: val_loss did not improve
 - 5s - loss: 12.1995 - out_stats_loss: 4.9719 - out_counts_loss: 1.9302 - out_mean_covariance_loss: 60.5609 - out_fielding_position_loss: 2.2693 - val_loss: 13.1694 - val_out_stats_loss: 5.3085 - val_out_counts_loss: 2.2249 - val_out_mean_covariance_loss: 64.5410 - val_out_fielding_position_loss: 2.4090
Epoch 36/1000

Epoch 00036: val_loss did not improve
 - 5s - loss: 12.1276 - out_stats_loss: 4.9359 - out_counts_loss: 1.9221 - out_mean_covariance_loss: 60.3247 - out_fielding_position_loss: 2.2534 - val_loss: 13.1792 - val_out_stats_loss: 5.3081 - val_out_counts_loss: 2.2372 - val_out_mean_covariance_loss: 64.5787 - val_out_fielding_position_loss: 2.4050
Epoch 37/1000

Epoch 00037: val_loss improved from 13.16698 to 13.16348, saving model to models/bc/shift2/max2015/simple-rnn/4.h5
 - 5s - loss: 12.1020 - out_stats_loss: 4.9302 - out_counts_loss: 1.9173 - out_mean_covariance_loss: 60.1913 - out_fielding_position_loss: 2.2450 - val_loss: 13.1635 - val_out_stats_loss: 5.3145 - val_out_counts_loss: 2.2296 - val_out_mean_covariance_loss: 64.5008 - val_out_fielding_position_loss: 2.3943
Epoch 38/1000

Epoch 00038: val_loss improved from 13.16348 to 13.12795, saving model to models/bc/shift2/max2015/simple-rnn/4.h5
 - 5s - loss: 12.1424 - out_stats_loss: 4.9589 - out_counts_loss: 1.9270 - out_mean_covariance_loss: 60.2590 - out_fielding_position_loss: 2.2436 - val_loss: 13.1279 - val_out_stats_loss: 5.2939 - val_out_counts_loss: 2.2224 - val_out_mean_covariance_loss: 64.3899 - val_out_fielding_position_loss: 2.3921
Epoch 39/1000

Epoch 00039: val_loss did not improve
 - 5s - loss: 12.0099 - out_stats_loss: 4.8968 - out_counts_loss: 1.9073 - out_mean_covariance_loss: 59.5315 - out_fielding_position_loss: 2.2292 - val_loss: 13.1365 - val_out_stats_loss: 5.2957 - val_out_counts_loss: 2.2278 - val_out_mean_covariance_loss: 64.4208 - val_out_fielding_position_loss: 2.3919
Epoch 40/1000

Epoch 00040: val_loss did not improve
 - 5s - loss: 11.9716 - out_stats_loss: 4.8968 - out_counts_loss: 1.8893 - out_mean_covariance_loss: 59.5223 - out_fielding_position_loss: 2.2093 - val_loss: 13.1669 - val_out_stats_loss: 5.3123 - val_out_counts_loss: 2.2482 - val_out_mean_covariance_loss: 64.4350 - val_out_fielding_position_loss: 2.3846
Epoch 41/1000

Epoch 00041: val_loss did not improve
 - 5s - loss: 11.9671 - out_stats_loss: 4.9013 - out_counts_loss: 1.8778 - out_mean_covariance_loss: 59.7161 - out_fielding_position_loss: 2.2022 - val_loss: 13.1947 - val_out_stats_loss: 5.3101 - val_out_counts_loss: 2.2744 - val_out_mean_covariance_loss: 64.3881 - val_out_fielding_position_loss: 2.3908
Epoch 42/1000

Epoch 00042: val_loss did not improve
 - 5s - loss: 11.9251 - out_stats_loss: 4.8839 - out_counts_loss: 1.8703 - out_mean_covariance_loss: 59.5440 - out_fielding_position_loss: 2.1936 - val_loss: 13.1924 - val_out_stats_loss: 5.3220 - val_out_counts_loss: 2.2665 - val_out_mean_covariance_loss: 64.4394 - val_out_fielding_position_loss: 2.3820
Epoch 43/1000

Epoch 00043: val_loss did not improve
 - 5s - loss: 11.9068 - out_stats_loss: 4.8929 - out_counts_loss: 1.8550 - out_mean_covariance_loss: 59.3725 - out_fielding_position_loss: 2.1902 - val_loss: 13.2118 - val_out_stats_loss: 5.3274 - val_out_counts_loss: 2.2839 - val_out_mean_covariance_loss: 64.3396 - val_out_fielding_position_loss: 2.3835
Epoch 44/1000

Epoch 00044: val_loss did not improve
 - 5s - loss: 11.8887 - out_stats_loss: 4.8927 - out_counts_loss: 1.8480 - out_mean_covariance_loss: 59.4878 - out_fielding_position_loss: 2.1737 - val_loss: 13.1494 - val_out_stats_loss: 5.3071 - val_out_counts_loss: 2.2588 - val_out_mean_covariance_loss: 64.2444 - val_out_fielding_position_loss: 2.3713
Epoch 45/1000

Epoch 00045: val_loss did not improve
 - 5s - loss: 11.7980 - out_stats_loss: 4.8663 - out_counts_loss: 1.8283 - out_mean_covariance_loss: 58.8413 - out_fielding_position_loss: 2.1613 - val_loss: 13.1411 - val_out_stats_loss: 5.3069 - val_out_counts_loss: 2.2637 - val_out_mean_covariance_loss: 64.1083 - val_out_fielding_position_loss: 2.3651
Epoch 46/1000

Epoch 00046: val_loss did not improve
 - 5s - loss: 11.7791 - out_stats_loss: 4.8680 - out_counts_loss: 1.8222 - out_mean_covariance_loss: 58.9308 - out_fielding_position_loss: 2.1425 - val_loss: 13.1591 - val_out_stats_loss: 5.3102 - val_out_counts_loss: 2.2699 - val_out_mean_covariance_loss: 64.3088 - val_out_fielding_position_loss: 2.3635
Epoch 47/1000

Epoch 00047: val_loss did not improve
 - 5s - loss: 11.8733 - out_stats_loss: 4.9130 - out_counts_loss: 1.8408 - out_mean_covariance_loss: 59.6373 - out_fielding_position_loss: 2.1376 - val_loss: 13.2288 - val_out_stats_loss: 5.3554 - val_out_counts_loss: 2.2984 - val_out_mean_covariance_loss: 64.2149 - val_out_fielding_position_loss: 2.3642
Epoch 48/1000

Epoch 00048: val_loss did not improve
 - 5s - loss: 11.6915 - out_stats_loss: 4.8363 - out_counts_loss: 1.8095 - out_mean_covariance_loss: 58.4095 - out_fielding_position_loss: 2.1252 - val_loss: 13.1378 - val_out_stats_loss: 5.3011 - val_out_counts_loss: 2.2755 - val_out_mean_covariance_loss: 64.0187 - val_out_fielding_position_loss: 2.3602
Epoch 49/1000

Epoch 00049: val_loss did not improve
 - 5s - loss: 11.6880 - out_stats_loss: 4.8470 - out_counts_loss: 1.7986 - out_mean_covariance_loss: 58.4298 - out_fielding_position_loss: 2.1209 - val_loss: 13.2094 - val_out_stats_loss: 5.3346 - val_out_counts_loss: 2.3090 - val_out_mean_covariance_loss: 64.1752 - val_out_fielding_position_loss: 2.3570
Epoch 50/1000

Epoch 00050: val_loss did not improve
 - 5s - loss: 11.7318 - out_stats_loss: 4.8844 - out_counts_loss: 1.7821 - out_mean_covariance_loss: 59.2314 - out_fielding_position_loss: 2.1038 - val_loss: 13.1659 - val_out_stats_loss: 5.3146 - val_out_counts_loss: 2.2996 - val_out_mean_covariance_loss: 64.0553 - val_out_fielding_position_loss: 2.3489
Epoch 51/1000

Epoch 00051: val_loss did not improve
 - 5s - loss: 11.6178 - out_stats_loss: 4.8255 - out_counts_loss: 1.7789 - out_mean_covariance_loss: 58.2986 - out_fielding_position_loss: 2.0985 - val_loss: 13.2073 - val_out_stats_loss: 5.3260 - val_out_counts_loss: 2.3166 - val_out_mean_covariance_loss: 64.1965 - val_out_fielding_position_loss: 2.3549
Epoch 52/1000

Epoch 00052: val_loss did not improve
 - 5s - loss: 11.6241 - out_stats_loss: 4.8196 - out_counts_loss: 1.7987 - out_mean_covariance_loss: 58.0743 - out_fielding_position_loss: 2.1020 - val_loss: 13.2856 - val_out_stats_loss: 5.3566 - val_out_counts_loss: 2.3627 - val_out_mean_covariance_loss: 64.1606 - val_out_fielding_position_loss: 2.3583
Epoch 53/1000

Epoch 00053: val_loss did not improve
 - 5s - loss: 11.5313 - out_stats_loss: 4.8028 - out_counts_loss: 1.7540 - out_mean_covariance_loss: 58.0277 - out_fielding_position_loss: 2.0731 - val_loss: 13.2773 - val_out_stats_loss: 5.3541 - val_out_counts_loss: 2.3575 - val_out_mean_covariance_loss: 64.2387 - val_out_fielding_position_loss: 2.3537
Epoch 54/1000

Epoch 00054: val_loss did not improve
 - 5s - loss: 11.6405 - out_stats_loss: 4.8566 - out_counts_loss: 1.7653 - out_mean_covariance_loss: 59.0079 - out_fielding_position_loss: 2.0683 - val_loss: 13.1629 - val_out_stats_loss: 5.3206 - val_out_counts_loss: 2.3080 - val_out_mean_covariance_loss: 63.8857 - val_out_fielding_position_loss: 2.3401
Epoch 55/1000

Epoch 00055: val_loss did not improve
 - 5s - loss: 11.5313 - out_stats_loss: 4.8130 - out_counts_loss: 1.7507 - out_mean_covariance_loss: 58.1413 - out_fielding_position_loss: 2.0606 - val_loss: 13.2343 - val_out_stats_loss: 5.3347 - val_out_counts_loss: 2.3469 - val_out_mean_covariance_loss: 64.0457 - val_out_fielding_position_loss: 2.3504
Epoch 56/1000

Epoch 00056: val_loss did not improve
 - 5s - loss: 11.5294 - out_stats_loss: 4.8134 - out_counts_loss: 1.7488 - out_mean_covariance_loss: 58.1440 - out_fielding_position_loss: 2.0600 - val_loss: 13.1862 - val_out_stats_loss: 5.3180 - val_out_counts_loss: 2.3336 - val_out_mean_covariance_loss: 63.9165 - val_out_fielding_position_loss: 2.3388
Epoch 57/1000

Epoch 00057: val_loss did not improve
 - 5s - loss: 11.4545 - out_stats_loss: 4.7852 - out_counts_loss: 1.7316 - out_mean_covariance_loss: 57.6490 - out_fielding_position_loss: 2.0552 - val_loss: 13.2529 - val_out_stats_loss: 5.3588 - val_out_counts_loss: 2.3587 - val_out_mean_covariance_loss: 63.9983 - val_out_fielding_position_loss: 2.3355
Epoch 58/1000

Epoch 00058: val_loss did not improve
 - 4s - loss: 11.4090 - out_stats_loss: 4.7791 - out_counts_loss: 1.7199 - out_mean_covariance_loss: 57.5830 - out_fielding_position_loss: 2.0308 - val_loss: 13.2586 - val_out_stats_loss: 5.3473 - val_out_counts_loss: 2.3728 - val_out_mean_covariance_loss: 63.9911 - val_out_fielding_position_loss: 2.3390
Epoch 59/1000

Epoch 00059: val_loss did not improve
 - 5s - loss: 11.4061 - out_stats_loss: 4.7748 - out_counts_loss: 1.7221 - out_mean_covariance_loss: 57.6602 - out_fielding_position_loss: 2.0263 - val_loss: 13.2565 - val_out_stats_loss: 5.3427 - val_out_counts_loss: 2.3789 - val_out_mean_covariance_loss: 63.9635 - val_out_fielding_position_loss: 2.3367
Epoch 60/1000

Epoch 00060: val_loss did not improve
 - 5s - loss: 11.4010 - out_stats_loss: 4.7944 - out_counts_loss: 1.7044 - out_mean_covariance_loss: 57.7986 - out_fielding_position_loss: 2.0123 - val_loss: 13.2572 - val_out_stats_loss: 5.3469 - val_out_counts_loss: 2.3809 - val_out_mean_covariance_loss: 63.9675 - val_out_fielding_position_loss: 2.3310
Epoch 61/1000

Epoch 00061: val_loss did not improve
 - 5s - loss: 11.3573 - out_stats_loss: 4.7714 - out_counts_loss: 1.7009 - out_mean_covariance_loss: 57.4458 - out_fielding_position_loss: 2.0127 - val_loss: 13.3305 - val_out_stats_loss: 5.3603 - val_out_counts_loss: 2.4234 - val_out_mean_covariance_loss: 64.1397 - val_out_fielding_position_loss: 2.3398
Epoch 62/1000

Epoch 00062: val_loss did not improve
 - 5s - loss: 11.3714 - out_stats_loss: 4.7893 - out_counts_loss: 1.7068 - out_mean_covariance_loss: 57.5040 - out_fielding_position_loss: 2.0001 - val_loss: 13.2677 - val_out_stats_loss: 5.3481 - val_out_counts_loss: 2.3971 - val_out_mean_covariance_loss: 63.9269 - val_out_fielding_position_loss: 2.3262
Epoch 63/1000

Epoch 00063: val_loss did not improve
 - 5s - loss: 11.2847 - out_stats_loss: 4.7601 - out_counts_loss: 1.6877 - out_mean_covariance_loss: 57.1551 - out_fielding_position_loss: 1.9791 - val_loss: 13.2658 - val_out_stats_loss: 5.3500 - val_out_counts_loss: 2.3874 - val_out_mean_covariance_loss: 63.9288 - val_out_fielding_position_loss: 2.3320
Epoch 64/1000

Epoch 00064: val_loss did not improve
 - 5s - loss: 11.2319 - out_stats_loss: 4.7397 - out_counts_loss: 1.6717 - out_mean_covariance_loss: 56.8670 - out_fielding_position_loss: 1.9771 - val_loss: 13.2631 - val_out_stats_loss: 5.3469 - val_out_counts_loss: 2.3956 - val_out_mean_covariance_loss: 63.9464 - val_out_fielding_position_loss: 2.3233
Epoch 65/1000

Epoch 00065: val_loss did not improve
 - 5s - loss: 11.2330 - out_stats_loss: 4.7334 - out_counts_loss: 1.6788 - out_mean_covariance_loss: 56.8545 - out_fielding_position_loss: 1.9781 - val_loss: 13.3062 - val_out_stats_loss: 5.3708 - val_out_counts_loss: 2.4046 - val_out_mean_covariance_loss: 64.1461 - val_out_fielding_position_loss: 2.3235
Epoch 66/1000

Epoch 00066: val_loss did not improve
 - 5s - loss: 11.2271 - out_stats_loss: 4.7473 - out_counts_loss: 1.6618 - out_mean_covariance_loss: 57.1150 - out_fielding_position_loss: 1.9623 - val_loss: 13.2537 - val_out_stats_loss: 5.3439 - val_out_counts_loss: 2.3984 - val_out_mean_covariance_loss: 63.8541 - val_out_fielding_position_loss: 2.3187
Epoch 67/1000

Epoch 00067: val_loss did not improve
 - 5s - loss: 11.2209 - out_stats_loss: 4.7574 - out_counts_loss: 1.6510 - out_mean_covariance_loss: 57.1734 - out_fielding_position_loss: 1.9538 - val_loss: 13.4767 - val_out_stats_loss: 5.4102 - val_out_counts_loss: 2.5077 - val_out_mean_covariance_loss: 64.4820 - val_out_fielding_position_loss: 2.3346
Epoch 68/1000

Epoch 00068: val_loss did not improve
 - 5s - loss: 11.1686 - out_stats_loss: 4.7203 - out_counts_loss: 1.6672 - out_mean_covariance_loss: 56.6929 - out_fielding_position_loss: 1.9465 - val_loss: 13.3146 - val_out_stats_loss: 5.3700 - val_out_counts_loss: 2.4269 - val_out_mean_covariance_loss: 63.9731 - val_out_fielding_position_loss: 2.3190
Epoch 69/1000

Epoch 00069: val_loss did not improve
 - 5s - loss: 11.1141 - out_stats_loss: 4.7099 - out_counts_loss: 1.6485 - out_mean_covariance_loss: 56.2957 - out_fielding_position_loss: 1.9410 - val_loss: 13.2936 - val_out_stats_loss: 5.3569 - val_out_counts_loss: 2.4241 - val_out_mean_covariance_loss: 64.0424 - val_out_fielding_position_loss: 2.3105
Epoch 70/1000

Epoch 00070: val_loss did not improve
 - 5s - loss: 11.0789 - out_stats_loss: 4.6981 - out_counts_loss: 1.6449 - out_mean_covariance_loss: 56.1144 - out_fielding_position_loss: 1.9302 - val_loss: 13.3867 - val_out_stats_loss: 5.3871 - val_out_counts_loss: 2.4616 - val_out_mean_covariance_loss: 64.2274 - val_out_fielding_position_loss: 2.3267
Epoch 71/1000

Epoch 00071: val_loss did not improve
 - 5s - loss: 11.0808 - out_stats_loss: 4.6969 - out_counts_loss: 1.6466 - out_mean_covariance_loss: 56.1498 - out_fielding_position_loss: 1.9298 - val_loss: 13.4385 - val_out_stats_loss: 5.4042 - val_out_counts_loss: 2.4871 - val_out_mean_covariance_loss: 64.3877 - val_out_fielding_position_loss: 2.3279
Epoch 72/1000

Epoch 00072: val_loss did not improve
 - 5s - loss: 11.1001 - out_stats_loss: 4.7097 - out_counts_loss: 1.6464 - out_mean_covariance_loss: 56.2315 - out_fielding_position_loss: 1.9324 - val_loss: 13.3285 - val_out_stats_loss: 5.3766 - val_out_counts_loss: 2.4425 - val_out_mean_covariance_loss: 64.0103 - val_out_fielding_position_loss: 2.3089
Epoch 73/1000

Epoch 00073: val_loss did not improve
 - 5s - loss: 11.0594 - out_stats_loss: 4.7024 - out_counts_loss: 1.6302 - out_mean_covariance_loss: 56.2391 - out_fielding_position_loss: 1.9149 - val_loss: 13.2821 - val_out_stats_loss: 5.3528 - val_out_counts_loss: 2.4291 - val_out_mean_covariance_loss: 63.8869 - val_out_fielding_position_loss: 2.3059
Epoch 74/1000

Epoch 00074: val_loss did not improve
 - 5s - loss: 11.0776 - out_stats_loss: 4.7066 - out_counts_loss: 1.6355 - out_mean_covariance_loss: 56.3410 - out_fielding_position_loss: 1.9185 - val_loss: 13.3446 - val_out_stats_loss: 5.3702 - val_out_counts_loss: 2.4598 - val_out_mean_covariance_loss: 63.9561 - val_out_fielding_position_loss: 2.3169
Epoch 75/1000

Epoch 00075: val_loss did not improve
 - 5s - loss: 10.9717 - out_stats_loss: 4.6798 - out_counts_loss: 1.6077 - out_mean_covariance_loss: 55.9567 - out_fielding_position_loss: 1.8863 - val_loss: 13.3812 - val_out_stats_loss: 5.3868 - val_out_counts_loss: 2.4765 - val_out_mean_covariance_loss: 64.1483 - val_out_fielding_position_loss: 2.3105
Epoch 76/1000

Epoch 00076: val_loss did not improve
 - 5s - loss: 11.0187 - out_stats_loss: 4.6993 - out_counts_loss: 1.6144 - out_mean_covariance_loss: 56.2379 - out_fielding_position_loss: 1.8931 - val_loss: 13.3997 - val_out_stats_loss: 5.3978 - val_out_counts_loss: 2.4818 - val_out_mean_covariance_loss: 64.2138 - val_out_fielding_position_loss: 2.3094
Epoch 77/1000

Epoch 00077: val_loss did not improve
 - 5s - loss: 10.9458 - out_stats_loss: 4.6825 - out_counts_loss: 1.5946 - out_mean_covariance_loss: 55.7881 - out_fielding_position_loss: 1.8792 - val_loss: 13.3664 - val_out_stats_loss: 5.3955 - val_out_counts_loss: 2.4626 - val_out_mean_covariance_loss: 64.1738 - val_out_fielding_position_loss: 2.2997
Epoch 78/1000

Epoch 00078: val_loss did not improve
 - 5s - loss: 10.9437 - out_stats_loss: 4.6790 - out_counts_loss: 1.6017 - out_mean_covariance_loss: 55.7634 - out_fielding_position_loss: 1.8749 - val_loss: 13.3009 - val_out_stats_loss: 5.3637 - val_out_counts_loss: 2.4480 - val_out_mean_covariance_loss: 64.0011 - val_out_fielding_position_loss: 2.2891
Epoch 79/1000

Epoch 00079: val_loss did not improve
 - 5s - loss: 10.9264 - out_stats_loss: 4.6660 - out_counts_loss: 1.6070 - out_mean_covariance_loss: 55.6285 - out_fielding_position_loss: 1.8720 - val_loss: 13.3226 - val_out_stats_loss: 5.3571 - val_out_counts_loss: 2.4662 - val_out_mean_covariance_loss: 63.9981 - val_out_fielding_position_loss: 2.2994
Epoch 80/1000

Epoch 00080: val_loss did not improve
 - 5s - loss: 10.9153 - out_stats_loss: 4.6563 - out_counts_loss: 1.6179 - out_mean_covariance_loss: 55.3853 - out_fielding_position_loss: 1.8719 - val_loss: 13.2880 - val_out_stats_loss: 5.3593 - val_out_counts_loss: 2.4453 - val_out_mean_covariance_loss: 63.9233 - val_out_fielding_position_loss: 2.2873
Epoch 81/1000

Epoch 00081: val_loss did not improve
 - 5s - loss: 10.8547 - out_stats_loss: 4.6534 - out_counts_loss: 1.5773 - out_mean_covariance_loss: 55.1968 - out_fielding_position_loss: 1.8642 - val_loss: 13.3861 - val_out_stats_loss: 5.3812 - val_out_counts_loss: 2.4935 - val_out_mean_covariance_loss: 64.1222 - val_out_fielding_position_loss: 2.3052
Epoch 82/1000

Epoch 00082: val_loss did not improve
 - 5s - loss: 10.8993 - out_stats_loss: 4.6710 - out_counts_loss: 1.5933 - out_mean_covariance_loss: 55.7175 - out_fielding_position_loss: 1.8491 - val_loss: 13.4652 - val_out_stats_loss: 5.3965 - val_out_counts_loss: 2.5300 - val_out_mean_covariance_loss: 64.5170 - val_out_fielding_position_loss: 2.3127
Epoch 83/1000

Epoch 00083: val_loss did not improve
 - 5s - loss: 10.8197 - out_stats_loss: 4.6499 - out_counts_loss: 1.5693 - out_mean_covariance_loss: 55.5311 - out_fielding_position_loss: 1.8239 - val_loss: 13.4763 - val_out_stats_loss: 5.4224 - val_out_counts_loss: 2.5251 - val_out_mean_covariance_loss: 64.4155 - val_out_fielding_position_loss: 2.3080
Epoch 84/1000

Epoch 00084: val_loss did not improve
 - 5s - loss: 10.7557 - out_stats_loss: 4.6177 - out_counts_loss: 1.5611 - out_mean_covariance_loss: 54.8194 - out_fielding_position_loss: 1.8359 - val_loss: 13.4691 - val_out_stats_loss: 5.3988 - val_out_counts_loss: 2.5404 - val_out_mean_covariance_loss: 64.3719 - val_out_fielding_position_loss: 2.3113
Epoch 85/1000

Epoch 00085: val_loss did not improve
 - 4s - loss: 10.8678 - out_stats_loss: 4.6807 - out_counts_loss: 1.5701 - out_mean_covariance_loss: 55.5532 - out_fielding_position_loss: 1.8393 - val_loss: 13.3999 - val_out_stats_loss: 5.3912 - val_out_counts_loss: 2.5042 - val_out_mean_covariance_loss: 64.2623 - val_out_fielding_position_loss: 2.2915
Epoch 86/1000

Epoch 00086: val_loss did not improve
 - 5s - loss: 10.7772 - out_stats_loss: 4.6319 - out_counts_loss: 1.5649 - out_mean_covariance_loss: 55.0639 - out_fielding_position_loss: 1.8272 - val_loss: 13.5419 - val_out_stats_loss: 5.4239 - val_out_counts_loss: 2.5794 - val_out_mean_covariance_loss: 64.4815 - val_out_fielding_position_loss: 2.3145
Epoch 87/1000

Epoch 00087: val_loss did not improve
 - 5s - loss: 10.7856 - out_stats_loss: 4.6430 - out_counts_loss: 1.5547 - out_mean_covariance_loss: 55.3507 - out_fielding_position_loss: 1.8203 - val_loss: 13.5779 - val_out_stats_loss: 5.4405 - val_out_counts_loss: 2.5808 - val_out_mean_covariance_loss: 64.8457 - val_out_fielding_position_loss: 2.3144
Epoch 88/1000

Epoch 00088: val_loss did not improve
 - 4s - loss: 10.7191 - out_stats_loss: 4.6209 - out_counts_loss: 1.5511 - out_mean_covariance_loss: 54.7625 - out_fielding_position_loss: 1.8090 - val_loss: 13.6660 - val_out_stats_loss: 5.4870 - val_out_counts_loss: 2.5945 - val_out_mean_covariance_loss: 65.1783 - val_out_fielding_position_loss: 2.3255
/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Years: [1958,2015]
Shift: 2
Fold: 4
Training into models/bc/shift2/max2015/simple-rnn/4.h5
/usr/local/lib/python3.5/dist-packages/keras/legacy/layers.py:533: UserWarning: The `MaxoutDense` layer is deprecated and will be removed after 06/2017.
  warnings.warn('The `MaxoutDense` layer is deprecated '
