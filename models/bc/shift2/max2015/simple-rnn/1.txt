__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
in_age (InputLayer)             (None, None, 2)      0                                            
__________________________________________________________________________________________________
in_bio (InputLayer)             (None, None, 7)      0                                            
__________________________________________________________________________________________________
in_fielding_position (InputLaye (None, None, 2)      0                                            
__________________________________________________________________________________________________
in_out_fielding_position (Input (None, None, 12)     0                                            
__________________________________________________________________________________________________
in_out_league_offense (InputLay (None, None, 9)      0                                            
__________________________________________________________________________________________________
in_out_park_factors (InputLayer (None, None, 8)      0                                            
__________________________________________________________________________________________________
in_out_plate_discipline (InputL (None, None, 8)      0                                            
__________________________________________________________________________________________________
in_out_running (InputLayer)     (None, None, 18)     0                                            
__________________________________________________________________________________________________
in_out_saber (InputLayer)       (None, None, 14)     0                                            
__________________________________________________________________________________________________
in_out_stats_extended (InputLay (None, None, 36)     0                                            
__________________________________________________________________________________________________
in_park_factors (InputLayer)    (None, None, 8)      0                                            
__________________________________________________________________________________________________
masked_in_age (Masking)         (None, None, 2)      0           in_age[0][0]                     
__________________________________________________________________________________________________
masked_in_bio (Masking)         (None, None, 7)      0           in_bio[0][0]                     
__________________________________________________________________________________________________
masked_in_fielding_position (Ma (None, None, 2)      0           in_fielding_position[0][0]       
__________________________________________________________________________________________________
masked_in_out_fielding_position (None, None, 12)     0           in_out_fielding_position[0][0]   
__________________________________________________________________________________________________
masked_in_out_league_offense (M (None, None, 9)      0           in_out_league_offense[0][0]      
__________________________________________________________________________________________________
masked_in_out_park_factors (Mas (None, None, 8)      0           in_out_park_factors[0][0]        
__________________________________________________________________________________________________
masked_in_out_plate_discipline  (None, None, 8)      0           in_out_plate_discipline[0][0]    
__________________________________________________________________________________________________
masked_in_out_running (Masking) (None, None, 18)     0           in_out_running[0][0]             
__________________________________________________________________________________________________
masked_in_out_saber (Masking)   (None, None, 14)     0           in_out_saber[0][0]               
__________________________________________________________________________________________________
masked_in_out_stats_extended (M (None, None, 36)     0           in_out_stats_extended[0][0]      
__________________________________________________________________________________________________
masked_in_park_factors (Masking (None, None, 8)      0           in_park_factors[0][0]            
__________________________________________________________________________________________________
time_distributed_10 (TimeDistri (None, None, 1)      0           masked_in_age[0][0]              
__________________________________________________________________________________________________
time_distributed_5 (TimeDistrib (None, None, 6)      0           masked_in_bio[0][0]              
__________________________________________________________________________________________________
time_distributed_4 (TimeDistrib (None, None, 1)      0           masked_in_fielding_position[0][0]
__________________________________________________________________________________________________
time_distributed_9 (TimeDistrib (None, None, 11)     0           masked_in_out_fielding_position[0
__________________________________________________________________________________________________
time_distributed_8 (TimeDistrib (None, None, 8)      0           masked_in_out_league_offense[0][0
__________________________________________________________________________________________________
time_distributed_7 (TimeDistrib (None, None, 7)      0           masked_in_out_park_factors[0][0] 
__________________________________________________________________________________________________
time_distributed_2 (TimeDistrib (None, None, 7)      0           masked_in_out_plate_discipline[0]
__________________________________________________________________________________________________
time_distributed_1 (TimeDistrib (None, None, 17)     0           masked_in_out_running[0][0]      
__________________________________________________________________________________________________
time_distributed_6 (TimeDistrib (None, None, 13)     0           masked_in_out_saber[0][0]        
__________________________________________________________________________________________________
time_distributed_3 (TimeDistrib (None, None, 35)     0           masked_in_out_stats_extended[0][0
__________________________________________________________________________________________________
time_distributed_11 (TimeDistri (None, None, 7)      0           masked_in_park_factors[0][0]     
__________________________________________________________________________________________________
norm_in_age (BatchNormalization (None, None, 1)      4           time_distributed_10[0][0]        
__________________________________________________________________________________________________
norm_in_bio (BatchNormalization (None, None, 6)      24          time_distributed_5[0][0]         
__________________________________________________________________________________________________
norm_in_fielding_position (Batc (None, None, 1)      4           time_distributed_4[0][0]         
__________________________________________________________________________________________________
norm_in_out_fielding_position ( (None, None, 11)     44          time_distributed_9[0][0]         
__________________________________________________________________________________________________
norm_in_out_league_offense (Bat (None, None, 8)      32          time_distributed_8[0][0]         
__________________________________________________________________________________________________
norm_in_out_park_factors (Batch (None, None, 7)      28          time_distributed_7[0][0]         
__________________________________________________________________________________________________
norm_in_out_plate_discipline (B (None, None, 7)      28          time_distributed_2[0][0]         
__________________________________________________________________________________________________2018-02-06 11:18:23.025553: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2018-02-06 11:18:29.956281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: 
name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235
pciBusID: eca0:00:00.0
totalMemory: 11.17GiB freeMemory: 11.10GiB
2018-02-06 11:18:29.956330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K80, pci bus id: eca0:00:00.0, compute capability: 3.7)

norm_in_out_running (BatchNorma (None, None, 17)     68          time_distributed_1[0][0]         
__________________________________________________________________________________________________
norm_in_out_saber (BatchNormali (None, None, 13)     52          time_distributed_6[0][0]         
__________________________________________________________________________________________________
norm_in_out_stats_extended (Bat (None, None, 35)     140         time_distributed_3[0][0]         
__________________________________________________________________________________________________
norm_in_park_factors (BatchNorm (None, None, 7)      28          time_distributed_11[0][0]        
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, None, 113)    0           norm_in_age[0][0]                
                                                                 norm_in_bio[0][0]                
                                                                 norm_in_fielding_position[0][0]  
                                                                 norm_in_out_fielding_position[0][
                                                                 norm_in_out_league_offense[0][0] 
                                                                 norm_in_out_park_factors[0][0]   
                                                                 norm_in_out_plate_discipline[0][0
                                                                 norm_in_out_running[0][0]        
                                                                 norm_in_out_saber[0][0]          
                                                                 norm_in_out_stats_extended[0][0] 
                                                                 norm_in_park_factors[0][0]       
__________________________________________________________________________________________________
gru_1 (GRU)                     (None, None, 113)    76953       concatenate_1[0][0]              
__________________________________________________________________________________________________
gru_2 (GRU)                     (None, None, 113)    76953       gru_1[0][0]                      
__________________________________________________________________________________________________
mv_out_stats (TimeDistributed)  (None, None, 5)      4560        gru_2[0][0]                      
__________________________________________________________________________________________________
mv_out_counts (TimeDistributed) (None, None, 3)      2736        gru_2[0][0]                      
__________________________________________________________________________________________________
mv_out_mean_covariance (TimeDis (None, None, 72)     65664       gru_2[0][0]                      
__________________________________________________________________________________________________
mv_out_fielding_position (TimeD (None, None, 11)     10032       gru_2[0][0]                      
__________________________________________________________________________________________________
out_stats (Activation)          (None, None, 5)      0           mv_out_stats[0][0]               
__________________________________________________________________________________________________
out_counts (Activation)         (None, None, 3)      0           mv_out_counts[0][0]              
__________________________________________________________________________________________________
out_mean_covariance (Activation (None, None, 72)     0           mv_out_mean_covariance[0][0]     
__________________________________________________________________________________________________
out_fielding_position (Activati (None, None, 11)     0           mv_out_fielding_position[0][0]   
==================================================================================================
Total params: 237,350
Trainable params: 237,124
Non-trainable params: 226
__________________________________________________________________________________________________
Train on 5748 samples, validate on 1385 samples
Epoch 1/1000

Epoch 00001: val_loss improved from inf to 19.24432, saving model to models/bc/shift2/max2015/simple-rnn/1.h5
 - 16s - loss: 20.8175 - out_stats_loss: 7.1749 - out_counts_loss: 3.8356 - out_mean_covariance_loss: 105.0477 - out_fielding_position_loss: 4.5546 - val_loss: 19.2443 - val_out_stats_loss: 6.7055 - val_out_counts_loss: 3.2101 - val_out_mean_covariance_loss: 99.8645 - val_out_fielding_position_loss: 4.3355
Epoch 2/1000

Epoch 00002: val_loss improved from 19.24432 to 16.67373, saving model to models/bc/shift2/max2015/simple-rnn/1.h5
 - 5s - loss: 17.6923 - out_stats_loss: 6.0563 - out_counts_loss: 2.9037 - out_mean_covariance_loss: 91.7871 - out_fielding_position_loss: 4.1430 - val_loss: 16.6737 - val_out_stats_loss: 5.6710 - val_out_counts_loss: 2.6496 - val_out_mean_covariance_loss: 87.4072 - val_out_fielding_position_loss: 3.9828
Epoch 3/1000

Epoch 00003: val_loss improved from 16.67373 to 15.15903, saving model to models/bc/shift2/max2015/simple-rnn/1.h5
 - 5s - loss: 15.7954 - out_stats_loss: 5.3199 - out_counts_loss: 2.5916 - out_mean_covariance_loss: 81.0590 - out_fielding_position_loss: 3.8310 - val_loss: 15.1590 - val_out_stats_loss: 5.1378 - val_out_counts_loss: 2.4290 - val_out_mean_covariance_loss: 78.5519 - val_out_fielding_position_loss: 3.6646
Epoch 4/1000

Epoch 00004: val_loss improved from 15.15903 to 14.41038, saving model to models/bc/shift2/max2015/simple-rnn/1.h5
 - 5s - loss: 14.7714 - out_stats_loss: 4.9938 - out_counts_loss: 2.4779 - out_mean_covariance_loss: 75.3080 - out_fielding_position_loss: 3.5343 - val_loss: 14.4104 - val_out_stats_loss: 4.9417 - val_out_counts_loss: 2.3466 - val_out_mean_covariance_loss: 74.3690 - val_out_fielding_position_loss: 3.4037
Epoch 5/1000

Epoch 00005: val_loss improved from 14.41038 to 13.99666, saving model to models/bc/shift2/max2015/simple-rnn/1.h5
 - 5s - loss: 14.1440 - out_stats_loss: 4.8298 - out_counts_loss: 2.4146 - out_mean_covariance_loss: 71.9258 - out_fielding_position_loss: 3.3034 - val_loss: 13.9967 - val_out_stats_loss: 4.8677 - val_out_counts_loss: 2.3137 - val_out_mean_covariance_loss: 72.3829 - val_out_fielding_position_loss: 3.1961
Epoch 6/1000

Epoch 00006: val_loss improved from 13.99666 to 13.62814, saving model to models/bc/shift2/max2015/simple-rnn/1.h5
 - 5s - loss: 13.7478 - out_stats_loss: 4.7541 - out_counts_loss: 2.3560 - out_mean_covariance_loss: 70.4562 - out_fielding_position_loss: 3.1149 - val_loss: 13.6281 - val_out_stats_loss: 4.7732 - val_out_counts_loss: 2.2766 - val_out_mean_covariance_loss: 70.7748 - val_out_fielding_position_loss: 3.0396
Epoch 7/1000

Epoch 00007: val_loss improved from 13.62814 to 13.38024, saving model to models/bc/shift2/max2015/simple-rnn/1.h5
 - 5s - loss: 13.4117 - out_stats_loss: 4.6782 - out_counts_loss: 2.3202 - out_mean_covariance_loss: 68.6785 - out_fielding_position_loss: 2.9794 - val_loss: 13.3802 - val_out_stats_loss: 4.7325 - val_out_counts_loss: 2.2618 - val_out_mean_covariance_loss: 69.6904 - val_out_fielding_position_loss: 2.9014
Epoch 8/1000

Epoch 00008: val_loss improved from 13.38024 to 13.20276, saving model to models/bc/shift2/max2015/simple-rnn/1.h5
 - 5s - loss: 13.2004 - out_stats_loss: 4.6345 - out_counts_loss: 2.3068 - out_mean_covariance_loss: 67.6931 - out_fielding_position_loss: 2.8745 - val_loss: 13.2028 - val_out_stats_loss: 4.6915 - val_out_counts_loss: 2.2509 - val_out_mean_covariance_loss: 69.0279 - val_out_fielding_position_loss: 2.8089
Epoch 9/1000

Epoch 00009: val_loss improved from 13.20276 to 13.07858, saving model to models/bc/shift2/max2015/simple-rnn/1.h5
 - 5s - loss: 13.0088 - out_stats_loss: 4.5915 - out_counts_loss: 2.2798 - out_mean_covariance_loss: 66.9573 - out_fielding_position_loss: 2.7896 - val_loss: 13.0786 - val_out_stats_loss: 4.6719 - val_out_counts_loss: 2.2405 - val_out_mean_covariance_loss: 68.6009 - val_out_fielding_position_loss: 2.7361
Epoch 10/1000

Epoch 00010: val_loss improved from 13.07858 to 12.97877, saving model to models/bc/shift2/max2015/simple-rnn/1.h5
 - 5s - loss: 12.8643 - out_stats_loss: 4.5496 - out_counts_loss: 2.2672 - out_mean_covariance_loss: 66.2489 - out_fielding_position_loss: 2.7350 - val_loss: 12.9788 - val_out_stats_loss: 4.6487 - val_out_counts_loss: 2.2406 - val_out_mean_covariance_loss: 68.2673 - val_out_fielding_position_loss: 2.6761
Epoch 11/1000

Epoch 00011: val_loss improved from 12.97877 to 12.90583, saving model to models/bc/shift2/max2015/simple-rnn/1.h5
 - 5s - loss: 12.8038 - out_stats_loss: 4.5526 - out_counts_loss: 2.2548 - out_mean_covariance_loss: 66.2307 - out_fielding_position_loss: 2.6849 - val_loss: 12.9058 - val_out_stats_loss: 4.6396 - val_out_counts_loss: 2.2313 - val_out_mean_covariance_loss: 67.8954 - val_out_fielding_position_loss: 2.6401
Epoch 12/1000

Epoch 00012: val_loss improved from 12.90583 to 12.80334, saving model to models/bc/shift2/max2015/simple-rnn/1.h5
 - 5s - loss: 12.6589 - out_stats_loss: 4.5054 - out_counts_loss: 2.2567 - out_mean_covariance_loss: 65.3624 - out_fielding_position_loss: 2.6286 - val_loss: 12.8033 - val_out_stats_loss: 4.6036 - val_out_counts_loss: 2.2248 - val_out_mean_covariance_loss: 67.4168 - val_out_fielding_position_loss: 2.6041
Epoch 13/1000

Epoch 00013: val_loss improved from 12.80334 to 12.72618, saving model to models/bc/shift2/max2015/simple-rnn/1.h5
 - 5s - loss: 12.5781 - out_stats_loss: 4.4866 - out_counts_loss: 2.2245 - out_mean_covariance_loss: 65.3435 - out_fielding_position_loss: 2.5998 - val_loss: 12.7262 - val_out_stats_loss: 4.5823 - val_out_counts_loss: 2.2090 - val_out_mean_covariance_loss: 67.1290 - val_out_fielding_position_loss: 2.5784
Epoch 14/1000

Epoch 00014: val_loss improved from 12.72618 to 12.68726, saving model to models/bc/shift2/max2015/simple-rnn/1.h5
 - 5s - loss: 12.5532 - out_stats_loss: 4.4916 - out_counts_loss: 2.2179 - out_mean_covariance_loss: 65.0288 - out_fielding_position_loss: 2.5922 - val_loss: 12.6873 - val_out_stats_loss: 4.5689 - val_out_counts_loss: 2.2109 - val_out_mean_covariance_loss: 66.9246 - val_out_fielding_position_loss: 2.5612
Epoch 15/1000

Epoch 00015: val_loss improved from 12.68726 to 12.63827, saving model to models/bc/shift2/max2015/simple-rnn/1.h5
 - 5s - loss: 12.4347 - out_stats_loss: 4.4442 - out_counts_loss: 2.2073 - out_mean_covariance_loss: 64.5103 - out_fielding_position_loss: 2.5577 - val_loss: 12.6383 - val_out_stats_loss: 4.5537 - val_out_counts_loss: 2.2040 - val_out_mean_covariance_loss: 66.6988 - val_out_fielding_position_loss: 2.5457
Epoch 16/1000

Epoch 00016: val_loss improved from 12.63827 to 12.59216, saving model to models/bc/shift2/max2015/simple-rnn/1.h5
 - 5s - loss: 12.3702 - out_stats_loss: 4.4310 - out_counts_loss: 2.1913 - out_mean_covariance_loss: 64.4562 - out_fielding_position_loss: 2.5251 - val_loss: 12.5922 - val_out_stats_loss: 4.5359 - val_out_counts_loss: 2.1974 - val_out_mean_covariance_loss: 66.5068 - val_out_fielding_position_loss: 2.5335
Epoch 17/1000

Epoch 00017: val_loss did not improve
 - 5s - loss: 12.2918 - out_stats_loss: 4.4147 - out_counts_loss: 2.1713 - out_mean_covariance_loss: 63.8912 - out_fielding_position_loss: 2.5113 - val_loss: 12.5961 - val_out_stats_loss: 4.5385 - val_out_counts_loss: 2.2194 - val_out_mean_covariance_loss: 66.4607 - val_out_fielding_position_loss: 2.5152
Epoch 18/1000

Epoch 00018: val_loss improved from 12.59216 to 12.54883, saving model to models/bc/shift2/max2015/simple-rnn/1.h5
 - 5s - loss: 12.2572 - out_stats_loss: 4.4091 - out_counts_loss: 2.1788 - out_mean_covariance_loss: 63.5279 - out_fielding_position_loss: 2.4929 - val_loss: 12.5488 - val_out_stats_loss: 4.5400 - val_out_counts_loss: 2.1943 - val_out_mean_covariance_loss: 66.1595 - val_out_fielding_position_loss: 2.5065
Epoch 19/1000

Epoch 00019: val_loss improved from 12.54883 to 12.51619, saving model to models/bc/shift2/max2015/simple-rnn/1.h5
 - 5s - loss: 12.2335 - out_stats_loss: 4.4020 - out_counts_loss: 2.1397 - out_mean_covariance_loss: 63.8975 - out_fielding_position_loss: 2.4969 - val_loss: 12.5162 - val_out_stats_loss: 4.5189 - val_out_counts_loss: 2.1989 - val_out_mean_covariance_loss: 66.0775 - val_out_fielding_position_loss: 2.4945
Epoch 20/1000

Epoch 00020: val_loss improved from 12.51619 to 12.51236, saving model to models/bc/shift2/max2015/simple-rnn/1.h5
 - 5s - loss: 12.1458 - out_stats_loss: 4.3761 - out_counts_loss: 2.1276 - out_mean_covariance_loss: 63.4866 - out_fielding_position_loss: 2.4678 - val_loss: 12.5124 - val_out_stats_loss: 4.5226 - val_out_counts_loss: 2.2058 - val_out_mean_covariance_loss: 65.9349 - val_out_fielding_position_loss: 2.4872
Epoch 21/1000

Epoch 00021: val_loss improved from 12.51236 to 12.47191, saving model to models/bc/shift2/max2015/simple-rnn/1.h5
 - 5s - loss: 12.0653 - out_stats_loss: 4.3640 - out_counts_loss: 2.1152 - out_mean_covariance_loss: 63.0750 - out_fielding_position_loss: 2.4324 - val_loss: 12.4719 - val_out_stats_loss: 4.5094 - val_out_counts_loss: 2.1899 - val_out_mean_covariance_loss: 65.8247 - val_out_fielding_position_loss: 2.4814
Epoch 22/1000

Epoch 00022: val_loss improved from 12.47191 to 12.46670, saving model to models/bc/shift2/max2015/simple-rnn/1.h5
 - 5s - loss: 12.0429 - out_stats_loss: 4.3524 - out_counts_loss: 2.0975 - out_mean_covariance_loss: 63.2343 - out_fielding_position_loss: 2.4313 - val_loss: 12.4667 - val_out_stats_loss: 4.5063 - val_out_counts_loss: 2.2006 - val_out_mean_covariance_loss: 65.7249 - val_out_fielding_position_loss: 2.4736
Epoch 23/1000

Epoch 00023: val_loss improved from 12.46670 to 12.42588, saving model to models/bc/shift2/max2015/simple-rnn/1.h5
 - 5s - loss: 11.9689 - out_stats_loss: 4.3312 - out_counts_loss: 2.0823 - out_mean_covariance_loss: 62.6200 - out_fielding_position_loss: 2.4243 - val_loss: 12.4259 - val_out_stats_loss: 4.4913 - val_out_counts_loss: 2.1935 - val_out_mean_covariance_loss: 65.4931 - val_out_fielding_position_loss: 2.4664
Epoch 24/1000

Epoch 00024: val_loss improved from 12.42588 to 12.41065, saving model to models/bc/shift2/max2015/simple-rnn/1.h5
 - 5s - loss: 11.9937 - out_stats_loss: 4.3521 - out_counts_loss: 2.0800 - out_mean_covariance_loss: 63.1045 - out_fielding_position_loss: 2.4064 - val_loss: 12.4106 - val_out_stats_loss: 4.4822 - val_out_counts_loss: 2.1887 - val_out_mean_covariance_loss: 65.5857 - val_out_fielding_position_loss: 2.4604
Epoch 25/1000

Epoch 00025: val_loss improved from 12.41065 to 12.39771, saving model to models/bc/shift2/max2015/simple-rnn/1.h5
 - 5s - loss: 11.9152 - out_stats_loss: 4.3325 - out_counts_loss: 2.0633 - out_mean_covariance_loss: 62.6517 - out_fielding_position_loss: 2.3868 - val_loss: 12.3977 - val_out_stats_loss: 4.4856 - val_out_counts_loss: 2.1883 - val_out_mean_covariance_loss: 65.4104 - val_out_fielding_position_loss: 2.4533
Epoch 26/1000

Epoch 00026: val_loss improved from 12.39771 to 12.39470, saving model to models/bc/shift2/max2015/simple-rnn/1.h5
 - 5s - loss: 11.8578 - out_stats_loss: 4.3097 - out_counts_loss: 2.0569 - out_mean_covariance_loss: 62.0748 - out_fielding_position_loss: 2.3874 - val_loss: 12.3947 - val_out_stats_loss: 4.4762 - val_out_counts_loss: 2.2011 - val_out_mean_covariance_loss: 65.4002 - val_out_fielding_position_loss: 2.4474
Epoch 27/1000

Epoch 00027: val_loss did not improve
 - 5s - loss: 11.8150 - out_stats_loss: 4.2954 - out_counts_loss: 2.0489 - out_mean_covariance_loss: 61.9310 - out_fielding_position_loss: 2.3741 - val_loss: 12.4776 - val_out_stats_loss: 4.4978 - val_out_counts_loss: 2.2468 - val_out_mean_covariance_loss: 65.8371 - val_out_fielding_position_loss: 2.4412
Epoch 28/1000

Epoch 00028: val_loss did not improve
 - 5s - loss: 11.7274 - out_stats_loss: 4.2792 - out_counts_loss: 2.0146 - out_mean_covariance_loss: 61.5996 - out_fielding_position_loss: 2.3536 - val_loss: 12.4973 - val_out_stats_loss: 4.5199 - val_out_counts_loss: 2.2619 - val_out_mean_covariance_loss: 65.5029 - val_out_fielding_position_loss: 2.4404
Epoch 29/1000

Epoch 00029: val_loss improved from 12.39470 to 12.35852, saving model to models/bc/shift2/max2015/simple-rnn/1.h5
 - 5s - loss: 11.7930 - out_stats_loss: 4.3183 - out_counts_loss: 2.0191 - out_mean_covariance_loss: 62.2516 - out_fielding_position_loss: 2.3430 - val_loss: 12.3585 - val_out_stats_loss: 4.4709 - val_out_counts_loss: 2.2004 - val_out_mean_covariance_loss: 65.1213 - val_out_fielding_position_loss: 2.4311
Epoch 30/1000

Epoch 00030: val_loss improved from 12.35852 to 12.34590, saving model to models/bc/shift2/max2015/simple-rnn/1.h5
 - 5s - loss: 11.6984 - out_stats_loss: 4.2841 - out_counts_loss: 2.0045 - out_mean_covariance_loss: 61.5902 - out_fielding_position_loss: 2.3303 - val_loss: 12.3459 - val_out_stats_loss: 4.4637 - val_out_counts_loss: 2.2076 - val_out_mean_covariance_loss: 64.9950 - val_out_fielding_position_loss: 2.4249
Epoch 31/1000

Epoch 00031: val_loss did not improve
 - 5s - loss: 11.7104 - out_stats_loss: 4.2984 - out_counts_loss: 1.9988 - out_mean_covariance_loss: 61.8987 - out_fielding_position_loss: 2.3183 - val_loss: 12.3489 - val_out_stats_loss: 4.4782 - val_out_counts_loss: 2.2029 - val_out_mean_covariance_loss: 64.9258 - val_out_fielding_position_loss: 2.4216
Epoch 32/1000

Epoch 00032: val_loss did not improve
 - 5s - loss: 11.5672 - out_stats_loss: 4.2475 - out_counts_loss: 1.9678 - out_mean_covariance_loss: 60.8685 - out_fielding_position_loss: 2.3084 - val_loss: 12.4430 - val_out_stats_loss: 4.4951 - val_out_counts_loss: 2.2639 - val_out_mean_covariance_loss: 65.2312 - val_out_fielding_position_loss: 2.4224
Epoch 33/1000

Epoch 00033: val_loss improved from 12.34590 to 12.32594, saving model to models/bc/shift2/max2015/simple-rnn/1.h5
 - 5s - loss: 11.5839 - out_stats_loss: 4.2630 - out_counts_loss: 1.9713 - out_mean_covariance_loss: 61.0115 - out_fielding_position_loss: 2.2990 - val_loss: 12.3259 - val_out_stats_loss: 4.4730 - val_out_counts_loss: 2.2093 - val_out_mean_covariance_loss: 64.7619 - val_out_fielding_position_loss: 2.4055
Epoch 34/1000

Epoch 00034: val_loss did not improve
 - 5s - loss: 11.5604 - out_stats_loss: 4.2603 - out_counts_loss: 1.9485 - out_mean_covariance_loss: 61.4655 - out_fielding_position_loss: 2.2783 - val_loss: 12.4939 - val_out_stats_loss: 4.5242 - val_out_counts_loss: 2.2932 - val_out_mean_covariance_loss: 65.3746 - val_out_fielding_position_loss: 2.4078
Epoch 35/1000

Epoch 00035: val_loss improved from 12.32594 to 12.29128, saving model to models/bc/shift2/max2015/simple-rnn/1.h5
 - 5s - loss: 11.4453 - out_stats_loss: 4.2289 - out_counts_loss: 1.9350 - out_mean_covariance_loss: 60.5281 - out_fielding_position_loss: 2.2551 - val_loss: 12.2913 - val_out_stats_loss: 4.4568 - val_out_counts_loss: 2.2031 - val_out_mean_covariance_loss: 64.6645 - val_out_fielding_position_loss: 2.3982
Epoch 36/1000

Epoch 00036: val_loss did not improve
 - 5s - loss: 11.4598 - out_stats_loss: 4.2342 - out_counts_loss: 1.9379 - out_mean_covariance_loss: 60.5640 - out_fielding_position_loss: 2.2595 - val_loss: 12.3402 - val_out_stats_loss: 4.4731 - val_out_counts_loss: 2.2347 - val_out_mean_covariance_loss: 64.7347 - val_out_fielding_position_loss: 2.3957
Epoch 37/1000

Epoch 00037: val_loss improved from 12.29128 to 12.28366, saving model to models/bc/shift2/max2015/simple-rnn/1.h5
 - 5s - loss: 11.4081 - out_stats_loss: 4.2229 - out_counts_loss: 1.9174 - out_mean_covariance_loss: 60.4478 - out_fielding_position_loss: 2.2455 - val_loss: 12.2837 - val_out_stats_loss: 4.4667 - val_out_counts_loss: 2.2035 - val_out_mean_covariance_loss: 64.6394 - val_out_fielding_position_loss: 2.3816
Epoch 38/1000

Epoch 00038: val_loss did not improve
 - 5s - loss: 11.3502 - out_stats_loss: 4.2150 - out_counts_loss: 1.8901 - out_mean_covariance_loss: 60.3375 - out_fielding_position_loss: 2.2282 - val_loss: 12.2934 - val_out_stats_loss: 4.4635 - val_out_counts_loss: 2.2264 - val_out_mean_covariance_loss: 64.5337 - val_out_fielding_position_loss: 2.3769
Epoch 39/1000

Epoch 00039: val_loss did not improve
 - 5s - loss: 11.2959 - out_stats_loss: 4.2024 - out_counts_loss: 1.8789 - out_mean_covariance_loss: 60.0740 - out_fielding_position_loss: 2.2108 - val_loss: 12.3082 - val_out_stats_loss: 4.4687 - val_out_counts_loss: 2.2420 - val_out_mean_covariance_loss: 64.5412 - val_out_fielding_position_loss: 2.3704
Epoch 40/1000

Epoch 00040: val_loss did not improve
 - 4s - loss: 11.2513 - out_stats_loss: 4.1884 - out_counts_loss: 1.8688 - out_mean_covariance_loss: 59.8440 - out_fielding_position_loss: 2.2018 - val_loss: 12.4067 - val_out_stats_loss: 4.4881 - val_out_counts_loss: 2.3059 - val_out_mean_covariance_loss: 64.7740 - val_out_fielding_position_loss: 2.3739
Epoch 41/1000

Epoch 00041: val_loss improved from 12.28366 to 12.27942, saving model to models/bc/shift2/max2015/simple-rnn/1.h5
 - 5s - loss: 11.2252 - out_stats_loss: 4.1908 - out_counts_loss: 1.8513 - out_mean_covariance_loss: 59.8293 - out_fielding_position_loss: 2.1916 - val_loss: 12.2794 - val_out_stats_loss: 4.4684 - val_out_counts_loss: 2.2318 - val_out_mean_covariance_loss: 64.4670 - val_out_fielding_position_loss: 2.3558
Epoch 42/1000

Epoch 00042: val_loss did not improve
 - 5s - loss: 11.1673 - out_stats_loss: 4.1729 - out_counts_loss: 1.8466 - out_mean_covariance_loss: 59.3791 - out_fielding_position_loss: 2.1789 - val_loss: 12.2991 - val_out_stats_loss: 4.4679 - val_out_counts_loss: 2.2528 - val_out_mean_covariance_loss: 64.5331 - val_out_fielding_position_loss: 2.3518
Epoch 43/1000

Epoch 00043: val_loss did not improve
 - 5s - loss: 11.1367 - out_stats_loss: 4.1611 - out_counts_loss: 1.8346 - out_mean_covariance_loss: 59.3161 - out_fielding_position_loss: 2.1752 - val_loss: 12.3248 - val_out_stats_loss: 4.4843 - val_out_counts_loss: 2.2700 - val_out_mean_covariance_loss: 64.4259 - val_out_fielding_position_loss: 2.3491
Epoch 44/1000

Epoch 00044: val_loss did not improve
 - 4s - loss: 11.1539 - out_stats_loss: 4.1778 - out_counts_loss: 1.8398 - out_mean_covariance_loss: 59.5211 - out_fielding_position_loss: 2.1603 - val_loss: 12.3628 - val_out_stats_loss: 4.4832 - val_out_counts_loss: 2.2969 - val_out_mean_covariance_loss: 64.6112 - val_out_fielding_position_loss: 2.3521
Epoch 45/1000

Epoch 00045: val_loss did not improve
 - 5s - loss: 11.1010 - out_stats_loss: 4.1584 - out_counts_loss: 1.8433 - out_mean_covariance_loss: 58.9792 - out_fielding_position_loss: 2.1503 - val_loss: 12.3434 - val_out_stats_loss: 4.4777 - val_out_counts_loss: 2.2952 - val_out_mean_covariance_loss: 64.4018 - val_out_fielding_position_loss: 2.3504
Epoch 46/1000

Epoch 00046: val_loss did not improve
 - 4s - loss: 11.0159 - out_stats_loss: 4.1450 - out_counts_loss: 1.8065 - out_mean_covariance_loss: 58.8020 - out_fielding_position_loss: 2.1243 - val_loss: 12.2972 - val_out_stats_loss: 4.4611 - val_out_counts_loss: 2.2792 - val_out_mean_covariance_loss: 64.2932 - val_out_fielding_position_loss: 2.3422
Epoch 47/1000

Epoch 00047: val_loss did not improve
 - 4s - loss: 11.0220 - out_stats_loss: 4.1485 - out_counts_loss: 1.7971 - out_mean_covariance_loss: 58.9918 - out_fielding_position_loss: 2.1268 - val_loss: 12.3314 - val_out_stats_loss: 4.4746 - val_out_counts_loss: 2.3003 - val_out_mean_covariance_loss: 64.3634 - val_out_fielding_position_loss: 2.3383
Epoch 48/1000

Epoch 00048: val_loss did not improve
 - 4s - loss: 11.0175 - out_stats_loss: 4.1503 - out_counts_loss: 1.8076 - out_mean_covariance_loss: 58.9740 - out_fielding_position_loss: 2.1109 - val_loss: 12.2977 - val_out_stats_loss: 4.4684 - val_out_counts_loss: 2.2849 - val_out_mean_covariance_loss: 64.3019 - val_out_fielding_position_loss: 2.3293
Epoch 49/1000

Epoch 00049: val_loss improved from 12.27942 to 12.26928, saving model to models/bc/shift2/max2015/simple-rnn/1.h5
 - 5s - loss: 10.9901 - out_stats_loss: 4.1510 - out_counts_loss: 1.7889 - out_mean_covariance_loss: 59.0279 - out_fielding_position_loss: 2.0987 - val_loss: 12.2693 - val_out_stats_loss: 4.4683 - val_out_counts_loss: 2.2737 - val_out_mean_covariance_loss: 64.1679 - val_out_fielding_position_loss: 2.3189
Epoch 50/1000

Epoch 00050: val_loss did not improve
 - 4s - loss: 10.8896 - out_stats_loss: 4.1113 - out_counts_loss: 1.7777 - out_mean_covariance_loss: 58.2383 - out_fielding_position_loss: 2.0886 - val_loss: 12.2867 - val_out_stats_loss: 4.4683 - val_out_counts_loss: 2.2893 - val_out_mean_covariance_loss: 64.2384 - val_out_fielding_position_loss: 2.3171
Epoch 51/1000

Epoch 00051: val_loss did not improve
 - 5s - loss: 10.9106 - out_stats_loss: 4.1366 - out_counts_loss: 1.7620 - out_mean_covariance_loss: 58.8277 - out_fielding_position_loss: 2.0707 - val_loss: 12.2789 - val_out_stats_loss: 4.4649 - val_out_counts_loss: 2.2905 - val_out_mean_covariance_loss: 64.1406 - val_out_fielding_position_loss: 2.3165
Epoch 52/1000

Epoch 00052: val_loss did not improve
 - 5s - loss: 10.8269 - out_stats_loss: 4.1120 - out_counts_loss: 1.7509 - out_mean_covariance_loss: 58.1772 - out_fielding_position_loss: 2.0552 - val_loss: 12.3004 - val_out_stats_loss: 4.4675 - val_out_counts_loss: 2.3114 - val_out_mean_covariance_loss: 64.2222 - val_out_fielding_position_loss: 2.3104
Epoch 53/1000

Epoch 00053: val_loss did not improve
 - 5s - loss: 10.8270 - out_stats_loss: 4.1200 - out_counts_loss: 1.7405 - out_mean_covariance_loss: 58.3549 - out_fielding_position_loss: 2.0487 - val_loss: 12.3602 - val_out_stats_loss: 4.5142 - val_out_counts_loss: 2.3276 - val_out_mean_covariance_loss: 64.2840 - val_out_fielding_position_loss: 2.3041
Epoch 54/1000

Epoch 00054: val_loss did not improve
 - 5s - loss: 10.7915 - out_stats_loss: 4.1137 - out_counts_loss: 1.7319 - out_mean_covariance_loss: 58.0653 - out_fielding_position_loss: 2.0427 - val_loss: 12.3310 - val_out_stats_loss: 4.4798 - val_out_counts_loss: 2.3313 - val_out_mean_covariance_loss: 64.2072 - val_out_fielding_position_loss: 2.3095
Epoch 55/1000

Epoch 00055: val_loss did not improve
 - 5s - loss: 10.7914 - out_stats_loss: 4.1154 - out_counts_loss: 1.7443 - out_mean_covariance_loss: 58.0736 - out_fielding_position_loss: 2.0280 - val_loss: 12.4045 - val_out_stats_loss: 4.4903 - val_out_counts_loss: 2.3772 - val_out_mean_covariance_loss: 64.3947 - val_out_fielding_position_loss: 2.3173
Epoch 56/1000

Epoch 00056: val_loss did not improve
 - 5s - loss: 10.7247 - out_stats_loss: 4.0875 - out_counts_loss: 1.7237 - out_mean_covariance_loss: 57.7976 - out_fielding_position_loss: 2.0237 - val_loss: 12.2926 - val_out_stats_loss: 4.4721 - val_out_counts_loss: 2.3187 - val_out_mean_covariance_loss: 64.1299 - val_out_fielding_position_loss: 2.2953
Epoch 57/1000

Epoch 00057: val_loss did not improve
 - 5s - loss: 10.6983 - out_stats_loss: 4.0959 - out_counts_loss: 1.6989 - out_mean_covariance_loss: 57.9336 - out_fielding_position_loss: 2.0068 - val_loss: 12.3766 - val_out_stats_loss: 4.4903 - val_out_counts_loss: 2.3679 - val_out_mean_covariance_loss: 64.2860 - val_out_fielding_position_loss: 2.3040
Epoch 58/1000

Epoch 00058: val_loss did not improve
 - 5s - loss: 10.7100 - out_stats_loss: 4.0900 - out_counts_loss: 1.7130 - out_mean_covariance_loss: 58.0196 - out_fielding_position_loss: 2.0061 - val_loss: 12.4404 - val_out_stats_loss: 4.5133 - val_out_counts_loss: 2.3848 - val_out_mean_covariance_loss: 64.5842 - val_out_fielding_position_loss: 2.3130
Epoch 59/1000

Epoch 00059: val_loss did not improve
 - 5s - loss: 10.6735 - out_stats_loss: 4.0847 - out_counts_loss: 1.7035 - out_mean_covariance_loss: 58.0383 - out_fielding_position_loss: 1.9835 - val_loss: 12.3352 - val_out_stats_loss: 4.4819 - val_out_counts_loss: 2.3420 - val_out_mean_covariance_loss: 64.4651 - val_out_fielding_position_loss: 2.2881
Epoch 60/1000

Epoch 00060: val_loss did not improve
 - 5s - loss: 10.6102 - out_stats_loss: 4.0712 - out_counts_loss: 1.6830 - out_mean_covariance_loss: 57.4365 - out_fielding_position_loss: 1.9842 - val_loss: 12.3496 - val_out_stats_loss: 4.4934 - val_out_counts_loss: 2.3606 - val_out_mean_covariance_loss: 64.1344 - val_out_fielding_position_loss: 2.2888
Epoch 61/1000

Epoch 00061: val_loss did not improve
 - 5s - loss: 10.6184 - out_stats_loss: 4.0793 - out_counts_loss: 1.6868 - out_mean_covariance_loss: 57.6104 - out_fielding_position_loss: 1.9718 - val_loss: 12.2914 - val_out_stats_loss: 4.4714 - val_out_counts_loss: 2.3366 - val_out_mean_covariance_loss: 64.0608 - val_out_fielding_position_loss: 2.2804
Epoch 62/1000

Epoch 00062: val_loss did not improve
 - 5s - loss: 10.5669 - out_stats_loss: 4.0602 - out_counts_loss: 1.6743 - out_mean_covariance_loss: 57.3513 - out_fielding_position_loss: 1.9649 - val_loss: 12.3542 - val_out_stats_loss: 4.4786 - val_out_counts_loss: 2.3774 - val_out_mean_covariance_loss: 64.1717 - val_out_fielding_position_loss: 2.2896
Epoch 63/1000

Epoch 00063: val_loss did not improve
 - 4s - loss: 10.5460 - out_stats_loss: 4.0551 - out_counts_loss: 1.6709 - out_mean_covariance_loss: 57.1281 - out_fielding_position_loss: 1.9636 - val_loss: 12.3868 - val_out_stats_loss: 4.4850 - val_out_counts_loss: 2.3982 - val_out_mean_covariance_loss: 64.2262 - val_out_fielding_position_loss: 2.2924
Epoch 64/1000

Epoch 00064: val_loss did not improve
 - 5s - loss: 10.4807 - out_stats_loss: 4.0361 - out_counts_loss: 1.6500 - out_mean_covariance_loss: 57.0025 - out_fielding_position_loss: 1.9444 - val_loss: 12.3610 - val_out_stats_loss: 4.4762 - val_out_counts_loss: 2.3908 - val_out_mean_covariance_loss: 64.1036 - val_out_fielding_position_loss: 2.2888
Epoch 65/1000

Epoch 00065: val_loss did not improve
 - 5s - loss: 10.4482 - out_stats_loss: 4.0247 - out_counts_loss: 1.6543 - out_mean_covariance_loss: 56.6123 - out_fielding_position_loss: 1.9386 - val_loss: 12.4469 - val_out_stats_loss: 4.4970 - val_out_counts_loss: 2.4226 - val_out_mean_covariance_loss: 64.4791 - val_out_fielding_position_loss: 2.3034
Epoch 66/1000

Epoch 00066: val_loss did not improve
 - 5s - loss: 10.4697 - out_stats_loss: 4.0451 - out_counts_loss: 1.6479 - out_mean_covariance_loss: 56.8173 - out_fielding_position_loss: 1.9359 - val_loss: 12.3585 - val_out_stats_loss: 4.4774 - val_out_counts_loss: 2.3940 - val_out_mean_covariance_loss: 64.1728 - val_out_fielding_position_loss: 2.2784
Epoch 67/1000

Epoch 00067: val_loss did not improve
 - 5s - loss: 10.4402 - out_stats_loss: 4.0257 - out_counts_loss: 1.6492 - out_mean_covariance_loss: 56.7184 - out_fielding_position_loss: 1.9294 - val_loss: 12.5156 - val_out_stats_loss: 4.5209 - val_out_counts_loss: 2.4707 - val_out_mean_covariance_loss: 64.5746 - val_out_fielding_position_loss: 2.2953
Epoch 68/1000

Epoch 00068: val_loss did not improve
 - 5s - loss: 10.4271 - out_stats_loss: 4.0283 - out_counts_loss: 1.6440 - out_mean_covariance_loss: 56.6388 - out_fielding_position_loss: 1.9229 - val_loss: 12.4957 - val_out_stats_loss: 4.5019 - val_out_counts_loss: 2.4669 - val_out_mean_covariance_loss: 64.6146 - val_out_fielding_position_loss: 2.2962
Epoch 69/1000

Epoch 00069: val_loss did not improve
 - 5s - loss: 10.4153 - out_stats_loss: 4.0309 - out_counts_loss: 1.6469 - out_mean_covariance_loss: 56.5457 - out_fielding_position_loss: 1.9103 - val_loss: 12.5973 - val_out_stats_loss: 4.5469 - val_out_counts_loss: 2.5059 - val_out_mean_covariance_loss: 64.7542 - val_out_fielding_position_loss: 2.3068
Epoch 70/1000

Epoch 00070: val_loss did not improve
 - 5s - loss: 10.4273 - out_stats_loss: 4.0535 - out_counts_loss: 1.6170 - out_mean_covariance_loss: 56.9558 - out_fielding_position_loss: 1.9091 - val_loss: 12.4440 - val_out_stats_loss: 4.4976 - val_out_counts_loss: 2.4517 - val_out_mean_covariance_loss: 64.3443 - val_out_fielding_position_loss: 2.2775
Epoch 71/1000

Epoch 00071: val_loss did not improve
 - 5s - loss: 10.3862 - out_stats_loss: 4.0286 - out_counts_loss: 1.6232 - out_mean_covariance_loss: 56.6782 - out_fielding_position_loss: 1.9005 - val_loss: 12.3858 - val_out_stats_loss: 4.4881 - val_out_counts_loss: 2.4156 - val_out_mean_covariance_loss: 64.1808 - val_out_fielding_position_loss: 2.2730
Epoch 72/1000

Epoch 00072: val_loss did not improve
 - 4s - loss: 10.3943 - out_stats_loss: 4.0337 - out_counts_loss: 1.6314 - out_mean_covariance_loss: 56.5894 - out_fielding_position_loss: 1.8997 - val_loss: 12.3255 - val_out_stats_loss: 4.4692 - val_out_counts_loss: 2.3881 - val_out_mean_covariance_loss: 63.9894 - val_out_fielding_position_loss: 2.2687
Epoch 73/1000

Epoch 00073: val_loss did not improve
 - 4s - loss: 10.2517 - out_stats_loss: 3.9834 - out_counts_loss: 1.6009 - out_mean_covariance_loss: 55.9110 - out_fielding_position_loss: 1.8718 - val_loss: 12.4066 - val_out_stats_loss: 4.4902 - val_out_counts_loss: 2.4207 - val_out_mean_covariance_loss: 64.3239 - val_out_fielding_position_loss: 2.2796
Epoch 74/1000

Epoch 00074: val_loss did not improve
 - 4s - loss: 10.3203 - out_stats_loss: 4.0117 - out_counts_loss: 1.6079 - out_mean_covariance_loss: 56.3561 - out_fielding_position_loss: 1.8829 - val_loss: 12.4508 - val_out_stats_loss: 4.4979 - val_out_counts_loss: 2.4485 - val_out_mean_covariance_loss: 64.4039 - val_out_fielding_position_loss: 2.2842
Epoch 75/1000

Epoch 00075: val_loss did not improve
 - 5s - loss: 10.2760 - out_stats_loss: 3.9991 - out_counts_loss: 1.6002 - out_mean_covariance_loss: 56.3114 - out_fielding_position_loss: 1.8611 - val_loss: 12.4222 - val_out_stats_loss: 4.4849 - val_out_counts_loss: 2.4425 - val_out_mean_covariance_loss: 64.3682 - val_out_fielding_position_loss: 2.2764
Epoch 76/1000

Epoch 00076: val_loss did not improve
 - 5s - loss: 10.2432 - out_stats_loss: 3.9897 - out_counts_loss: 1.5915 - out_mean_covariance_loss: 56.0712 - out_fielding_position_loss: 1.8584 - val_loss: 12.4477 - val_out_stats_loss: 4.4852 - val_out_counts_loss: 2.4644 - val_out_mean_covariance_loss: 64.3838 - val_out_fielding_position_loss: 2.2789
Epoch 77/1000

Epoch 00077: val_loss did not improve
 - 5s - loss: 10.2298 - out_stats_loss: 3.9965 - out_counts_loss: 1.5796 - out_mean_covariance_loss: 56.0875 - out_fielding_position_loss: 1.8493 - val_loss: 12.6027 - val_out_stats_loss: 4.5379 - val_out_counts_loss: 2.5340 - val_out_mean_covariance_loss: 64.8128 - val_out_fielding_position_loss: 2.2902
Epoch 78/1000

Epoch 00078: val_loss did not improve
 - 5s - loss: 10.2027 - out_stats_loss: 3.9875 - out_counts_loss: 1.5756 - out_mean_covariance_loss: 55.8787 - out_fielding_position_loss: 1.8457 - val_loss: 12.5457 - val_out_stats_loss: 4.5166 - val_out_counts_loss: 2.5056 - val_out_mean_covariance_loss: 64.6873 - val_out_fielding_position_loss: 2.2891
Epoch 79/1000

Epoch 00079: val_loss did not improve
 - 5s - loss: 10.2360 - out_stats_loss: 4.0031 - out_counts_loss: 1.5739 - out_mean_covariance_loss: 56.3643 - out_fielding_position_loss: 1.8408 - val_loss: 12.5438 - val_out_stats_loss: 4.5324 - val_out_counts_loss: 2.4957 - val_out_mean_covariance_loss: 64.8433 - val_out_fielding_position_loss: 2.2736
Epoch 80/1000

Epoch 00080: val_loss did not improve
 - 5s - loss: 10.1636 - out_stats_loss: 3.9775 - out_counts_loss: 1.5657 - out_mean_covariance_loss: 55.6228 - out_fielding_position_loss: 1.8393 - val_loss: 12.4283 - val_out_stats_loss: 4.4817 - val_out_counts_loss: 2.4604 - val_out_mean_covariance_loss: 64.3356 - val_out_fielding_position_loss: 2.2694
Epoch 81/1000

Epoch 00081: val_loss did not improve
 - 4s - loss: 10.0878 - out_stats_loss: 3.9555 - out_counts_loss: 1.5498 - out_mean_covariance_loss: 55.2528 - out_fielding_position_loss: 1.8198 - val_loss: 12.4432 - val_out_stats_loss: 4.4804 - val_out_counts_loss: 2.4823 - val_out_mean_covariance_loss: 64.4173 - val_out_fielding_position_loss: 2.2597
Epoch 82/1000

Epoch 00082: val_loss did not improve
 - 4s - loss: 10.1295 - out_stats_loss: 3.9791 - out_counts_loss: 1.5563 - out_mean_covariance_loss: 55.5448 - out_fielding_position_loss: 1.8168 - val_loss: 12.4356 - val_out_stats_loss: 4.4947 - val_out_counts_loss: 2.4695 - val_out_mean_covariance_loss: 64.4146 - val_out_fielding_position_loss: 2.2507
Epoch 83/1000

Epoch 00083: val_loss did not improve
 - 5s - loss: 10.0868 - out_stats_loss: 3.9613 - out_counts_loss: 1.5519 - out_mean_covariance_loss: 55.2142 - out_fielding_position_loss: 1.8129 - val_loss: 12.5470 - val_out_stats_loss: 4.5180 - val_out_counts_loss: 2.5116 - val_out_mean_covariance_loss: 64.6626 - val_out_fielding_position_loss: 2.2843
Epoch 84/1000

Epoch 00084: val_loss did not improve
 - 5s - loss: 10.0938 - out_stats_loss: 3.9587 - out_counts_loss: 1.5687 - out_mean_covariance_loss: 55.1542 - out_fielding_position_loss: 1.8087 - val_loss: 12.4158 - val_out_stats_loss: 4.4829 - val_out_counts_loss: 2.4576 - val_out_mean_covariance_loss: 64.3922 - val_out_fielding_position_loss: 2.2557
Epoch 85/1000

Epoch 00085: val_loss did not improve
 - 5s - loss: 10.0380 - out_stats_loss: 3.9425 - out_counts_loss: 1.5457 - out_mean_covariance_loss: 54.9105 - out_fielding_position_loss: 1.8043 - val_loss: 12.4990 - val_out_stats_loss: 4.5028 - val_out_counts_loss: 2.4939 - val_out_mean_covariance_loss: 64.5555 - val_out_fielding_position_loss: 2.2746
Epoch 86/1000

Epoch 00086: val_loss did not improve
 - 5s - loss: 10.0390 - out_stats_loss: 3.9514 - out_counts_loss: 1.5419 - out_mean_covariance_loss: 54.8814 - out_fielding_position_loss: 1.8017 - val_loss: 12.4509 - val_out_stats_loss: 4.5000 - val_out_counts_loss: 2.4683 - val_out_mean_covariance_loss: 64.4773 - val_out_fielding_position_loss: 2.2587
Epoch 87/1000

Epoch 00087: val_loss did not improve
 - 5s - loss: 10.0301 - out_stats_loss: 3.9444 - out_counts_loss: 1.5375 - out_mean_covariance_loss: 55.0328 - out_fielding_position_loss: 1.7966 - val_loss: 12.4948 - val_out_stats_loss: 4.5038 - val_out_counts_loss: 2.5026 - val_out_mean_covariance_loss: 64.6229 - val_out_fielding_position_loss: 2.2573
Epoch 88/1000

Epoch 00088: val_loss did not improve
 - 5s - loss: 10.0119 - out_stats_loss: 3.9484 - out_counts_loss: 1.5242 - out_mean_covariance_loss: 55.1924 - out_fielding_position_loss: 1.7798 - val_loss: 12.4673 - val_out_stats_loss: 4.4865 - val_out_counts_loss: 2.4904 - val_out_mean_covariance_loss: 64.5588 - val_out_fielding_position_loss: 2.2624
Epoch 89/1000

Epoch 00089: val_loss did not improve
 - 4s - loss: 9.9937 - out_stats_loss: 3.9373 - out_counts_loss: 1.5220 - out_mean_covariance_loss: 55.0261 - out_fielding_position_loss: 1.7831 - val_loss: 12.5478 - val_out_stats_loss: 4.5234 - val_out_counts_loss: 2.5182 - val_out_mean_covariance_loss: 64.8223 - val_out_fielding_position_loss: 2.2651
Epoch 90/1000

Epoch 00090: val_loss did not improve
 - 5s - loss: 10.0307 - out_stats_loss: 3.9490 - out_counts_loss: 1.5338 - out_mean_covariance_loss: 55.1303 - out_fielding_position_loss: 1.7914 - val_loss: 12.8116 - val_out_stats_loss: 4.5669 - val_out_counts_loss: 2.6515 - val_out_mean_covariance_loss: 65.5974 - val_out_fielding_position_loss: 2.3134
Epoch 91/1000

Epoch 00091: val_loss did not improve
 - 5s - loss: 10.0188 - out_stats_loss: 3.9491 - out_counts_loss: 1.5412 - out_mean_covariance_loss: 55.1317 - out_fielding_position_loss: 1.7719 - val_loss: 12.5211 - val_out_stats_loss: 4.5071 - val_out_counts_loss: 2.5131 - val_out_mean_covariance_loss: 64.7786 - val_out_fielding_position_loss: 2.2620
Epoch 92/1000

Epoch 00092: val_loss did not improve
 - 5s - loss: 9.9329 - out_stats_loss: 3.9331 - out_counts_loss: 1.5098 - out_mean_covariance_loss: 54.7779 - out_fielding_position_loss: 1.7512 - val_loss: 12.4599 - val_out_stats_loss: 4.4919 - val_out_counts_loss: 2.4790 - val_out_mean_covariance_loss: 64.6822 - val_out_fielding_position_loss: 2.2548
Epoch 93/1000

Epoch 00093: val_loss did not improve
 - 4s - loss: 9.9203 - out_stats_loss: 3.9253 - out_counts_loss: 1.5013 - out_mean_covariance_loss: 54.7663 - out_fielding_position_loss: 1.7554 - val_loss: 12.5821 - val_out_stats_loss: 4.5287 - val_out_counts_loss: 2.5335 - val_out_mean_covariance_loss: 64.9913 - val_out_fielding_position_loss: 2.2703
Epoch 94/1000

Epoch 00094: val_loss did not improve
 - 5s - loss: 9.8832 - out_stats_loss: 3.9182 - out_counts_loss: 1.4945 - out_mean_covariance_loss: 54.4562 - out_fielding_position_loss: 1.7476 - val_loss: 12.7230 - val_out_stats_loss: 4.5735 - val_out_counts_loss: 2.5909 - val_out_mean_covariance_loss: 65.2994 - val_out_fielding_position_loss: 2.2936
Epoch 95/1000

Epoch 00095: val_loss did not improve
 - 4s - loss: 9.8502 - out_stats_loss: 3.9126 - out_counts_loss: 1.4908 - out_mean_covariance_loss: 54.2256 - out_fielding_position_loss: 1.7355 - val_loss: 12.5242 - val_out_stats_loss: 4.5086 - val_out_counts_loss: 2.5191 - val_out_mean_covariance_loss: 64.7392 - val_out_fielding_position_loss: 2.2595
Epoch 96/1000

Epoch 00096: val_loss did not improve
 - 5s - loss: 9.9228 - out_stats_loss: 3.9432 - out_counts_loss: 1.4844 - out_mean_covariance_loss: 54.8867 - out_fielding_position_loss: 1.7509 - val_loss: 12.7230 - val_out_stats_loss: 4.5597 - val_out_counts_loss: 2.6012 - val_out_mean_covariance_loss: 65.3768 - val_out_fielding_position_loss: 2.2933
Epoch 97/1000

Epoch 00097: val_loss did not improve
 - 5s - loss: 9.8397 - out_stats_loss: 3.9131 - out_counts_loss: 1.4926 - out_mean_covariance_loss: 54.1904 - out_fielding_position_loss: 1.7245 - val_loss: 12.5832 - val_out_stats_loss: 4.5116 - val_out_counts_loss: 2.5467 - val_out_mean_covariance_loss: 65.0824 - val_out_fielding_position_loss: 2.2707
Epoch 98/1000

Epoch 00098: val_loss did not improve
 - 5s - loss: 9.8295 - out_stats_loss: 3.9057 - out_counts_loss: 1.4926 - out_mean_covariance_loss: 54.2195 - out_fielding_position_loss: 1.7201 - val_loss: 12.6851 - val_out_stats_loss: 4.5410 - val_out_counts_loss: 2.5842 - val_out_mean_covariance_loss: 65.4456 - val_out_fielding_position_loss: 2.2876
Epoch 99/1000

Epoch 00099: val_loss did not improve
 - 5s - loss: 9.8159 - out_stats_loss: 3.9082 - out_counts_loss: 1.4781 - out_mean_covariance_loss: 54.1212 - out_fielding_position_loss: 1.7235 - val_loss: 12.5956 - val_out_stats_loss: 4.5172 - val_out_counts_loss: 2.5623 - val_out_mean_covariance_loss: 65.0122 - val_out_fielding_position_loss: 2.2654
/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
Years: [1958,2015]
Shift: 2
Fold: 4
Training into models/bc/shift2/max2015/simple-rnn/1.h5
/usr/local/lib/python3.5/dist-packages/keras/legacy/layers.py:533: UserWarning: The `MaxoutDense` layer is deprecated and will be removed after 06/2017.
  warnings.warn('The `MaxoutDense` layer is deprecated '
